{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# REST API Publishing Examples Validation (Python)\n",
        "\n",
        "This notebook validates Python code examples from the Fiddler REST API publishing guides:\n",
        "- [Publishing via REST API](../python-client-guides/publishing-production-data/publishing-via-rest-api.md) (Quick-start guide)\n",
        "- [Advanced REST API Publishing](../python-client-guides/publishing-production-data/publishing-via-rest-api-advanced.md) (Advanced guide)\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "### Environment Variables\n",
        "Set these environment variables before running:\n",
        "```bash\n",
        "export FIDDLER_API_KEY=\"your-api-key\"\n",
        "export FIDDLER_ENDPOINT=\"https://your-instance.fiddler.ai\"\n",
        "export MODEL_ID=\"your-model-uuid\"\n",
        "```\n",
        "\n",
        "### Python Dependencies\n",
        "```bash\n",
        "pip install requests ipykernel\n",
        "```\n",
        "\n",
        "## Notebook Structure\n",
        "\n",
        "1. **Setup** - Environment variables and test data creation\n",
        "2. **Quick-Start Examples** - Python examples from quick-start guide\n",
        "3. **Advanced Examples** - Production-ready Python publisher with retry logic\n",
        "4. **Cleanup** - Remove temporary files\n",
        "\n",
        "## Note on TypeScript Examples\n",
        "\n",
        "For TypeScript examples, see the dedicated [TypeScript REST API Validation Notebook](validate-typescript-rest-api-example.nnb).\n",
        "\n",
        "## Note on curl Examples\n",
        "\n",
        "The markdown documentation includes curl examples for language-agnostic reference. This notebook uses Python `requests` for clarity and simplicity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Section 1: Setup\n",
        "\n",
        "Initialize environment variables and create test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from datetime import datetime, timezone\n",
        "from typing import Dict, List\n",
        "\n",
        "import requests\n",
        "\n",
        "# Load environment variables\n",
        "api_key = os.environ.get(\"FIDDLER_API_KEY\")\n",
        "fiddler_endpoint = os.environ.get(\"FIDDLER_ENDPOINT\")\n",
        "model_id = os.environ.get(\"MODEL_ID\")\n",
        "\n",
        "# Validate environment\n",
        "if not all([api_key, fiddler_endpoint, model_id]):\n",
        "    raise ValueError(\n",
        "        \"Missing required environment variables. Set: \"\n",
        "        \"FIDDLER_API_KEY, FIDDLER_ENDPOINT, MODEL_ID\"\n",
        "    )\n",
        "\n",
        "print(\"✓ Environment configured\")\n",
        "print(f\"  Endpoint: {fiddler_endpoint}\")\n",
        "print(f\"  Model ID: {model_id}\")\n",
        "\n",
        "# Create test CSV file for batch publishing with bank churn schema\n",
        "csv_content = \"\"\"customer_id,creditscore,geography,gender,age,tenure,balance,numofproducts,hascrcard,isactivemember,estimatedsalary,predicted_churn,churn,timestamp\n",
        "27c349a2,559,California,Male,52,2,0.0,1,1,0,129013.59,0.007447,no,2025-12-28T12:00:00Z\n",
        "27c35cee,482,California,Male,55,5,97318.25,1,0,1,78416.14,0.804852,yes,2025-12-27T12:01:00Z\n",
        "27c364f0,651,Florida,Female,46,4,89743.05,1,1,0,156425.57,0.012754,no,2025-12-29T12:02:00Z\n",
        "\"\"\"\n",
        "\n",
        "with open(\"churn_events.csv\", \"w\") as f:\n",
        "    f.write(csv_content)\n",
        "\n",
        "print(\"✓ Created test CSV file: churn_events.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Section 2: Quick-Start Examples\n",
        "\n",
        "Examples from [publishing-via-rest-api.md](../python-client-guides/publishing-production-data/publishing-via-rest-api.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Batch Upload - Python Example\n",
        "\n",
        "Upload CSV file and save file_id for batch publishing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload file\n",
        "with open(\"churn_events.csv\", \"rb\") as f:\n",
        "    response = requests.post(\n",
        "        f\"{fiddler_endpoint}/v3/files/upload\",\n",
        "        headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
        "        files={\"file\": f}\n",
        "    )\n",
        "\n",
        "file_id = response.json()[\"data\"][\"id\"]\n",
        "print(f\"✓ File uploaded. File ID: {file_id}\")\n",
        "\n",
        "# Save for next step\n",
        "with open(\"file_id.txt\", \"w\") as f:\n",
        "    f.write(file_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Batch Publish - Python Example\n",
        "\n",
        "Publish events from the uploaded file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read file_id from previous upload\n",
        "with open(\"file_id.txt\", \"r\") as f:\n",
        "    file_id = f.read().strip()\n",
        "\n",
        "payload = {\n",
        "    \"model_id\": model_id,\n",
        "    \"env_type\": \"PRODUCTION\",\n",
        "    \"source\": {\n",
        "        \"type\": \"FILE\",\n",
        "        \"file_id\": file_id\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(\n",
        "    f\"{fiddler_endpoint}/v3/events\",\n",
        "    headers={\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"},\n",
        "    data=json.dumps(payload)\n",
        ")\n",
        "\n",
        "job_id = response.json()[\"data\"][\"job\"][\"id\"]\n",
        "print(f\"✓ Batch publish started. Job ID: {job_id}\")\n",
        "\n",
        "# Save for reference\n",
        "with open(\"job_id.txt\", \"w\") as f:\n",
        "    f.write(job_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Streaming - Python Example\n",
        "\n",
        "Stream individual events directly to Fiddler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "events = [\n",
        "    {\n",
        "        \"customer_id\": \"27c349a2\",\n",
        "        \"creditscore\": 559,\n",
        "        \"geography\": \"California\",\n",
        "        \"gender\": \"Male\",\n",
        "        \"age\": 52,\n",
        "        \"tenure\": 2,\n",
        "        \"balance\": 0.0,\n",
        "        \"numofproducts\": 1,\n",
        "        \"hascrcard\": 1,\n",
        "        \"isactivemember\": 0,\n",
        "        \"estimatedsalary\": 129013.59,\n",
        "        \"predicted_churn\": 0.007447,\n",
        "        \"churn\": \"no\",\n",
        "        \"timestamp\": datetime.now(timezone.utc).isoformat()\n",
        "    }\n",
        "]\n",
        "\n",
        "payload = {\n",
        "    \"model_id\": model_id,\n",
        "    \"env_type\": \"PRODUCTION\",\n",
        "    \"source\": {\n",
        "        \"type\": \"EVENTS\",\n",
        "        \"events\": events\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(\n",
        "    f\"{fiddler_endpoint}/v3/events\",\n",
        "    headers={\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"},\n",
        "    data=json.dumps(payload)\n",
        ")\n",
        "\n",
        "event_ids = response.json()[\"data\"][\"event_ids\"]\n",
        "print(f\"✓ Streaming publish completed. Published {len(event_ids)} event(s)\")\n",
        "\n",
        "# Save first event_id for updates\n",
        "with open(\"event_id.txt\", \"w\") as f:\n",
        "    f.write(event_ids[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Updates - Python Example\n",
        "\n",
        "Update existing events using PATCH.\n",
        "\n",
        "**IMPORTANT:** Only PRODUCTION events can be updated. Non-production events (PRE_PRODUCTION) are immutable and cannot be modified via batch OR streaming processes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "updates = [\n",
        "    {\n",
        "        \"customer_id\": \"27c349a2\",\n",
        "        \"churn\": \"yes\"\n",
        "    }\n",
        "]\n",
        "\n",
        "payload = {\n",
        "    \"model_id\": model_id,\n",
        "    \"env_type\": \"PRODUCTION\",\n",
        "    \"source\": {\n",
        "        \"type\": \"EVENTS\",\n",
        "        \"events\": updates\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.patch(\n",
        "    f\"{fiddler_endpoint}/v3/events\",\n",
        "    headers={\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"},\n",
        "    data=json.dumps(payload)\n",
        ")\n",
        "\n",
        "print(f\"✓ Update completed. Response status: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Section 3: Advanced Examples\n",
        "\n",
        "Production-ready Python publisher from [publishing-via-rest-api-advanced.md](../python-client-guides/publishing-production-data/publishing-via-rest-api-advanced.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Python ProductionStreamingPublisher\n",
        "\n",
        "Production-grade publisher with exponential backoff retry logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "\n",
        "class ProductionStreamingPublisher:\n",
        "    def __init__(\n",
        "        self,\n",
        "        api_key: str,\n",
        "        endpoint: str,\n",
        "        max_retries: int = 3,\n",
        "        initial_delay: float = 1.0,\n",
        "        backoff_multiplier: float = 2.0\n",
        "    ):\n",
        "        self.api_key = api_key\n",
        "        self.endpoint = endpoint\n",
        "        self.max_retries = max_retries\n",
        "        self.initial_delay = initial_delay\n",
        "        self.backoff_multiplier = backoff_multiplier\n",
        "\n",
        "    def _get_headers(self, is_retry: bool = False) -> Dict[str, str]:\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
        "        }\n",
        "        if is_retry:\n",
        "            headers[\"X-Fiddler-Client-Retry\"] = \"true\"\n",
        "        return headers\n",
        "\n",
        "    def _calculate_backoff(self, attempt: int) -> float:\n",
        "        return self.initial_delay * (self.backoff_multiplier ** attempt)\n",
        "\n",
        "    def _is_retryable(self, status_code: int) -> bool:\n",
        "        return status_code in [429, 500, 502, 503, 504]\n",
        "\n",
        "    def publish_events_with_retry(\n",
        "        self,\n",
        "        model_id: str,\n",
        "        events: List[Dict]\n",
        "    ) -> Optional[List[str]]:\n",
        "        \"\"\"Publish events with exponential backoff retry logic.\"\"\"\n",
        "\n",
        "        if not events:\n",
        "            raise ValueError(\"Events list cannot be empty\")\n",
        "\n",
        "        if len(events) > 1000:\n",
        "            raise ValueError(f\"Batch size {len(events)} exceeds maximum 1000\")\n",
        "\n",
        "        payload = {\n",
        "            \"model_id\": model_id,\n",
        "            \"env_type\": \"PRODUCTION\",\n",
        "            \"source\": {\n",
        "                \"type\": \"EVENTS\",\n",
        "                \"events\": events\n",
        "            }\n",
        "        }\n",
        "\n",
        "        last_error = None\n",
        "\n",
        "        for attempt in range(self.max_retries + 1):\n",
        "            try:\n",
        "                # Add delay and retry header for retries\n",
        "                if attempt > 0:\n",
        "                    delay = self._calculate_backoff(attempt - 1)\n",
        "                    print(f\"Retry attempt {attempt}/{self.max_retries} after {delay:.1f}s\")\n",
        "                    time.sleep(delay)\n",
        "\n",
        "                headers = self._get_headers(is_retry=attempt > 0)\n",
        "\n",
        "                response = requests.post(\n",
        "                    f\"{self.endpoint}/v3/events\",\n",
        "                    headers=headers,\n",
        "                    data=json.dumps(payload),\n",
        "                    timeout=30\n",
        "                )\n",
        "\n",
        "                # Streaming returns 202 Accepted (both batch and streaming use 202)\n",
        "                if response.status_code == 200 or response.status_code == 202:\n",
        "                    result = response.json()\n",
        "                    if attempt > 0:\n",
        "                        print(f\"✓ Succeeded on retry attempt {attempt}\")\n",
        "                    return result[\"data\"].get(\"event_ids\", [])\n",
        "\n",
        "                # Check if retryable\n",
        "                if not self._is_retryable(response.status_code):\n",
        "                    error_body = response.json()\n",
        "                    raise Exception(\n",
        "                        f\"Non-retryable error ({response.status_code}): \"\n",
        "                        f\"{error_body.get('message', 'Unknown error')}\"\n",
        "                    )\n",
        "\n",
        "                error_body = response.json()\n",
        "                last_error = Exception(\n",
        "                    f\"HTTP {response.status_code}: \"\n",
        "                    f\"{error_body.get('message', 'Unknown error')}\"\n",
        "                )\n",
        "\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                last_error = e\n",
        "                # Network errors are retryable\n",
        "                if attempt == self.max_retries:\n",
        "                    break\n",
        "\n",
        "        raise Exception(\n",
        "            f\"Max retries ({self.max_retries}) exceeded. \"\n",
        "            f\"Last error: {str(last_error)}\"\n",
        "        )\n",
        "\n",
        "    def publish_batch(\n",
        "        self,\n",
        "        model_id: str,\n",
        "        events: List[Dict],\n",
        "        batch_size: int = 1000\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Publish large event lists in batches with retry.\"\"\"\n",
        "        all_event_ids = []\n",
        "\n",
        "        for i in range(0, len(events), batch_size):\n",
        "            batch = events[i:i + batch_size]\n",
        "            print(f\"Publishing batch {i // batch_size + 1} ({len(batch)} events)\")\n",
        "\n",
        "            event_ids = self.publish_events_with_retry(model_id, batch)\n",
        "            all_event_ids.extend(event_ids)\n",
        "\n",
        "            print(f\"✓ Published {len(event_ids)} events\")\n",
        "\n",
        "        return all_event_ids\n",
        "\n",
        "print(\"✓ ProductionStreamingPublisher class defined\")\n",
        "\n",
        "# Test the class with sample events\n",
        "publisher = ProductionStreamingPublisher(\n",
        "    api_key=api_key,\n",
        "    endpoint=fiddler_endpoint,\n",
        "    max_retries=2,\n",
        "    initial_delay=1.0\n",
        ")\n",
        "\n",
        "# Create test events with bank churn schema\n",
        "test_events = [\n",
        "    {\n",
        "        \"customer_id\": \"27c349a2\",\n",
        "        \"creditscore\": 559,\n",
        "        \"geography\": \"California\",\n",
        "        \"gender\": \"Male\",\n",
        "        \"age\": 52,\n",
        "        \"tenure\": 2,\n",
        "        \"balance\": 0.0,\n",
        "        \"numofproducts\": 1,\n",
        "        \"hascrcard\": 1,\n",
        "        \"isactivemember\": 0,\n",
        "        \"estimatedsalary\": 129013.59,\n",
        "        \"predicted_churn\": 0.007447,\n",
        "        \"churn\": \"no\",\n",
        "        \"timestamp\": datetime.now(timezone.utc).isoformat()\n",
        "    },\n",
        "    {\n",
        "        \"customer_id\": \"27c35cee\",\n",
        "        \"creditscore\": 482,\n",
        "        \"geography\": \"California\",\n",
        "        \"gender\": \"Male\",\n",
        "        \"age\": 55,\n",
        "        \"tenure\": 5,\n",
        "        \"balance\": 97318.25,\n",
        "        \"numofproducts\": 1,\n",
        "        \"hascrcard\": 0,\n",
        "        \"isactivemember\": 1,\n",
        "        \"estimatedsalary\": 78416.14,\n",
        "        \"predicted_churn\": 0.804852,\n",
        "        \"churn\": \"yes\",\n",
        "        \"timestamp\": datetime.now(timezone.utc).isoformat()\n",
        "    }\n",
        "]\n",
        "\n",
        "try:\n",
        "    event_ids = publisher.publish_events_with_retry(\n",
        "        model_id=model_id,\n",
        "        events=test_events\n",
        "    )\n",
        "    print(f\"✓ Successfully published {len(event_ids)} events with ProductionStreamingPublisher\")\n",
        "except Exception as e:\n",
        "    print(f\"Publishing test: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Section 4: Cleanup\n",
        "\n",
        "Remove temporary files created during validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "temp_files = [\n",
        "    \"churn_events.csv\",\n",
        "    \"file_id.txt\",\n",
        "    \"job_id.txt\",\n",
        "    \"event_id.txt\"\n",
        "]\n",
        "\n",
        "for file in temp_files:\n",
        "    if os.path.exists(file):\n",
        "        os.remove(file)\n",
        "        print(f\"✓ Removed {file}\")\n",
        "\n",
        "print(\"\\n=== Validation Complete ===\")\n",
        "print(\"All Python code examples from REST API publishing guides have been tested.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
