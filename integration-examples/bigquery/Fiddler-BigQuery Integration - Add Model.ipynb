{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "839cb7fa",
   "metadata": {},
   "source": [
    "# Fiddler examples have moved! [Deprecation Notice]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7c2ec",
   "metadata": {},
   "source": [
    "Dear user thank you for using fiddler product, we appreciate your time! We have moved the examples to a new github repo located at the following link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f5e1b",
   "metadata": {},
   "source": [
    "***\n",
    "# [New fiddler-examples repo](https://github.com/fiddler-labs/fiddler-examples)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71127364",
   "metadata": {},
   "source": [
    "# Fiddler-BigQuery Integration 1 - Add Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f9fd88",
   "metadata": {},
   "source": [
    "This notebook is used in conjuction with the guide on how to use Fiddler for you machine learning model data stored in BigQuery. Link\n",
    "\n",
    "In this notebook we will look at how we can use data stored in BigQuery to upload to fiddler as baseline data for your ML model. We will also add your model on the Fiddler platform.\n",
    "\n",
    "Link to [part 2](https://colab.research.google.com/github/fiddler-labs/fiddler-samples/blob/master/content_root/tutorial/integration-examples/bigquery/Fiddler-BigQuery%20Integration%20-%20Event%20Publishing.ipynb) of the guide on how to publish production data on Fiddler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a05d3",
   "metadata": {},
   "source": [
    "## Establish connection to BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc7e8f",
   "metadata": {},
   "source": [
    "Install required libraries to loading data from BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud\n",
    "# !pip install google-cloud-bigquery[pandas]\n",
    "# !pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5df19",
   "metadata": {},
   "source": [
    "Adding the location of the Google cloud auth key info as environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d93c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set environment variables for your notebook\n",
    "import os \n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '<link to json key>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ef79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports google cloud client library and initiates BQ service\n",
    "from google.cloud import bigquery\n",
    "bigquery_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0814681",
   "metadata": {},
   "source": [
    "Below we use the query to load the required data from BigQuery table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52dee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Query on BQ\n",
    "QUERY = \"\"\"\n",
    "SELECT * FROM `fiddler-bq.fiddler_test.churn_prediction_baseline` \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4669dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the query and write result to a pandas data frame\n",
    "Query_Results = bigquery_client.query(QUERY)\n",
    "baseline_df = Query_Results.to_dataframe()\n",
    "\n",
    "#View top few rows of result\n",
    "print(baseline_df.shape)\n",
    "baseline_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5760675",
   "metadata": {},
   "source": [
    "## Add your model to Fiddler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e88a67",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9900b4",
   "metadata": {},
   "source": [
    "We will perform the following steps to get started on the Fiddler platform using the BigQuery data - \n",
    "1. Upload a baseline dataset\n",
    "2. Register your model with Fiddler\n",
    "\n",
    "If you are new to Fiddler and want a detailed explanation on how to setup the fiddler environment please refer to our [Getting Started Guide](https://docs.fiddler.ai/pages/getting-started/product-tour/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dad4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q fiddler-client;\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fiddler as fdl\n",
    "\n",
    "print(f\"Running client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8655c",
   "metadata": {},
   "source": [
    "### Connect to Fiddler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d6d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = #\n",
    "ORG_ID = #\n",
    "AUTH_TOKEN = #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4780f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Fiddler client\n",
    "client = fdl.FiddlerApi(\n",
    "    url=URL,\n",
    "    org_id=ORG_ID,\n",
    "    auth_token=AUTH_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'churn_prediction_bq'\n",
    "\n",
    "client.create_project(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d80347",
   "metadata": {},
   "source": [
    "### Upload a baseline dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44252d",
   "metadata": {},
   "source": [
    "Now that we already have baseline data imported from BigQuery, we can go ahead and upload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b921195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset info object to be used by 'upload_dataset'\n",
    "dataset_info = fdl.DatasetInfo.from_dataframe(baseline_df, max_inferred_cardinality=100)\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704fca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data to fiddler\n",
    "DATASET_ID = 'churn_data'\n",
    "\n",
    "client.upload_dataset(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    dataset={\n",
    "        'baseline': baseline_df\n",
    "    },\n",
    "    info=dataset_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762e03f",
   "metadata": {},
   "source": [
    "### Add your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb8fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify task\n",
    "model_task = 'binary'\n",
    "\n",
    "if model_task == 'regression':\n",
    "    model_task = fdl.ModelTask.REGRESSION\n",
    "    \n",
    "elif model_task == 'binary':\n",
    "    model_task = fdl.ModelTask.BINARY_CLASSIFICATION\n",
    "\n",
    "elif model_task == 'multiclass':\n",
    "    model_task = fdl.ModelTask.MULTICLASS_CLASSIFICATION\n",
    "\n",
    "    \n",
    "# Specify column types\n",
    "target = 'churn'\n",
    "outputs = ['predicted_churn']\n",
    "decision_cols = ['decision']\n",
    "features = ['geography', 'gender', 'age', 'tenure', 'balance', 'numofproducts', 'hascrcard', 'isactivemember', 'estimatedsalary']\n",
    "    \n",
    "# Generate ModelInfo\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=dataset_info,\n",
    "    dataset_id=DATASET_ID,\n",
    "    model_task=model_task,\n",
    "    target=target,\n",
    "    outputs=outputs,\n",
    "    decision_cols=decision_cols,\n",
    "    features=features\n",
    ")\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b68d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 'churn_classifier'\n",
    "\n",
    "client.add_model(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    model_id=MODEL_ID,\n",
    "    model_info=model_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0702263a",
   "metadata": {},
   "source": [
    "Now, that we have added the mode, we can go ahead and publish events to Fiddler platform.\n",
    "\n",
    "To learn how to import data from BigQuery and publish to Fiddler, refer to our [notebook](https://colab.research.google.com/github/fiddler-labs/fiddler-samples/blob/master/content_root/tutorial/integration-examples/bigquery/Fiddler-BigQuery%20Integration%20-%20Event%20Publishing.ipynb) on Event Publishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dcbfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
