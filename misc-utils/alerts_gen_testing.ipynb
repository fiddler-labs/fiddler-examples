{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiddler Alert Testing Notebook\n",
    "This notebook creates a test environment to verify if Fiddler's alert emails successfully reach your inbox despite corporate firewalls and email filtering. We'll:\n",
    "\n",
    "- Create a test project and model with a synthetic dataset\n",
    "- Set up a baseline and various alert rules\n",
    "- Publish events that intentionally violate these alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fiddler Alert Testing Notebook Documentation\n",
    "\n",
    "## Purpose\n",
    "This notebook creates a complete testing environment to verify Fiddler's alert functionality and email delivery. It automates the entire workflow from creating test resources to triggering real alerts that send notifications.\n",
    "\n",
    "## Key Features\n",
    "- Creates a self-contained test project with synthetic data\n",
    "- Configures all available Fiddler alert types\n",
    "- Generates and publishes events that trigger each alert type\n",
    "- Tests email delivery through corporate networks/firewalls\n",
    "\n",
    "## Prerequisites\n",
    "- Fiddler URL\n",
    "- API token (from Credentials tab in Settings)\n",
    "- Email address(es) for receiving test alerts\n",
    "\n",
    "## Alert Types Demonstrated\n",
    "1. **Data Integrity Alerts**\n",
    "   - Range violations (numeric values outside expected bounds)\n",
    "   - Null value violations (unexpected missing data)\n",
    "   - Type violations (data of incorrect type)\n",
    "\n",
    "2. **Data Drift Alerts**\n",
    "   - Distribution shift detection via Jensen-Shannon Distance\n",
    "\n",
    "3. **Traffic Alerts**\n",
    "   - Low volume detection\n",
    "\n",
    "4. **Performance Alerts**\n",
    "   - Model precision degradation\n",
    "\n",
    "5. **Custom Metric Alerts**\n",
    "   - Business-relevant metrics (e.g., revenue loss from churned customers)\n",
    "\n",
    "## Implementation Details\n",
    "- Creates synthetic customer churn dataset with varied column types\n",
    "- Sets appropriate thresholds for each alert type\n",
    "- Configures email notifications for each alert\n",
    "- Publishes batches of violation events to trigger alerts\n",
    "\n",
    "## Usage\n",
    "1. Configure URL, API token and email recipients\n",
    "2. Run all cells sequentially\n",
    "3. Verify alerts in Fiddler UI\n",
    "4. Check email inbox for alert notifications\n",
    "\n",
    "## Troubleshooting\n",
    "If emails aren't received, check spam folders or verify with IT that emails from Fiddler's domain aren't being blocked.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiddler connection details\n",
    "URL = ''  # Your Fiddler URL (e.g., 'https://your_company_name.fiddler.ai')\n",
    "TOKEN = ''  # Your API token from the Credentials tab in Settings\n",
    "\n",
    "# Project and model details\n",
    "PROJECT_NAME = 'alert_test_project'\n",
    "MODEL_NAME = 'alert_test_model'\n",
    "BASELINE_NAME = 'baseline_dataset'\n",
    "\n",
    "# Alert test settings\n",
    "RECIPIENT_EMAIL = ['email1','email2']  # Email address to test alert delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fiddler-client>=3.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from uuid import uuid4\n",
    "import fiddler as fdl\n",
    "\n",
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler()],\n",
    ")\n",
    "\n",
    "# Initialize connection to Fiddler\n",
    "fdl.init(url=URL, token=TOKEN)\n",
    "logging.info(f\"Connected to Fiddler. Client version: {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a Synthetic Dataset with Various Column Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_dataset(rows=500, seed=42):\n",
    "    \"\"\"Generate a synthetic dataset with various column types for alert testing\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Generate a timestamp column\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=30)\n",
    "    timestamps = [start_date + timedelta(\n",
    "        seconds=random.randint(0, int((end_date - start_date).total_seconds()))) \n",
    "        for _ in range(rows)]\n",
    "    \n",
    "    # Convert timestamps to milliseconds\n",
    "    timestamp_ms = [int(ts.timestamp() * 1000) for ts in timestamps]\n",
    "    \n",
    "    # Generate data\n",
    "    data = {\n",
    "        # Integer feature\n",
    "        'age': np.random.randint(18, 80, rows),\n",
    "        \n",
    "        # Float feature with 2 decimal places\n",
    "        'income': np.round(np.random.uniform(20000, 200000, rows), 2),\n",
    "        \n",
    "        # Categorical feature with 3 categories\n",
    "        'location': np.random.choice(['Urban', 'Suburban', 'Rural'], rows),\n",
    "        \n",
    "        # Boolean feature\n",
    "        'has_subscription': np.random.choice([True, False], rows),\n",
    "        \n",
    "        # String feature\n",
    "        'customer_id': [f\"CUST-{str(uuid4())[:8]}\" for _ in range(rows)],\n",
    "        \n",
    "        # Target column (binary)\n",
    "        'churn': np.random.choice([0, 1], rows, p=[0.8, 0.2]),\n",
    "        \n",
    "        # Model prediction (probability)\n",
    "        'predicted_churn': np.random.beta(2, 5, rows),\n",
    "        \n",
    "        # Timestamp column\n",
    "        'timestamp': timestamp_ms\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate baseline dataset\n",
    "baseline_df = generate_synthetic_dataset(rows=500)\n",
    "print(f\"Generated baseline dataset with {len(baseline_df)} rows\")\n",
    "baseline_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Project, Model, and Upload the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or get the project\n",
    "try:\n",
    "    project = fdl.Project(name=PROJECT_NAME).create()\n",
    "    print(f'Created new project with id = {project.id} and name = {project.name}')\n",
    "except fdl.Conflict:\n",
    "    project = fdl.Project.from_name(name=PROJECT_NAME)\n",
    "    print(f'Using existing project with id = {project.id} and name = {project.name}')\n",
    "\n",
    "# Define the model spec\n",
    "model_spec = fdl.ModelSpec(\n",
    "    inputs=['age', 'income', 'location', 'has_subscription'],\n",
    "    outputs=['predicted_churn'],\n",
    "    targets=['churn'],\n",
    "    metadata=['customer_id', 'timestamp']\n",
    ")\n",
    "\n",
    "# Set model task parameters\n",
    "model_task = fdl.ModelTask.BINARY_CLASSIFICATION\n",
    "task_params = fdl.ModelTaskParams(target_class_order=[0, 1])\n",
    "\n",
    "# Create the model\n",
    "try:\n",
    "    model = fdl.Model.from_data(\n",
    "        name=MODEL_NAME,\n",
    "        project_id=project.id,\n",
    "        source=baseline_df,\n",
    "        spec=model_spec,\n",
    "        task=model_task,\n",
    "        task_params=task_params,\n",
    "        event_id_col='customer_id',\n",
    "        event_ts_col='timestamp'\n",
    "    )\n",
    "    model.create()\n",
    "    print(f'Created new model with id = {model.id} and name = {model.name}')\n",
    "except fdl.Conflict:\n",
    "    model = fdl.Model.from_name(name=MODEL_NAME, project_id=project.id)\n",
    "    print(f'Using existing model with id = {model.id} and name = {model.name}')\n",
    "\n",
    "# Upload the baseline dataset\n",
    "baseline_publish_job = model.publish(\n",
    "    source=baseline_df,\n",
    "    environment=fdl.EnvType.PRE_PRODUCTION,\n",
    "    dataset_name=BASELINE_NAME\n",
    ")\n",
    "print(f'Initiated baseline upload with Job ID = {baseline_publish_job.id}')\n",
    "\n",
    "# Wait for the baseline upload to complete\n",
    "baseline_publish_job.wait()\n",
    "print(\"Baseline upload completed successfully\")\n",
    "\n",
    "# Get the dataset\n",
    "dataset = fdl.Dataset.from_name(name=BASELINE_NAME, model_id=model.id)\n",
    "print(f'Retrieved dataset with id = {dataset.id} and name = {dataset.name}')\n",
    "\n",
    "baseline = fdl.Baseline.from_name(name=BASELINE_NAME, model_id=model.id)\n",
    "print(f'Retrieved baseline with id = {baseline.id} and name = {baseline.name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Alert Rules\n",
    "This section covers all the alert rules availble in Fiddler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create alerts and set notification\n",
    "def create_alert_with_notification(alert_rule):\n",
    "    try:\n",
    "        alert_rule.create()\n",
    "        print(f'Created alert rule: {alert_rule.name}')\n",
    "        \n",
    "        # Set email notification\n",
    "        alert_rule.set_notification_config(emails=RECIPIENT_EMAIL)\n",
    "        print(f'Set email notification for {alert_rule.name} to {RECIPIENT_EMAIL}')\n",
    "    except fdl.Conflict:\n",
    "        print(f'Alert rule {alert_rule.name} already exists')\n",
    "\n",
    "# 1. Data Integrity Alert - Range Violation (age)\n",
    "range_alert = fdl.AlertRule(\n",
    "    name='Age Range Violation Alert',\n",
    "    model_id=model.id,\n",
    "    metric_id='range_violation_count',\n",
    "    bin_size=fdl.BinSize.HOUR,\n",
    "    compare_to=fdl.CompareTo.RAW_VALUE,\n",
    "    priority=fdl.Priority.HIGH,\n",
    "    warning_threshold=1,\n",
    "    critical_threshold=3,\n",
    "    condition=fdl.AlertCondition.GREATER,\n",
    "    columns=['age']\n",
    ")\n",
    "create_alert_with_notification(range_alert)\n",
    "\n",
    "# 2. Data Integrity Alert - Null Value Violation\n",
    "null_alert = fdl.AlertRule(\n",
    "    name='Null Value Violation Alert',\n",
    "    model_id=model.id,\n",
    "    metric_id='null_violation_percentage',\n",
    "    bin_size=fdl.BinSize.HOUR,\n",
    "    compare_to=fdl.CompareTo.RAW_VALUE,\n",
    "    priority=fdl.Priority.HIGH,\n",
    "    warning_threshold=5,\n",
    "    critical_threshold=10,\n",
    "    condition=fdl.AlertCondition.GREATER,\n",
    "    columns=['income']\n",
    ")\n",
    "create_alert_with_notification(null_alert)\n",
    "\n",
    "# 3. Data Integrity Alert - Type Violation\n",
    "type_alert = fdl.AlertRule(\n",
    "    name='Location Type Violation Alert',\n",
    "    model_id=model.id,\n",
    "    metric_id='type_violation_count',\n",
    "    bin_size=fdl.BinSize.HOUR,\n",
    "    compare_to=fdl.CompareTo.RAW_VALUE,\n",
    "    priority=fdl.Priority.HIGH,\n",
    "    warning_threshold=1,\n",
    "    critical_threshold=3,\n",
    "    condition=fdl.AlertCondition.GREATER,\n",
    "    columns=['location']\n",
    ")\n",
    "create_alert_with_notification(type_alert)\n",
    "\n",
    "# 4. Data Drift Alert - Jensen-Shannon Distance\n",
    "jsd_alert = fdl.AlertRule(\n",
    "    name='Age Data Drift Alert',\n",
    "    model_id=model.id,\n",
    "    metric_id='jsd',\n",
    "    bin_size=fdl.BinSize.HOUR,\n",
    "    compare_to=fdl.CompareTo.RAW_VALUE,\n",
    "    priority=fdl.Priority.MEDIUM,\n",
    "    warning_threshold=0.1,\n",
    "    critical_threshold=0.2,\n",
    "    condition=fdl.AlertCondition.GREATER,\n",
    "    columns=['age'],\n",
    "    baseline_id=baseline.id,\n",
    ")\n",
    "create_alert_with_notification(jsd_alert)\n",
    "\n",
    "# 5. Traffic Alert\n",
    "traffic_alert = fdl.AlertRule(\n",
    "    name='Low Traffic Alert',\n",
    "    model_id=model.id,\n",
    "    metric_id='traffic',\n",
    "    bin_size=fdl.BinSize.HOUR,\n",
    "    compare_to=fdl.CompareTo.RAW_VALUE,\n",
    "    priority=fdl.Priority.MEDIUM,\n",
    "    warning_threshold=5,\n",
    "    critical_threshold=2,\n",
    "    condition=fdl.AlertCondition.LESSER,  # Alert if traffic is low\n",
    ")\n",
    "create_alert_with_notification(traffic_alert)\n",
    "\n",
    "# 6. Performance Alert - Precision\n",
    "precision_alert = fdl.AlertRule(\n",
    "    name='Low Precision Alert',\n",
    "    model_id=model.id,\n",
    "    metric_id='precision',\n",
    "    bin_size=fdl.BinSize.HOUR,\n",
    "    compare_to=fdl.CompareTo.RAW_VALUE,\n",
    "    priority=fdl.Priority.HIGH,\n",
    "    warning_threshold=0.7,\n",
    "    critical_threshold=0.5,\n",
    "    condition=fdl.AlertCondition.LESSER,  # Alert if precision is low\n",
    ")\n",
    "create_alert_with_notification(precision_alert)\n",
    "\n",
    "# 7. Custom Metric Alert\n",
    "# First, create a custom metric\n",
    "lost_revenue_metric = fdl.CustomMetric(\n",
    "    name='Lost Revenue',\n",
    "    model_id=model.id,\n",
    "    description='Revenue lost for customers who churn',\n",
    "    definition=\"sum(if(\\\"churn\\\"==1, \\\"income\\\", 0))\",\n",
    ")\n",
    "try:\n",
    "    lost_revenue_metric.create()\n",
    "    print(f'Created custom metric: {lost_revenue_metric.name}')\n",
    "except fdl.Conflict:\n",
    "    print(f'Custom metric {lost_revenue_metric.name} already exists')\n",
    "    lost_revenue_metric = fdl.CustomMetric.from_name(\n",
    "        name='Lost Revenue', \n",
    "        model_id=model.id\n",
    "    )\n",
    "\n",
    "# Create alert based on custom metric\n",
    "custom_metric_alert = fdl.AlertRule(\n",
    "    name='High Lost Revenue Alert',\n",
    "    model_id=model.id,\n",
    "    metric_id=lost_revenue_metric.id,\n",
    "    bin_size=fdl.BinSize.HOUR,\n",
    "    compare_to=fdl.CompareTo.RAW_VALUE,\n",
    "    priority=fdl.Priority.HIGH,\n",
    "    warning_threshold=50000,\n",
    "    critical_threshold=100000,\n",
    "    condition=fdl.AlertCondition.GREATER,\n",
    ")\n",
    "create_alert_with_notification(custom_metric_alert)\n",
    "\n",
    "# List all alert rules to verify\n",
    "alert_rules = list(fdl.AlertRule.list(model_id=model.id))\n",
    "print(f\"\\nCreated {len(alert_rules)} alert rules:\")\n",
    "for alert in alert_rules:\n",
    "    print(f\"- {alert.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish Events to trigger alerts\n",
    "These generated events when published will intentionally trigger all the previosuly configured alert rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_violation_events():\n",
    "    \"\"\"Generate events that will trigger various alerts\"\"\"\n",
    "    now = int(time.time() * 1000)  # Current time in milliseconds\n",
    "    \n",
    "    # 1. Range Violation - Create events with ages outside valid range\n",
    "    range_violations = generate_synthetic_dataset(rows=5, seed=100)\n",
    "    range_violations['age'] = np.random.choice([5, 10, 95, 100, 120], 5)  # Invalid ages\n",
    "    range_violations['timestamp'] = [now] * 5\n",
    "    \n",
    "    # 2. Null Violation - Create events with null values\n",
    "    null_violations = generate_synthetic_dataset(rows=10, seed=101)\n",
    "    null_violations.loc[0:4, 'income'] = None\n",
    "    null_violations['timestamp'] = [now] * 10\n",
    "    \n",
    "    # 3. Type Violation - Create events with wrong types\n",
    "    type_violations = generate_synthetic_dataset(rows=5, seed=102)\n",
    "    type_violations['location'] = [1, 2, 3, 4, 5]  # Should be strings, not integers\n",
    "    type_violations['timestamp'] = [now] * 5\n",
    "    \n",
    "    # 4. Data Drift - Create events with significant distribution shift\n",
    "    data_drift = generate_synthetic_dataset(rows=50, seed=103)\n",
    "    data_drift['age'] = np.random.randint(60, 100, 50)  # Shift age distribution\n",
    "    data_drift['timestamp'] = [now] * 50\n",
    "    \n",
    "    # 5. Low Traffic - Already covered by having few events\n",
    "    \n",
    "    # 6. Performance Alert - Create events with wrong predictions\n",
    "    performance_issues = generate_synthetic_dataset(rows=20, seed=104)\n",
    "    performance_issues['churn'] = 1  # All churned\n",
    "    performance_issues['predicted_churn'] = np.random.beta(1, 10, 20)  # Low predictions\n",
    "    performance_issues['timestamp'] = [now] * 20\n",
    "    \n",
    "    # 7. Custom Metric Alert - High income customers who churned\n",
    "    high_lost_revenue = generate_synthetic_dataset(rows=15, seed=105)\n",
    "    high_lost_revenue['churn'] = 1  # All churned\n",
    "    high_lost_revenue['income'] = np.random.uniform(150000, 200000, 15)  # High income\n",
    "    high_lost_revenue['timestamp'] = [now] * 15\n",
    "    \n",
    "    # Combine all datasets\n",
    "    all_violations = pd.concat([\n",
    "        range_violations,\n",
    "        null_violations,\n",
    "        type_violations,\n",
    "        data_drift,\n",
    "        performance_issues,\n",
    "        high_lost_revenue\n",
    "    ])\n",
    "    \n",
    "    return all_violations\n",
    "\n",
    "# Generate events that will trigger alerts\n",
    "violation_events = generate_violation_events()\n",
    "print(f\"Generated {len(violation_events)} violation events\")\n",
    "\n",
    "# Publish events in batches (to avoid timeouts)\n",
    "batch_size = 20\n",
    "for i in range(0, len(violation_events), batch_size):\n",
    "    batch_df = violation_events.iloc[i:i+batch_size].copy()\n",
    "    print(f\"Publishing batch {i//batch_size + 1} with {len(batch_df)} events...\")\n",
    "    events_job = model.publish(source=batch_df)\n",
    "    events_job.wait()\n",
    "    print(f\"Batch {i//batch_size + 1} published successfully\")\n",
    "    time.sleep(2)  # Add a small delay between batches\n",
    "\n",
    "print(\"\\nAll violation events have been published!\")\n",
    "print(\"Alerts should be triggered and emails sent to:\", RECIPIENT_EMAIL)\n",
    "print(\"Please check your inbox for alert notifications.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Alert Status in UI :\n",
    "\n",
    "- Navigate to the Fiddler UI and go to your test project\n",
    "- Click on the 'Alerts' tab to view triggered alerts\n",
    "- Check your email inbox for alert notifications\n",
    "    - If emails haven't arrived:\n",
    "        - check your spam/junk folder\n",
    "        - Verify with your IT department that emails from Fiddler's domain aren't being blocked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
