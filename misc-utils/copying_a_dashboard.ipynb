{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Fiddler Programmatic Dashboards Script\n",
    "\n",
    "Export segments, custom metrics, and charts from one Fiddler model and import them to another model, with support for:\n",
    "* Cross-instance transfers (different Fiddler instances)\n",
    "* Cross-model transfers (different models on same or different instances)\n",
    "* Automatic schema validation with error handling for incompatible columns\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "* Source Fiddler instance URL and API token\n",
    "* Target Fiddler instance URL and API token (can be same as source)\n",
    "* Source and target models must exist\n",
    "* `fiddler_utils` package installed (run cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "# %pip install -q fiddler-client\n",
    "\n",
    "# Install fiddler_utils from parent directory\n",
    "# If not already installed, run from repo root: pip install -e .\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiddler as fdl\n",
    "from fiddler_utils import (\n",
    "    ConnectionManager,\n",
    "    SegmentManager,\n",
    "    CustomMetricManager,\n",
    "    SchemaValidator,\n",
    ")\n",
    "from requests import HTTPError, Response\n",
    "from fiddler.libs.http_client import RequestClient\n",
    "\n",
    "print(f\"Fiddler client version: {fdl.__version__}\")\n",
    "print(\"fiddler_utils: Successfully imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Fiddler Instance\n",
    "SOURCE_URL = \"\"  # e.g., 'https://source.fiddler.ai'\n",
    "SOURCE_TOKEN = \"\"\n",
    "SOURCE_PROJECT_NAME = \"\"\n",
    "SOURCE_MODEL_NAME = \"\"\n",
    "SOURCE_MODEL_VERSION = \"\"  # Optional, leave empty for unversioned models\n",
    "\n",
    "# Target Fiddler Instance (can be same as source)\n",
    "TARGET_URL = \"\"  # e.g., 'https://target.fiddler.ai'\n",
    "TARGET_TOKEN = \"\"\n",
    "TARGET_PROJECT_NAME = \"\"\n",
    "TARGET_MODEL_NAME = \"\"\n",
    "TARGET_MODEL_VERSION = \"\"  # Optional, leave empty for unversioned models\n",
    "\n",
    "# Asset Selection (empty lists = export all)\n",
    "SEGMENTS_TO_EXPORT = []  # e.g., ['segment1', 'segment2'] or [] for all\n",
    "CUSTOM_METRICS_TO_EXPORT = []  # e.g., ['metric1'] or [] for all\n",
    "\n",
    "\n",
    "# Chart Export Options (for bonus section)\n",
    "SOURCE_DASHBOARD_ID = \"\"  # Dashboard UUID to export charts from (leave empty to skip)\n",
    "CHART_IDS_TO_EXPORT = []  # e.g., ['uuid1', 'uuid2'] or [] for none"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup Connections and Initialize Managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup connection manager for handling multiple instances\n",
    "conn_mgr = ConnectionManager(log_level=\"WARNING\")\n",
    "conn_mgr.add(\"source\", url=SOURCE_URL, token=SOURCE_TOKEN)\n",
    "conn_mgr.add(\"target\", url=TARGET_URL, token=TARGET_TOKEN)\n",
    "\n",
    "# Initialize asset managers\n",
    "segment_mgr = SegmentManager()\n",
    "metric_mgr = CustomMetricManager()\n",
    "\n",
    "print(\"âœ“ Connection manager configured\")\n",
    "print(\"âœ“ Asset managers initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "get-models",
   "metadata": {},
   "source": [
    "## Fetch Source and Target Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-models-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to source and get model\n",
    "with conn_mgr.use(\"source\"):\n",
    "    source_project = fdl.Project.from_name(SOURCE_PROJECT_NAME)\n",
    "    source_model_kwargs = {\"project_id\": source_project.id, \"name\": SOURCE_MODEL_NAME}\n",
    "    if SOURCE_MODEL_VERSION:\n",
    "        source_model_kwargs[\"version\"] = SOURCE_MODEL_VERSION\n",
    "\n",
    "    source_model = fdl.Model.from_name(**source_model_kwargs)\n",
    "    print(f\"Source model: {source_model.name} (ID: {source_model.id})\")\n",
    "\n",
    "# Connect to target and get model\n",
    "with conn_mgr.use(\"target\"):\n",
    "    target_project = fdl.Project.from_name(TARGET_PROJECT_NAME)\n",
    "    target_model_kwargs = {\"project_id\": target_project.id, \"name\": TARGET_MODEL_NAME}\n",
    "    if TARGET_MODEL_VERSION:\n",
    "        target_model_kwargs[\"version\"] = TARGET_MODEL_VERSION\n",
    "\n",
    "    target_model = fdl.Model.from_name(**target_model_kwargs)\n",
    "    print(f\"Target model: {target_model.name} (ID: {target_model.id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "schema",
   "metadata": {},
   "source": [
    "## Schema Comparison\n",
    "\n",
    "Compare source and target model schemas to identify potential compatibility issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "schema-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get schema information from both models\n",
    "with conn_mgr.use(\"source\"):\n",
    "    source_columns = SchemaValidator.get_model_columns(source_model)\n",
    "    print(f\"Source model has {len(source_columns)} columns\")\n",
    "\n",
    "with conn_mgr.use(\"target\"):\n",
    "    target_columns = SchemaValidator.get_model_columns(target_model)\n",
    "    print(f\"Target model has {len(target_columns)} columns\")\n",
    "\n",
    "with conn_mgr.use(\"source\"):\n",
    "    comparison = SchemaValidator.compare_schemas(source_model, target_model)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SCHEMA COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nCommon columns: {len(comparison.in_both)}\")\n",
    "\n",
    "if comparison.only_in_source:\n",
    "    print(\n",
    "        f\"\\nâš ï¸  Columns in SOURCE but MISSING in TARGET ({len(comparison.only_in_source)}):\"\n",
    "    )\n",
    "    for col in sorted(comparison.only_in_source):\n",
    "        col_info = source_columns[col]\n",
    "        print(f\"  - {col} ({col_info.role}, {col_info.data_type})\")\n",
    "else:\n",
    "    print(\"\\nâœ… No missing columns - all source columns exist in target\")\n",
    "\n",
    "if comparison.only_in_target:\n",
    "    print(\n",
    "        f\"\\nðŸ“‹ Columns in TARGET but NOT in SOURCE ({len(comparison.only_in_target)}):\"\n",
    "    )\n",
    "    for col in sorted(list(comparison.only_in_target)[:5]):\n",
    "        col_info = target_columns[col]\n",
    "        print(f\"  - {col} ({col_info.role}, {col_info.data_type})\")\n",
    "    if len(comparison.only_in_target) > 5:\n",
    "        print(f\"  ... and {len(comparison.only_in_target) - 5} more\")\n",
    "\n",
    "if comparison.type_mismatches:\n",
    "    print(f\"\\nâš ï¸  Data type DIFFERENCES ({len(comparison.type_mismatches)}):\")\n",
    "    for col, (source_type, target_type) in list(comparison.type_mismatches.items())[:5]:\n",
    "        print(f\"  - {col}: source={source_type} â†’ target={target_type}\")\n",
    "else:\n",
    "    print(\"\\nâœ… All common columns have matching data types\")\n",
    "\n",
    "print(\n",
    "    f\"\\n{'âœ…' if comparison.is_compatible else 'âš ï¸ '} Schema compatibility: {comparison.is_compatible}\"\n",
    ")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995afaf-f144-4f51-b93b-03b84e73d77f",
   "metadata": {},
   "source": [
    "## Export Segments\n",
    "\n",
    "Export segments from source model using `SegmentManager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-segments-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPORTING SEGMENTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with conn_mgr.use(\"source\"):\n",
    "    # Export segments (filtered by name if specified)\n",
    "    exported_segments = segment_mgr.export_assets(\n",
    "        model_id=source_model.id,\n",
    "        names=SEGMENTS_TO_EXPORT if SEGMENTS_TO_EXPORT else None,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nâœ“ Exported {len(exported_segments)} segment(s)\")\n",
    "\n",
    "    for seg_data in exported_segments:\n",
    "        print(f\"\\n  Segment: {seg_data.name}\")\n",
    "        print(f\"    Definition: {seg_data.data['definition']}\")\n",
    "        print(f\"    Referenced columns: {seg_data.referenced_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-segments",
   "metadata": {},
   "source": [
    "## Import Segments\n",
    "\n",
    "Import segments to target model with automatic validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-segments-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"IMPORTING SEGMENTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with conn_mgr.use(\"target\"):\n",
    "    # Import with validation and error handling\n",
    "    segment_result = segment_mgr.import_assets(\n",
    "        target_model_id=target_model.id,\n",
    "        assets=exported_segments,\n",
    "        validate=True,\n",
    "        dry_run=False,\n",
    "        skip_invalid=True,\n",
    "        overwrite=False,\n",
    "    )\n",
    "\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"  âœ… Successfully imported: {segment_result.successful}\")\n",
    "    print(f\"  ðŸ”„ Skipped (existing): {segment_result.skipped_existing}\")\n",
    "    print(f\"  âŠ˜  Skipped (invalid): {segment_result.skipped_invalid}\")\n",
    "    print(f\"  âŒ Failed: {segment_result.failed}\")\n",
    "\n",
    "    if segment_result.errors:\n",
    "        print(\"\\n  Errors:\")\n",
    "        for name, error in segment_result.errors:\n",
    "            print(f\"    - {name}: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-metrics",
   "metadata": {},
   "source": [
    "## Export Custom Metrics\n",
    "\n",
    "Export custom metrics from source model using `CustomMetricManager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-metrics-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPORTING CUSTOM METRICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with conn_mgr.use(\"source\"):\n",
    "    # Export custom metrics (filtered by name if specified)\n",
    "    exported_metrics = metric_mgr.export_assets(\n",
    "        model_id=source_model.id,\n",
    "        names=CUSTOM_METRICS_TO_EXPORT if CUSTOM_METRICS_TO_EXPORT else None,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nâœ“ Exported {len(exported_metrics)} custom metric(s)\")\n",
    "\n",
    "    for metric_data in exported_metrics:\n",
    "        print(f\"\\n  Metric: {metric_data.name}\")\n",
    "        print(f\"    Definition: {metric_data.data['definition']}\")\n",
    "        print(f\"    Referenced columns: {metric_data.referenced_columns}\")\n",
    "\n",
    "        # Show complexity info\n",
    "        metadata = metric_data.data[\"metadata\"]\n",
    "        metric_type = \"Aggregation\" if metadata[\"is_aggregation\"] else \"Simple\"\n",
    "        print(f\"    Type: {metric_type}\")\n",
    "        if metadata[\"functions_used\"]:\n",
    "            print(f\"    Functions: {', '.join(metadata['functions_used'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-metrics",
   "metadata": {},
   "source": [
    "## Import Custom Metrics\n",
    "\n",
    "Import custom metrics to target model with automatic validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-metrics-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"IMPORTING CUSTOM METRICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with conn_mgr.use(\"target\"):\n",
    "    # Import with validation and error handling\n",
    "    metric_result = metric_mgr.import_assets(\n",
    "        target_model_id=target_model.id,\n",
    "        assets=exported_metrics,\n",
    "        validate=True,\n",
    "        dry_run=False,\n",
    "        skip_invalid=True,\n",
    "        overwrite=False,\n",
    "    )\n",
    "\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"  âœ… Successfully imported: {metric_result.successful}\")\n",
    "    print(f\"  ðŸ”„ Skipped (existing): {metric_result.skipped_existing}\")\n",
    "    print(f\"  âŠ˜  Skipped (invalid): {metric_result.skipped_invalid}\")\n",
    "    print(f\"  âŒ Failed: {metric_result.failed}\")\n",
    "\n",
    "    if metric_result.errors:\n",
    "        print(\"\\n  Errors:\")\n",
    "        for name, error in metric_result.errors:\n",
    "            print(f\"    - {name}: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPORT/IMPORT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nSegments:\")\n",
    "print(f\"  Total exported: {len(exported_segments)}\")\n",
    "print(f\"  Successfully imported: {segment_result.successful}\")\n",
    "print(f\"  Skipped (existing): {segment_result.skipped_existing}\")\n",
    "print(f\"  Skipped (invalid): {segment_result.skipped_invalid}\")\n",
    "print(f\"  Failed: {segment_result.failed}\")\n",
    "\n",
    "print(\"\\nCustom Metrics:\")\n",
    "print(f\"  Total exported: {len(exported_metrics)}\")\n",
    "print(f\"  Successfully imported: {metric_result.successful}\")\n",
    "print(f\"  Skipped (existing): {metric_result.skipped_existing}\")\n",
    "print(f\"  Skipped (invalid): {metric_result.skipped_invalid}\")\n",
    "print(f\"  Failed: {metric_result.failed}\")\n",
    "\n",
    "total_success = segment_result.successful + metric_result.successful\n",
    "total_skipped_existing = (\n",
    "    segment_result.skipped_existing + metric_result.skipped_existing\n",
    ")\n",
    "total_skipped_invalid = segment_result.skipped_invalid + metric_result.skipped_invalid\n",
    "total_failed = segment_result.failed + metric_result.failed\n",
    "total_exported = len(exported_segments) + len(exported_metrics)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"OVERALL: {total_success}/{total_exported} assets successfully imported\")\n",
    "if total_skipped_existing > 0:\n",
    "    print(f\"  {total_skipped_existing} skipped (already exist on target)\")\n",
    "if total_skipped_invalid > 0:\n",
    "    print(f\"  {total_skipped_invalid} skipped (validation errors)\")\n",
    "if total_failed > 0:\n",
    "    print(f\"  {total_failed} failed during import\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charts-header",
   "metadata": {},
   "source": [
    "## Export/Import Charts\n",
    "\n",
    "Demonstrate cross-instance chart transfer using `ChartManager`.\n",
    "\n",
    "This section shows how fiddler_utils simplifies chart transfers.\n",
    "\n",
    "**To use this section:**\n",
    "1. Set `SOURCE_DASHBOARD_ID` in the configuration cell above (find dashboard ID in Fiddler UI URL)\n",
    "2. OR set `CHART_IDS_TO_EXPORT` to manually specify chart UUIDs\n",
    "3. Run the cells below to export and import charts\n",
    "\n",
    "**Note:** Chart API uses unofficial Fiddler endpoints and may change without notice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charts-init",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiddler_utils import ChartManager\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INITIALIZING CHART MANAGERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create separate managers for source and target\n",
    "# Each needs its own URL/token for RequestClient\n",
    "source_chart_mgr = ChartManager(url=SOURCE_URL, token=SOURCE_TOKEN)\n",
    "target_chart_mgr = ChartManager(url=TARGET_URL, token=TARGET_TOKEN)\n",
    "\n",
    "print(\"\\nâœ“ Source ChartManager initialized\")\n",
    "print(\"âœ“ Target ChartManager initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charts-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPORTING CHARTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Determine export method\n",
    "if SOURCE_DASHBOARD_ID:\n",
    "    print(f\"\\nExporting charts from dashboard: {SOURCE_DASHBOARD_ID}\")\n",
    "elif CHART_IDS_TO_EXPORT:\n",
    "    print(f\"\\nExporting {len(CHART_IDS_TO_EXPORT)} charts by ID\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No SOURCE_DASHBOARD_ID or CHART_IDS_TO_EXPORT specified.\")\n",
    "    print(\"   Set one of these in the configuration cell to export charts.\")\n",
    "    exported_charts = []\n",
    "\n",
    "if SOURCE_DASHBOARD_ID or CHART_IDS_TO_EXPORT:\n",
    "    with conn_mgr.use(\"source\"):\n",
    "        try:\n",
    "            # Export charts using dashboard_id or chart_ids\n",
    "            exported_charts = source_chart_mgr.export_charts(\n",
    "                dashboard_id=SOURCE_DASHBOARD_ID if SOURCE_DASHBOARD_ID else None,\n",
    "                chart_ids=CHART_IDS_TO_EXPORT if CHART_IDS_TO_EXPORT else None,\n",
    "            )\n",
    "\n",
    "            print(f\"\\nâœ“ Exported {len(exported_charts)} chart(s)\\n\")\n",
    "\n",
    "            # Display exported chart details\n",
    "            for i, chart in enumerate(exported_charts, 1):\n",
    "                print(f\"{i}. {chart.get('title', 'Untitled')}\")\n",
    "                print(f\"   Type: {chart.get('query_type', 'unknown')}\")\n",
    "\n",
    "                # Show data source info\n",
    "                data_source = chart.get(\"data_source\", {})\n",
    "                queries = data_source.get(\"queries\", [])\n",
    "\n",
    "                if queries:\n",
    "                    # Show first query details for monitoring charts\n",
    "                    query = queries[0]\n",
    "                    metric_info = []\n",
    "\n",
    "                    if \"baseline_name\" in query:\n",
    "                        metric_info.append(f\"baseline={query['baseline_name']}\")\n",
    "                    if query.get(\"metric_type\") == \"custom\":\n",
    "                        metric_info.append(\n",
    "                            f\"custom_metric={query.get('metric', 'N/A')}\"\n",
    "                        )\n",
    "                    if \"segment\" in query and query[\"segment\"]:\n",
    "                        metric_info.append(f\"segment={query['segment']}\")\n",
    "\n",
    "                    if metric_info:\n",
    "                        print(f\"   Dependencies: {', '.join(metric_info)}\")\n",
    "                print()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Failed to export charts: {e}\")\n",
    "            exported_charts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charts-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not exported_charts:\n",
    "    print(\"\\nâŠ˜ No charts to import. Skipping import.\")\n",
    "    chart_result = {\"successful\": 0, \"failed\": 0, \"errors\": []}\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"IMPORTING CHARTS\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    with conn_mgr.use(\"target\"):\n",
    "        # Perform actual import\n",
    "        chart_result = target_chart_mgr.import_charts(\n",
    "            target_project_id=target_project.id,\n",
    "            target_model_id=target_model.id,\n",
    "            charts=exported_charts,\n",
    "            validate=True,\n",
    "            dry_run=False,  # Actually create charts\n",
    "        )\n",
    "\n",
    "        print(\"\\nResults:\")\n",
    "        print(f\"  âœ… Successfully imported: {chart_result['successful']}\")\n",
    "        print(f\"  âŒ Failed: {chart_result['failed']}\")\n",
    "\n",
    "        if chart_result.get(\"errors\"):\n",
    "            print(f\"\\n  Errors encountered:\")\n",
    "            for title, error in chart_result[\"errors\"]:\n",
    "                print(f\"    â€¢ {title}\")\n",
    "                print(f\"      {error}\")\n",
    "\n",
    "        # Update overall summary\n",
    "        if chart_result[\"successful\"] > 0:\n",
    "            print(\n",
    "                f\"\\nâœ“ Successfully imported {chart_result['successful']} chart(s) to target model\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dde93a-b09b-4f46-b8d7-58999f7a39e8",
   "metadata": {},
   "source": [
    "## Package Charts Into a New Default Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b81646a-e6f8-4fab-ac06-fbebee909295",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = RequestClient(\n",
    "    TARGET_URL,\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {TARGET_TOKEN}\",\n",
    "    },\n",
    ")\n",
    "\n",
    "def create_dashboard(\n",
    "    project_name: str,\n",
    "    model_name: str,\n",
    "    charts: list,\n",
    "    dashboard: dict,\n",
    ") -> dict:\n",
    "    dashboards_url = \"v2/dashboards\"\n",
    "\n",
    "    dashboard[\"organization_name\"] = fdl.conn.organization_name\n",
    "    dashboard[\"project_name\"] = project_name\n",
    "\n",
    "    try:\n",
    "        # Map the chart titles to uuids\n",
    "        chart_titles = {chart[\"title\"]: chart[\"id\"] for chart in charts}\n",
    "        # Get model name from yaml config\n",
    "        model_name = dashboard.get(\"model_name\", None)\n",
    "        dashboard.pop(\"model_name\", None)\n",
    "\n",
    "        # Replace chart titles with uuids in dashboard yaml\n",
    "        for index, saved_chart in enumerate(dashboard.get(\"layouts\")):\n",
    "            chart_title = saved_chart.get(\"chart_title\")\n",
    "            saved_chart[\"chart_uuid\"] = chart_titles.get(chart_title)\n",
    "            saved_chart.pop(\"chart_title\", None)\n",
    "\n",
    "        dashboard_resp: Response = client.post(url=dashboards_url, data=dashboard)\n",
    "        \n",
    "        project = fdl.Project.get_or_create(name=project_name)\n",
    "        model = fdl.Model.from_name(name=model_name, project_id=project.id)\n",
    "\n",
    "        # Set the created dashboard as default\n",
    "        default_dashboard_url = f\"v3/models/{model.id}/default-dashboard\"\n",
    "\n",
    "        payload = {}\n",
    "        payload[\"dashboard_uuid\"] = dashboard_resp.json()[\"data\"].get(\"uuid\")\n",
    "\n",
    "        client.put(url=default_dashboard_url, data=payload)\n",
    "\n",
    "        return dashboard_resp\n",
    "\n",
    "    except HTTPError as hex:\n",
    "        print(\n",
    "            f\"HTTPError occured: {hex.response.text} with error code {hex.response.status_code}\"\n",
    "        )\n",
    "        raise hex\n",
    "\n",
    "\n",
    "def generate_chart_layout(chart_title, x, y):\n",
    "    return {\n",
    "        \"chart_title\": chart_title,\n",
    "        \"grid_props\": {\n",
    "            \"height\": 1,\n",
    "            \"position_x\": x,\n",
    "            \"position_y\": y,\n",
    "            \"width\": 1,\n",
    "        },\n",
    "    }\n",
    "\n",
    "def generate_chart_layouts(chart_titles):\n",
    "    chart_layouts = []\n",
    "    \n",
    "    for i in range(len(chart_titles)):\n",
    "        chart_title = chart_titles[i]\n",
    "        x = i % 2\n",
    "        y = i // 2\n",
    "        chart_layouts.append(generate_chart_layout(chart_title, x, y))\n",
    "\n",
    "    return chart_layouts\n",
    "\n",
    "\n",
    "charts_url = f\"/v3/charts?filter=%7B%22condition%22:%22AND%22,%22rules%22:[%7B%22field%22:%22project_name%22,%22operator%22:%22equal%22,%22value%22:%22{TARGET_PROJECT_NAME}%22%7D]%7D&search=&offset=0&limit=40\"\n",
    "charts_response = client.get(url=charts_url)\n",
    "charts = charts_response.json().get(\"data\").get(\"items\")\n",
    "\n",
    "\n",
    "# List out chart titles (out of order)\n",
    "chart_titles = {chart[\"title\"]: chart[\"id\"] for chart in charts}\n",
    "\n",
    "\n",
    "# Dashboards definition with chart order (YAML version below)\n",
    "dashboard = {\n",
    "    \"layouts\": generate_chart_layouts(list(chart_titles.keys())),\n",
    "    \"model_name\": TARGET_MODEL_NAME,\n",
    "    \"options\": {\n",
    "        \"filters\": {\"time_label\": \"6m\", \"time_zone\": \"America/Los_Angeles\"}\n",
    "    },\n",
    "    \"organization_name\": fdl.conn.organization_name,\n",
    "    \"project_name\": TARGET_PROJECT_NAME,\n",
    "    \"title\": \"test_dashboard\",\n",
    "}\n",
    "\n",
    "# Run command to create dashboard(s) according to order in the yaml definition\n",
    "dashboard_response = create_dashboard(\n",
    "    project_name=TARGET_PROJECT_NAME, model_name=TARGET_MODEL_NAME, charts=charts, dashboard=dashboard\n",
    ")\n",
    "\n",
    "project = fdl.Project.from_name(TARGET_PROJECT_NAME)\n",
    "model = fdl.Model.from_name(name=TARGET_MODEL_NAME, project_id=project.id)\n",
    "\n",
    "# # Set the created dashboard as default\n",
    "default_dashboard_url = f\"v3/models/{model.id}/default-dashboard\"\n",
    "\n",
    "payload = {}\n",
    "payload[\"dashboard_uuid\"] = dashboard_response.json()['data']['uuid']\n",
    "\n",
    "default_dashboard_response = client.put(url=default_dashboard_url, data=payload)\n",
    "\n",
    "if default_dashboard_response.status_code == 200:\n",
    "    print(f\"  âœ… Successfully created new default dashboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c685e19-b736-41e2-8639-81b2701514e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1659c24-aa38-4367-8f90-f02c27fe4151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
