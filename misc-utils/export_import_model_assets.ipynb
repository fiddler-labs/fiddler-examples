{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# Export/Import Fiddler Assets\n",
        "\n",
        "Export segments and custom metrics from one Fiddler model and import them to another model, with support for:\n",
        "* Cross-instance transfers (different Fiddler instances)\n",
        "* Cross-model transfers (different models on same or different instances)\n",
        "* Automatic schema validation with error handling for incompatible columns\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "* Source Fiddler instance URL and API token\n",
        "* Target Fiddler instance URL and API token (can be same as source)\n",
        "* Source and target models must exist\n",
        "* `fiddler_utils` package installed (run cell below)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "install",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "%pip install -q fiddler-client\n",
        "\n",
        "# Install fiddler_utils from parent directory\n",
        "# If not already installed, run from repo root: pip install -e .\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, \"..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "imports",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fiddler client version: 3.10.0\n",
            "fiddler_utils: Successfully imported\n"
          ]
        }
      ],
      "source": [
        "import fiddler as fdl\n",
        "from fiddler_utils import (\n",
        "    ConnectionManager,\n",
        "    SegmentManager,\n",
        "    CustomMetricManager,\n",
        "    SchemaValidator,\n",
        ")\n",
        "\n",
        "print(f\"Fiddler client version: {fdl.__version__}\")\n",
        "print(\"fiddler_utils: Successfully imported\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "config",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "config-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Source Fiddler Instance\n",
        "SOURCE_URL = \"https://demo.fiddler.ai\"  # e.g., 'https://source.fiddler.ai'\n",
        "SOURCE_TOKEN = \"bviEN-TNK5LhJ-ObZNMboMCnm99LxG7eVSDwjJzX_es\"\n",
        "SOURCE_PROJECT_NAME = \"bank_churn\"\n",
        "SOURCE_MODEL_NAME = \"churn_classifier\"\n",
        "SOURCE_MODEL_VERSION = \"\"  # Optional, leave empty for unversioned models\n",
        "\n",
        "# Target Fiddler Instance (can be same as source)\n",
        "TARGET_URL = \"https://preprod.cloud.fiddler.ai\"  # e.g., 'https://target.fiddler.ai'\n",
        "TARGET_TOKEN = \"hqvUV7r8-WUkMkjvKHbvI_sVpxRd9DJLKX6PCloRwVk\"\n",
        "TARGET_PROJECT_NAME = \"quickstart_examples\"\n",
        "TARGET_MODEL_NAME = \"bank_churn_simple_monitoring_v2\"\n",
        "TARGET_MODEL_VERSION = \"\"  # Optional, leave empty for unversioned models\n",
        "\n",
        "# Asset Selection (empty lists = export all)\n",
        "SEGMENTS_TO_EXPORT = []  # e.g., ['segment1', 'segment2'] or [] for all\n",
        "CUSTOM_METRICS_TO_EXPORT = []  # e.g., ['metric1'] or [] for all\n",
        "\n",
        "\n",
        "# Chart Export Options (for bonus section)\n",
        "SOURCE_DASHBOARD_ID = \"dbd97cc9-3cfb-4d22-8159-a025ced9b455\"  # Dashboard UUID to export charts from (leave empty to skip)\n",
        "CHART_IDS_TO_EXPORT = []  # e.g., ['uuid1', 'uuid2'] or [] for none"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup",
      "metadata": {},
      "source": [
        "## Setup Connections and Initialize Managers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "setup-cell",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Connection manager configured\n",
            "‚úì Asset managers initialized\n"
          ]
        }
      ],
      "source": [
        "# Setup connection manager for handling multiple instances\n",
        "conn_mgr = ConnectionManager(log_level=\"WARNING\")\n",
        "conn_mgr.add(\"source\", url=SOURCE_URL, token=SOURCE_TOKEN)\n",
        "conn_mgr.add(\"target\", url=TARGET_URL, token=TARGET_TOKEN)\n",
        "\n",
        "# Initialize asset managers\n",
        "segment_mgr = SegmentManager()\n",
        "metric_mgr = CustomMetricManager()\n",
        "\n",
        "print(\"‚úì Connection manager configured\")\n",
        "print(\"‚úì Asset managers initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "get-models",
      "metadata": {},
      "source": [
        "## Fetch Source and Target Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "get-models-cell",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source model: churn_classifier (ID: 8dea99c0-6724-46df-a2de-5d542ed7f272)\n",
            "Target model: bank_churn_simple_monitoring_v2 (ID: 31f97c25-fd0b-44ad-9860-9077747a0119)\n"
          ]
        }
      ],
      "source": [
        "# Connect to source and get model\n",
        "with conn_mgr.use(\"source\"):\n",
        "    source_project = fdl.Project.from_name(SOURCE_PROJECT_NAME)\n",
        "    source_model_kwargs = {\"project_id\": source_project.id, \"name\": SOURCE_MODEL_NAME}\n",
        "    if SOURCE_MODEL_VERSION:\n",
        "        source_model_kwargs[\"version\"] = SOURCE_MODEL_VERSION\n",
        "\n",
        "    source_model = fdl.Model.from_name(**source_model_kwargs)\n",
        "    print(f\"Source model: {source_model.name} (ID: {source_model.id})\")\n",
        "\n",
        "# Connect to target and get model\n",
        "with conn_mgr.use(\"target\"):\n",
        "    target_project = fdl.Project.from_name(TARGET_PROJECT_NAME)\n",
        "    target_model_kwargs = {\"project_id\": target_project.id, \"name\": TARGET_MODEL_NAME}\n",
        "    if TARGET_MODEL_VERSION:\n",
        "        target_model_kwargs[\"version\"] = TARGET_MODEL_VERSION\n",
        "\n",
        "    target_model = fdl.Model.from_name(**target_model_kwargs)\n",
        "    print(f\"Target model: {target_model.name} (ID: {target_model.id})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "schema",
      "metadata": {},
      "source": [
        "## Schema Comparison\n",
        "\n",
        "Compare source and target model schemas to identify potential compatibility issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "schema-cell",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source model has 13 columns\n",
            "Target model has 14 columns\n",
            "\n",
            "============================================================\n",
            "SCHEMA COMPARISON\n",
            "============================================================\n",
            "\n",
            "Common columns: 11\n",
            "\n",
            "‚ö†Ô∏è  Columns in SOURCE but MISSING in TARGET (2):\n",
            "  - decisions (ColumnRole.DECISION, None)\n",
            "  - probability_churn (ColumnRole.OUTPUT, None)\n",
            "\n",
            "üìã Columns in TARGET but NOT in SOURCE (3):\n",
            "  - customer_id (ColumnRole.METADATA, None)\n",
            "  - predicted_churn (ColumnRole.OUTPUT, None)\n",
            "  - timestamp (ColumnRole.METADATA, None)\n",
            "\n",
            "‚úÖ All common columns have matching data types\n",
            "\n",
            "‚ö†Ô∏è  Schema compatibility: False\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Get schema information from both models\n",
        "with conn_mgr.use(\"source\"):\n",
        "    source_columns = SchemaValidator.get_model_columns(source_model)\n",
        "    print(f\"Source model has {len(source_columns)} columns\")\n",
        "\n",
        "with conn_mgr.use(\"target\"):\n",
        "    target_columns = SchemaValidator.get_model_columns(target_model)\n",
        "    print(f\"Target model has {len(target_columns)} columns\")\n",
        "\n",
        "with conn_mgr.use(\"source\"):\n",
        "    comparison = SchemaValidator.compare_schemas(source_model, target_model)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SCHEMA COMPARISON\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nCommon columns: {len(comparison.in_both)}\")\n",
        "\n",
        "if comparison.only_in_source:\n",
        "    print(\n",
        "        f\"\\n‚ö†Ô∏è  Columns in SOURCE but MISSING in TARGET ({len(comparison.only_in_source)}):\"\n",
        "    )\n",
        "    for col in sorted(comparison.only_in_source):\n",
        "        col_info = source_columns[col]\n",
        "        print(f\"  - {col} ({col_info.role}, {col_info.data_type})\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ No missing columns - all source columns exist in target\")\n",
        "\n",
        "if comparison.only_in_target:\n",
        "    print(\n",
        "        f\"\\nüìã Columns in TARGET but NOT in SOURCE ({len(comparison.only_in_target)}):\"\n",
        "    )\n",
        "    for col in sorted(list(comparison.only_in_target)[:5]):\n",
        "        col_info = target_columns[col]\n",
        "        print(f\"  - {col} ({col_info.role}, {col_info.data_type})\")\n",
        "    if len(comparison.only_in_target) > 5:\n",
        "        print(f\"  ... and {len(comparison.only_in_target) - 5} more\")\n",
        "\n",
        "if comparison.type_mismatches:\n",
        "    print(f\"\\n‚ö†Ô∏è  Data type DIFFERENCES ({len(comparison.type_mismatches)}):\")\n",
        "    for col, (source_type, target_type) in list(comparison.type_mismatches.items())[:5]:\n",
        "        print(f\"  - {col}: source={source_type} ‚Üí target={target_type}\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ All common columns have matching data types\")\n",
        "\n",
        "print(\n",
        "    f\"\\n{'‚úÖ' if comparison.is_compatible else '‚ö†Ô∏è '} Schema compatibility: {comparison.is_compatible}\"\n",
        ")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "export-segments-cell",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPORTING SEGMENTS\n",
            "============================================================\n",
            "\n",
            "‚úì Exported 15 segment(s)\n",
            "\n",
            "  Segment: California Customers\n",
            "    Definition: geography=='California'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: California Customers between 30 and 60\n",
            "    Definition: (age<60 or age>30) and geography=='California'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: California Customers over 60\n",
            "    Definition: age>60 and geography=='California'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: California Customers under 30\n",
            "    Definition: age<30 and geography=='California'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: Female Customers\n",
            "    Definition: gender=='Female'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: Florida Customers\n",
            "    Definition: geography=='Florida'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: Has CC\n",
            "    Definition: hascrcard==1\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: Has no CC\n",
            "    Definition: hascrcard==0\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: Hawaii Customers\n",
            "    Definition: geography=='Hawaii'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: Male Customers\n",
            "    Definition: gender=='Male'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: Massachusetts Customers\n",
            "    Definition: geography=='Massachusetts'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: New York Customers\n",
            "    Definition: geography=='New York'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: Non Binary Customers\n",
            "    Definition: gender=='Nonbinary'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: Non Hawaii Customers\n",
            "    Definition: geography!='Hawaii'\n",
            "    Referenced columns: set()\n",
            "\n",
            "  Segment: Texas Customers\n",
            "    Definition: geography=='Texas'\n",
            "    Referenced columns: set()\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXPORTING SEGMENTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "with conn_mgr.use(\"source\"):\n",
        "    # Export segments (filtered by name if specified)\n",
        "    exported_segments = segment_mgr.export_assets(\n",
        "        model_id=source_model.id,\n",
        "        names=SEGMENTS_TO_EXPORT if SEGMENTS_TO_EXPORT else None,\n",
        "    )\n",
        "\n",
        "    print(f\"\\n‚úì Exported {len(exported_segments)} segment(s)\")\n",
        "\n",
        "    for seg_data in exported_segments:\n",
        "        print(f\"\\n  Segment: {seg_data.name}\")\n",
        "        print(f\"    Definition: {seg_data.data['definition']}\")\n",
        "        print(f\"    Referenced columns: {seg_data.referenced_columns}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "import-segments",
      "metadata": {},
      "source": [
        "## Import Segments\n",
        "\n",
        "Import segments to target model with automatic validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "import-segments-cell",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "IMPORTING SEGMENTS\n",
            "============================================================\n",
            "\n",
            "Results:\n",
            "  ‚úÖ Successfully imported: 0\n",
            "  üîÑ Skipped (existing): 15\n",
            "  ‚äò  Skipped (invalid): 0\n",
            "  ‚ùå Failed: 0\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"IMPORTING SEGMENTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "with conn_mgr.use(\"target\"):\n",
        "    # Import with validation and error handling\n",
        "    segment_result = segment_mgr.import_assets(\n",
        "        target_model_id=target_model.id,\n",
        "        assets=exported_segments,\n",
        "        validate=True,\n",
        "        dry_run=False,\n",
        "        skip_invalid=True,\n",
        "        overwrite=False,\n",
        "    )\n",
        "\n",
        "    print(\"\\nResults:\")\n",
        "    print(f\"  ‚úÖ Successfully imported: {segment_result.successful}\")\n",
        "    print(f\"  üîÑ Skipped (existing): {segment_result.skipped_existing}\")\n",
        "    print(f\"  ‚äò  Skipped (invalid): {segment_result.skipped_invalid}\")\n",
        "    print(f\"  ‚ùå Failed: {segment_result.failed}\")\n",
        "\n",
        "    if segment_result.errors:\n",
        "        print(\"\\n  Errors:\")\n",
        "        for name, error in segment_result.errors:\n",
        "            print(f\"    - {name}: {error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "export-metrics",
      "metadata": {},
      "source": [
        "## Export Custom Metrics\n",
        "\n",
        "Export custom metrics from source model using `CustomMetricManager`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "export-metrics-cell",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPORTING CUSTOM METRICS\n",
            "============================================================\n",
            "\n",
            "‚úì Exported 9 custom metric(s)\n",
            "\n",
            "  Metric: Disparate Impact Female against Male\n",
            "    Definition: (sum(if((\"probability_churn\">0.8 and \"gender\"== 'Female'), 1, 0))/sum(if((\"gender\"== 'Female'), 1, 0)))/(sum(if((\"probability_churn\">0.8 and \"gender\"== 'Male'), 1, 0))/sum(if((\"gender\"== 'Male'), 1, 0)))\n",
            "    Referenced columns: {'probability_churn', 'gender'}\n",
            "    Type: Aggregation\n",
            "    Functions: sum, if\n",
            "\n",
            "  Metric: Disparate Impact Non Binary against Male\n",
            "    Definition: (sum(if((\"probability_churn\">0.8 and \"gender\"== 'Nonbinary'), 1, 0))/sum(if((\"gender\"== 'Nonbinary'), 1, 0)))/(sum(if((\"probability_churn\">0.8 and \"gender\"== 'Male'), 1, 0))/sum(if((\"gender\"== 'Male'), 1, 0)))\n",
            "    Referenced columns: {'probability_churn', 'gender'}\n",
            "    Type: Aggregation\n",
            "    Functions: sum, if\n",
            "\n",
            "  Metric: Equal Opportunity True Positive Rate\n",
            "    Definition: sum(if(tp(), 1, 0)) / sum(if(tp(), 1, 0)+if(fn(), 1, 0))\n",
            "    Referenced columns: set()\n",
            "    Type: Aggregation\n",
            "    Functions: sum, if, tp, fn\n",
            "\n",
            "  Metric: False Negative Count\n",
            "    Definition: sum(if(fn(),1,0))\n",
            "    Referenced columns: set()\n",
            "    Type: Aggregation\n",
            "    Functions: sum, if, fn\n",
            "\n",
            "  Metric: False Positive Count\n",
            "    Definition: sum(if(fp(),1,0))\n",
            "    Referenced columns: set()\n",
            "    Type: Aggregation\n",
            "    Functions: sum, if, fp\n",
            "\n",
            "  Metric: Group Benefit\n",
            "    Definition: sum(if(tp(), 1, 0)+if(fp(), 1, 0)) / sum(if(tp(), 1, 0)+if(fn(), 1, 0))\n",
            "    Referenced columns: set()\n",
            "    Type: Aggregation\n",
            "    Functions: sum, if, fn, fp, tp\n",
            "\n",
            "  Metric: Revenue Impact from False Negatives\n",
            "    Definition: sum(if(fn(),1,0) * -100)\n",
            "    Referenced columns: set()\n",
            "    Type: Aggregation\n",
            "    Functions: sum, if, fn\n",
            "\n",
            "  Metric: Revenue Impact from False Positives\n",
            "    Definition: sum(if(fp(),1,0) * -100)\n",
            "    Referenced columns: set()\n",
            "    Type: Aggregation\n",
            "    Functions: sum, if, fp\n",
            "\n",
            "  Metric: Total Revenue Impact\n",
            "    Definition: sum(if(tp(),1, 0)*100 + if((fp() or fn()), 1, 0)* -100)\n",
            "    Referenced columns: set()\n",
            "    Type: Aggregation\n",
            "    Functions: sum, if, fn, fp, tp\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXPORTING CUSTOM METRICS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "with conn_mgr.use(\"source\"):\n",
        "    # Export custom metrics (filtered by name if specified)\n",
        "    exported_metrics = metric_mgr.export_assets(\n",
        "        model_id=source_model.id,\n",
        "        names=CUSTOM_METRICS_TO_EXPORT if CUSTOM_METRICS_TO_EXPORT else None,\n",
        "    )\n",
        "\n",
        "    print(f\"\\n‚úì Exported {len(exported_metrics)} custom metric(s)\")\n",
        "\n",
        "    for metric_data in exported_metrics:\n",
        "        print(f\"\\n  Metric: {metric_data.name}\")\n",
        "        print(f\"    Definition: {metric_data.data['definition']}\")\n",
        "        print(f\"    Referenced columns: {metric_data.referenced_columns}\")\n",
        "\n",
        "        # Show complexity info\n",
        "        metadata = metric_data.data[\"metadata\"]\n",
        "        metric_type = \"Aggregation\" if metadata[\"is_aggregation\"] else \"Simple\"\n",
        "        print(f\"    Type: {metric_type}\")\n",
        "        if metadata[\"functions_used\"]:\n",
        "            print(f\"    Functions: {', '.join(metadata['functions_used'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "import-metrics",
      "metadata": {},
      "source": [
        "## Import Custom Metrics\n",
        "\n",
        "Import custom metrics to target model with automatic validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "import-metrics-cell",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "IMPORTING CUSTOM METRICS\n",
            "============================================================\n",
            "\n",
            "Results:\n",
            "  ‚úÖ Successfully imported: 0\n",
            "  üîÑ Skipped (existing): 7\n",
            "  ‚äò  Skipped (invalid): 2\n",
            "  ‚ùå Failed: 0\n",
            "\n",
            "  Errors:\n",
            "    - Disparate Impact Female against Male: Missing columns: ['probability_churn']\n",
            "    - Disparate Impact Non Binary against Male: Missing columns: ['probability_churn']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"IMPORTING CUSTOM METRICS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "with conn_mgr.use(\"target\"):\n",
        "    # Import with validation and error handling\n",
        "    metric_result = metric_mgr.import_assets(\n",
        "        target_model_id=target_model.id,\n",
        "        assets=exported_metrics,\n",
        "        validate=True,\n",
        "        dry_run=False,\n",
        "        skip_invalid=True, \n",
        "        overwrite=False,\n",
        "    )\n",
        "\n",
        "    print(\"\\nResults:\")\n",
        "    print(f\"  ‚úÖ Successfully imported: {metric_result.successful}\")\n",
        "    print(f\"  üîÑ Skipped (existing): {metric_result.skipped_existing}\")\n",
        "    print(f\"  ‚äò  Skipped (invalid): {metric_result.skipped_invalid}\")\n",
        "    print(f\"  ‚ùå Failed: {metric_result.failed}\")\n",
        "\n",
        "    if metric_result.errors:\n",
        "        print(\"\\n  Errors:\")\n",
        "        for name, error in metric_result.errors:\n",
        "            print(f\"    - {name}: {error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary",
      "metadata": {},
      "source": [
        "## Summary Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "summary-cell",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPORT/IMPORT SUMMARY\n",
            "============================================================\n",
            "\n",
            "Segments:\n",
            "  Total exported: 15\n",
            "  Successfully imported: 0\n",
            "  Skipped (existing): 15\n",
            "  Skipped (invalid): 0\n",
            "  Failed: 0\n",
            "\n",
            "Custom Metrics:\n",
            "  Total exported: 9\n",
            "  Successfully imported: 0\n",
            "  Skipped (existing): 7\n",
            "  Skipped (invalid): 2\n",
            "  Failed: 0\n",
            "\n",
            "============================================================\n",
            "OVERALL: 0/24 assets successfully imported\n",
            "  22 skipped (already exist on target)\n",
            "  2 skipped (validation errors)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXPORT/IMPORT SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nSegments:\")\n",
        "print(f\"  Total exported: {len(exported_segments)}\")\n",
        "print(f\"  Successfully imported: {segment_result.successful}\")\n",
        "print(f\"  Skipped (existing): {segment_result.skipped_existing}\")\n",
        "print(f\"  Skipped (invalid): {segment_result.skipped_invalid}\")\n",
        "print(f\"  Failed: {segment_result.failed}\")\n",
        "\n",
        "print(\"\\nCustom Metrics:\")\n",
        "print(f\"  Total exported: {len(exported_metrics)}\")\n",
        "print(f\"  Successfully imported: {metric_result.successful}\")\n",
        "print(f\"  Skipped (existing): {metric_result.skipped_existing}\")\n",
        "print(f\"  Skipped (invalid): {metric_result.skipped_invalid}\")\n",
        "print(f\"  Failed: {metric_result.failed}\")\n",
        "\n",
        "total_success = segment_result.successful + metric_result.successful\n",
        "total_skipped_existing = segment_result.skipped_existing + metric_result.skipped_existing\n",
        "total_skipped_invalid = segment_result.skipped_invalid + metric_result.skipped_invalid\n",
        "total_failed = segment_result.failed + metric_result.failed\n",
        "total_exported = len(exported_segments) + len(exported_metrics)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"OVERALL: {total_success}/{total_exported} assets successfully imported\")\n",
        "if total_skipped_existing > 0:\n",
        "    print(f\"  {total_skipped_existing} skipped (already exist on target)\")\n",
        "if total_skipped_invalid > 0:\n",
        "    print(f\"  {total_skipped_invalid} skipped (validation errors)\")\n",
        "if total_failed > 0:\n",
        "    print(f\"  {total_failed} failed during import\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "charts-header",
      "metadata": {},
      "source": [
        "## Export/Import Charts\n",
        "\n",
        "Demonstrate cross-instance chart transfer using `ChartManager`.\n",
        "\n",
        "This section shows how fiddler_utils simplifies chart transfers.\n",
        "\n",
        "**To use this section:**\n",
        "1. Set `SOURCE_DASHBOARD_ID` in the configuration cell above (find dashboard ID in Fiddler UI URL)\n",
        "2. OR set `CHART_IDS_TO_EXPORT` to manually specify chart UUIDs\n",
        "3. Run the cells below to export and import charts\n",
        "\n",
        "**Note:** Chart API uses unofficial Fiddler endpoints and may change without notice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "charts-init",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "INITIALIZING CHART MANAGERS\n",
            "============================================================\n",
            "\n",
            "‚úì Source ChartManager initialized\n",
            "‚úì Target ChartManager initialized\n"
          ]
        }
      ],
      "source": [
        "from fiddler_utils import ChartManager\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"INITIALIZING CHART MANAGERS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create separate managers for source and target\n",
        "# Each needs its own URL/token for RequestClient\n",
        "source_chart_mgr = ChartManager(url=SOURCE_URL, token=SOURCE_TOKEN)\n",
        "target_chart_mgr = ChartManager(url=TARGET_URL, token=TARGET_TOKEN)\n",
        "\n",
        "print(\"\\n‚úì Source ChartManager initialized\")\n",
        "print(\"‚úì Target ChartManager initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "charts-export",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXPORTING CHARTS\n",
            "============================================================\n",
            "\n",
            "Exporting charts from dashboard: dbd97cc9-3cfb-4d22-8159-a025ced9b455\n",
            "\n",
            "‚úì Exported 12 chart(s)\n",
            "\n",
            "1. Model Performance - Monthly\n",
            "   Type: ANALYTICS\n",
            "\n",
            "2. Revenue Impact By State\n",
            "   Type: MONITORING\n",
            "   Dependencies: custom_metric=3662284e-df05-4874-8904-3af32261e98e, segment={'id': 'd06c74a4-7480-46c5-a10f-659e79527ffe'}\n",
            "\n",
            "3. Prediction Drift\n",
            "   Type: MONITORING\n",
            "\n",
            "4. Accuracy By State\n",
            "   Type: MONITORING\n",
            "   Dependencies: segment={'id': 'd06c74a4-7480-46c5-a10f-659e79527ffe'}\n",
            "\n",
            "5. Decision Distribution \n",
            "   Type: ANALYTICS\n",
            "\n",
            "6. Decision Volume Tracking\n",
            "   Type: MONITORING\n",
            "\n",
            "7. Churn Probability - Gender\n",
            "   Type: MONITORING\n",
            "   Dependencies: segment={'id': '70298256-e1b5-49c1-abd4-3bc1908ecf5d'}\n",
            "\n",
            "8. Churn Probability - Geography\n",
            "   Type: MONITORING\n",
            "   Dependencies: segment={'id': 'ed229f55-370e-48af-acef-93176fcb5896'}\n",
            "\n",
            "9. Group Benefit - Gender\n",
            "   Type: MONITORING\n",
            "   Dependencies: custom_metric=b507cad8-c257-4467-b3a3-96dfc0f4e67f, segment={'id': '70298256-e1b5-49c1-abd4-3bc1908ecf5d'}\n",
            "\n",
            "10. Data Integrity Metrics - Bank Churn\n",
            "   Type: MONITORING\n",
            "\n",
            "11. Accuracy\n",
            "   Type: MONITORING\n",
            "\n",
            "12. Accuracy for California Users\n",
            "   Type: MONITORING\n",
            "   Dependencies: segment={'id': '2777cca0-1f40-49bc-a555-ff30b1c8c2a9'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXPORTING CHARTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Determine export method\n",
        "if SOURCE_DASHBOARD_ID:\n",
        "    print(f\"\\nExporting charts from dashboard: {SOURCE_DASHBOARD_ID}\")\n",
        "elif CHART_IDS_TO_EXPORT:\n",
        "    print(f\"\\nExporting {len(CHART_IDS_TO_EXPORT)} charts by ID\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No SOURCE_DASHBOARD_ID or CHART_IDS_TO_EXPORT specified.\")\n",
        "    print(\"   Set one of these in the configuration cell to export charts.\")\n",
        "    exported_charts = []\n",
        "\n",
        "if SOURCE_DASHBOARD_ID or CHART_IDS_TO_EXPORT:\n",
        "    with conn_mgr.use('source'):\n",
        "        try:\n",
        "            # Export charts using dashboard_id or chart_ids\n",
        "            exported_charts = source_chart_mgr.export_charts(\n",
        "                dashboard_id=SOURCE_DASHBOARD_ID if SOURCE_DASHBOARD_ID else None,\n",
        "                chart_ids=CHART_IDS_TO_EXPORT if CHART_IDS_TO_EXPORT else None,\n",
        "            )\n",
        "            \n",
        "            print(f\"\\n‚úì Exported {len(exported_charts)} chart(s)\\n\")\n",
        "            \n",
        "            # Display exported chart details\n",
        "            for i, chart in enumerate(exported_charts, 1):\n",
        "                print(f\"{i}. {chart.get('title', 'Untitled')}\")\n",
        "                print(f\"   Type: {chart.get('query_type', 'unknown')}\")\n",
        "                \n",
        "                # Show data source info\n",
        "                data_source = chart.get('data_source', {})\n",
        "                queries = data_source.get('queries', [])\n",
        "                \n",
        "                if queries:\n",
        "                    # Show first query details for monitoring charts\n",
        "                    query = queries[0]\n",
        "                    metric_info = []\n",
        "                    \n",
        "                    if 'baseline_name' in query:\n",
        "                        metric_info.append(f\"baseline={query['baseline_name']}\")\n",
        "                    if query.get('metric_type') == 'custom':\n",
        "                        metric_info.append(f\"custom_metric={query.get('metric', 'N/A')}\")\n",
        "                    if 'segment' in query and query['segment']:\n",
        "                        metric_info.append(f\"segment={query['segment']}\")\n",
        "                    \n",
        "                    if metric_info:\n",
        "                        print(f\"   Dependencies: {', '.join(metric_info)}\")\n",
        "                print()\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Failed to export charts: {e}\")\n",
        "            exported_charts = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "charts-analyze",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ANALYZING CHART DEPENDENCIES\n",
            "============================================================\n",
            "\n",
            "Charts reference:\n",
            "  0 baseline(s): None\n",
            "  2 custom metric(s): ['3662284e-df05-4874-8904-3af32261e98e', 'b507cad8-c257-4467-b3a3-96dfc0f4e67f']\n",
            "  0 segment(s): None\n",
            "\n",
            "üí° These dependencies must exist on target for successful import\n"
          ]
        }
      ],
      "source": [
        "if not exported_charts:\n",
        "    print(\"\\n‚äò No charts to analyze. Skipping dependency analysis.\")\n",
        "else:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ANALYZING CHART DEPENDENCIES\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Collect all dependencies from charts\n",
        "    baseline_refs = set()\n",
        "    metric_refs = set()\n",
        "    segment_refs = set()\n",
        "    \n",
        "    for chart in exported_charts:\n",
        "        data_source = chart.get('data_source', {})\n",
        "        queries = data_source.get('queries', [])\n",
        "        \n",
        "        for query in queries:\n",
        "            if 'baseline_name' in query:\n",
        "                baseline_refs.add(query['baseline_name'])\n",
        "            if query.get('metric_type') == 'custom' and 'metric' in query:\n",
        "                metric_refs.add(query['metric'])\n",
        "            if 'segment' in query and query['segment']:\n",
        "                segment_val = query['segment']\n",
        "                if isinstance(segment_val, dict):\n",
        "                    # May have segment ID or name\n",
        "                    if 'name' in segment_val:\n",
        "                        segment_refs.add(segment_val['name'])\n",
        "                elif isinstance(segment_val, str):\n",
        "                    segment_refs.add(segment_val)\n",
        "    \n",
        "    print(f\"\\nCharts reference:\")\n",
        "    print(f\"  {len(baseline_refs)} baseline(s): {sorted(baseline_refs) if baseline_refs else 'None'}\")\n",
        "    print(f\"  {len(metric_refs)} custom metric(s): {sorted(list(metric_refs)[:3]) if metric_refs else 'None'}\")\n",
        "    print(f\"  {len(segment_refs)} segment(s): {sorted(list(segment_refs)[:3]) if segment_refs else 'None'}\")\n",
        "    \n",
        "    print(\"\\nüí° These dependencies must exist on target for successful import\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "charts-dryrun",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "DRY RUN: VALIDATE CHART IMPORT\n",
            "============================================================\n",
            "\n",
            "Dry run results:\n",
            "  ‚úÖ Would succeed: 12\n",
            "  ‚ùå Would fail: 0\n",
            "\n",
            "‚úÖ All charts validated successfully\n"
          ]
        }
      ],
      "source": [
        "if not exported_charts:\n",
        "    print(\"\\n‚äò No charts to validate. Skipping dry run.\")\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"DRY RUN: VALIDATE CHART IMPORT\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    with conn_mgr.use('target'):\n",
        "        # Perform dry run to validate without creating charts\n",
        "        dry_result = target_chart_mgr.import_charts(\n",
        "            target_project_id=target_project.id,\n",
        "            target_model_id=target_model.id,\n",
        "            charts=exported_charts,\n",
        "            validate=True,\n",
        "            dry_run=True  # Preview only\n",
        "        )\n",
        "        \n",
        "        print(f\"\\nDry run results:\")\n",
        "        print(f\"  ‚úÖ Would succeed: {dry_result['successful']}\")\n",
        "        print(f\"  ‚ùå Would fail: {dry_result['failed']}\")\n",
        "        \n",
        "        if dry_result.get('errors'):\n",
        "            print(f\"\\n‚ö†Ô∏è  Potential errors ({len(dry_result['errors'])}):\")\n",
        "            for title, error in dry_result['errors'][:5]:  # Show first 5\n",
        "                print(f\"    ‚Ä¢ {title}\")\n",
        "                print(f\"      {error}\")\n",
        "            if len(dry_result['errors']) > 5:\n",
        "                print(f\"    ... and {len(dry_result['errors']) - 5} more\")\n",
        "        else:\n",
        "            print(\"\\n‚úÖ All charts validated successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "charts-import",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "IMPORTING CHARTS\n",
            "============================================================\n",
            "\n",
            "Results:\n",
            "  ‚úÖ Successfully imported: 12\n",
            "  ‚ùå Failed: 0\n",
            "\n",
            "‚úì Successfully imported 12 chart(s) to target model\n"
          ]
        }
      ],
      "source": [
        "if not exported_charts:\n",
        "    print(\"\\n‚äò No charts to import. Skipping import.\")\n",
        "    chart_result = {'successful': 0, 'failed': 0, 'errors': []}\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"IMPORTING CHARTS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    with conn_mgr.use('target'):\n",
        "        # Perform actual import\n",
        "        chart_result = target_chart_mgr.import_charts(\n",
        "            target_project_id=target_project.id,\n",
        "            target_model_id=target_model.id,\n",
        "            charts=exported_charts,\n",
        "            validate=True,\n",
        "            dry_run=False  # Actually create charts\n",
        "        )\n",
        "        \n",
        "        print(\"\\nResults:\")\n",
        "        print(f\"  ‚úÖ Successfully imported: {chart_result['successful']}\")\n",
        "        print(f\"  ‚ùå Failed: {chart_result['failed']}\")\n",
        "        \n",
        "        if chart_result.get('errors'):\n",
        "            print(f\"\\n  Errors encountered:\")\n",
        "            for title, error in chart_result['errors']:\n",
        "                print(f\"    ‚Ä¢ {title}\")\n",
        "                print(f\"      {error}\")\n",
        "        \n",
        "        # Update overall summary\n",
        "        if chart_result['successful'] > 0:\n",
        "            print(f\"\\n‚úì Successfully imported {chart_result['successful']} chart(s) to target model\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
