{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f0c3549a",
      "metadata": {
        "id": "f0c3549a"
      },
      "source": [
        "# A Notebook for Generating Labeled Data for a Multi-class NLP Classification\n",
        "This notebook generates some useful assets (data/model) that can be used by other examples and notebooks for demonstration and debugging of NLP use cases in Fiddler. In particular, we use the public 20Newsgroups dataset and apply a TF-IDF vectorization to find embedding vectors of text data. Then we split the data into training and test samples and apply a logistic regression model to predict the probability of each the target for each data point. To make the classification task simpler, We group the original targets into more general news categories. In the end, we concatenate all the results in a pandas DataFrame and store both the labeled training and labeled test data as CSV files. This data can be used as baseline and production data in Fiddler when model artifacts and surrogate models are not required. We also store the trained model as a pickle file, for scenarios where access to the model is also required.    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F3ZScdVsgYzo",
      "metadata": {
        "id": "F3ZScdVsgYzo"
      },
      "source": [
        "# Fetch the 20 Newsgroup Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yZh-dG6kdMoP",
      "metadata": {
        "id": "yZh-dG6kdMoP"
      },
      "source": [
        "First, we retrieve the 20Newsgroups dataset, which is available as part of the scikit-learn real-world dataset. This dataset contains around 18,000 newsgroup posts on 20 topics. The original dataset is available [here](http://qwone.com/~jason/20Newsgroups/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zCqhKtjrXFU1",
      "metadata": {
        "id": "zCqhKtjrXFU1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zEY0gOzyhrvY",
      "metadata": {
        "id": "zEY0gOzyhrvY"
      },
      "outputs": [],
      "source": [
        "data_bunch = fetch_20newsgroups(\n",
        "    subset = 'train',\n",
        "    shuffle=True,\n",
        "    random_state=1,\n",
        "    remove=('headers','footers','quotes')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hnphKST_e617",
      "metadata": {
        "id": "hnphKST_e617"
      },
      "source": [
        "A target name from 20 topics is assigned to each data sample in the above dataset, and you can access all the target names by running the: \n",
        "```\n",
        "data_bunch.target_names\n",
        "```\n",
        "However, to make this example notebook simpler, we group similar topics and define more general targets as the following:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M83tz1P5W8Fp",
      "metadata": {
        "id": "M83tz1P5W8Fp"
      },
      "outputs": [],
      "source": [
        "subcategories = {\n",
        "    \n",
        "    'computer': ['comp.graphics',\n",
        "                 'comp.os.ms-windows.misc',\n",
        "                 'comp.sys.ibm.pc.hardware',\n",
        "                 'comp.sys.mac.hardware',\n",
        "                 'comp.windows.x'],\n",
        "    \n",
        "    'politics': ['talk.politics.guns',\n",
        "                 'talk.politics.mideast',\n",
        "                 'talk.politics.misc'],\n",
        "    \n",
        "    'recreation':['rec.autos',\n",
        "                  'rec.motorcycles',\n",
        "                  'rec.sport.baseball',\n",
        "                  'rec.sport.hockey'],\n",
        "    \n",
        "    'science': ['sci.crypt',\n",
        "                'sci.electronics',\n",
        "                'sci.med',\n",
        "                'sci.space',],\n",
        "    \n",
        "    'religion': ['soc.religion.christian',\n",
        "                 'talk.religion.misc',\n",
        "                 'alt.atheism'],\n",
        "    \n",
        "    'forsale':['misc.forsale']\n",
        "}\n",
        "\n",
        "main_category = {}\n",
        "for key,l in subcategories.items():\n",
        "    for item in l:\n",
        "        main_category[item] = key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TA9_uykyggmt",
      "metadata": {
        "id": "TA9_uykyggmt"
      },
      "source": [
        "Finally, we run some preprocessing and store the data in a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WcZh806fXKVK",
      "metadata": {
        "id": "WcZh806fXKVK"
      },
      "outputs": [],
      "source": [
        "data_prep = [s.replace('\\n',' ').strip('\\n,=,|,-, ,\\,^') for s in data_bunch.data]\n",
        "data_series = pd.Series(data_prep)\n",
        "df = pd.DataFrame()\n",
        "df['original_text'] = data_series\n",
        "df['original_target'] = [data_bunch.target_names[t] for t in data_bunch.target]\n",
        "df['target'] = [main_category[data_bunch.target_names[t]] for t in data_bunch.target]\n",
        "df['original_text'].replace('', np.nan, inplace=True)\n",
        "df.dropna(axis=0, subset=['original_text'], inplace=True)\n",
        "df = df[df.target!='politics'] #delete political posts \n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JFzXvnYSYCcT",
      "metadata": {
        "id": "JFzXvnYSYCcT"
      },
      "source": [
        "# TF-IDF *Vectorization*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vg781hoag6af",
      "metadata": {
        "id": "vg781hoag6af"
      },
      "source": [
        "Before training a model for predicting the targets, we transform the text data into a format that can be processed by standard ML models. This transformation step is often called \"vectorization\" and it is performed by embedding text data into high-dimensional vector space.  In this notebook, we use a simple TF-IDF vectorization method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0FOIbZmeYP8a",
      "metadata": {
        "id": "0FOIbZmeYP8a"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f016bc6",
      "metadata": {
        "id": "2f016bc6"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PNYxc5zrYSu1",
      "metadata": {
        "id": "PNYxc5zrYSu1"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(sublinear_tf=True,\n",
        "                             max_features=embedding_dimension,\n",
        "                             min_df=0.01,\n",
        "                             max_df=0.9,\n",
        "                             stop_words='english',\n",
        "                             token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
        "\n",
        "tfidf_sparse = vectorizer.fit_transform(df['original_text'])\n",
        "embedding_cols = vectorizer.get_feature_names_out()\n",
        "embedding_col_names = ['tfidf_token_{}'.format(t) for t in embedding_cols]\n",
        "tfidf_df = pd.DataFrame.sparse.from_spmatrix(tfidf_sparse, columns=embedding_col_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed17dabb",
      "metadata": {
        "id": "ed17dabb",
        "outputId": "1cf73490-ee37-454d-88dc-9c07e501afdc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tfidf_token_able</th>\n",
              "      <th>tfidf_token_access</th>\n",
              "      <th>tfidf_token_actually</th>\n",
              "      <th>tfidf_token_address</th>\n",
              "      <th>tfidf_token_application</th>\n",
              "      <th>tfidf_token_article</th>\n",
              "      <th>tfidf_token_ask</th>\n",
              "      <th>tfidf_token_available</th>\n",
              "      <th>tfidf_token_b</th>\n",
              "      <th>tfidf_token_bad</th>\n",
              "      <th>...</th>\n",
              "      <th>tfidf_token_work</th>\n",
              "      <th>tfidf_token_works</th>\n",
              "      <th>tfidf_token_world</th>\n",
              "      <th>tfidf_token_wrong</th>\n",
              "      <th>tfidf_token_x</th>\n",
              "      <th>tfidf_token_y</th>\n",
              "      <th>tfidf_token_year</th>\n",
              "      <th>tfidf_token_years</th>\n",
              "      <th>tfidf_token_yes</th>\n",
              "      <th>tfidf_token_z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.226770</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.229739</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.198851</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.219193</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.296510</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.114576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.118824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9471</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117575</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.09222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.109909</td>\n",
              "      <td>0.19099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9472</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9473</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9474</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9475</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.163896</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.158854</td>\n",
              "      <td>0.260401</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9476 rows × 250 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      tfidf_token_able  tfidf_token_access  tfidf_token_actually  \\\n",
              "0                  0.0                 0.0              0.226770   \n",
              "1                  0.0                 0.0              0.000000   \n",
              "2                  0.0                 0.0              0.000000   \n",
              "3                  0.0                 0.0              0.000000   \n",
              "4                  0.0                 0.0              0.000000   \n",
              "...                ...                 ...                   ...   \n",
              "9471               0.0                 0.0              0.000000   \n",
              "9472               0.0                 0.0              0.000000   \n",
              "9473               0.0                 0.0              0.000000   \n",
              "9474               0.0                 0.0              0.000000   \n",
              "9475               0.0                 0.0              0.163896   \n",
              "\n",
              "      tfidf_token_address  tfidf_token_application  tfidf_token_article  \\\n",
              "0                     0.0                      0.0                  0.0   \n",
              "1                     0.0                      0.0                  0.0   \n",
              "2                     0.0                      0.0                  0.0   \n",
              "3                     0.0                      0.0                  0.0   \n",
              "4                     0.0                      0.0                  0.0   \n",
              "...                   ...                      ...                  ...   \n",
              "9471                  0.0                      0.0                  0.0   \n",
              "9472                  0.0                      0.0                  0.0   \n",
              "9473                  0.0                      0.0                  0.0   \n",
              "9474                  0.0                      0.0                  0.0   \n",
              "9475                  0.0                      0.0                  0.0   \n",
              "\n",
              "      tfidf_token_ask  tfidf_token_available  tfidf_token_b  tfidf_token_bad  \\\n",
              "0            0.000000                    0.0       0.000000              0.0   \n",
              "1            0.000000                    0.0       0.229739              0.0   \n",
              "2            0.000000                    0.0       0.000000              0.0   \n",
              "3            0.000000                    0.0       0.000000              0.0   \n",
              "4            0.000000                    0.0       0.296510              0.0   \n",
              "...               ...                    ...            ...              ...   \n",
              "9471         0.117575                    0.0       0.000000              0.0   \n",
              "9472         0.000000                    0.0       0.000000              0.0   \n",
              "9473         0.000000                    0.0       0.000000              0.0   \n",
              "9474         0.000000                    0.0       0.000000              0.0   \n",
              "9475         0.000000                    0.0       0.000000              0.0   \n",
              "\n",
              "      ...  tfidf_token_work  tfidf_token_works  tfidf_token_world  \\\n",
              "0     ...           0.00000                0.0           0.000000   \n",
              "1     ...           0.00000                0.0           0.000000   \n",
              "2     ...           0.00000                0.0           0.000000   \n",
              "3     ...           0.00000                0.0           0.000000   \n",
              "4     ...           0.00000                0.0           0.000000   \n",
              "...   ...               ...                ...                ...   \n",
              "9471  ...           0.09222                0.0           0.109909   \n",
              "9472  ...           0.00000                0.0           0.000000   \n",
              "9473  ...           0.00000                0.0           0.000000   \n",
              "9474  ...           0.00000                0.0           0.000000   \n",
              "9475  ...           0.00000                0.0           0.000000   \n",
              "\n",
              "      tfidf_token_wrong  tfidf_token_x  tfidf_token_y  tfidf_token_year  \\\n",
              "0               0.00000            0.0       0.000000          0.000000   \n",
              "1               0.00000            0.0       0.000000          0.198851   \n",
              "2               0.00000            0.0       0.000000          0.000000   \n",
              "3               0.00000            0.0       0.000000          0.000000   \n",
              "4               0.00000            0.0       0.114576          0.000000   \n",
              "...                 ...            ...            ...               ...   \n",
              "9471            0.19099            0.0       0.000000          0.000000   \n",
              "9472            0.00000            0.0       0.000000          0.000000   \n",
              "9473            0.00000            0.0       0.000000          0.000000   \n",
              "9474            0.00000            0.0       0.000000          0.000000   \n",
              "9475            0.00000            0.0       0.000000          0.158854   \n",
              "\n",
              "      tfidf_token_years  tfidf_token_yes  tfidf_token_z  \n",
              "0              0.000000         0.000000       0.000000  \n",
              "1              0.000000         0.219193       0.000000  \n",
              "2              0.000000         0.000000       0.000000  \n",
              "3              0.000000         0.000000       0.000000  \n",
              "4              0.000000         0.000000       0.118824  \n",
              "...                 ...              ...            ...  \n",
              "9471           0.000000         0.000000       0.000000  \n",
              "9472           0.000000         0.000000       0.000000  \n",
              "9473           0.000000         0.000000       0.000000  \n",
              "9474           0.000000         0.000000       0.000000  \n",
              "9475           0.260401         0.000000       0.000000  \n",
              "\n",
              "[9476 rows x 250 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4UA5gdltnSb3",
      "metadata": {
        "id": "4UA5gdltnSb3"
      },
      "source": [
        "Now we concatenate the embedding representations and the DataFrame that we generated previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ulhYGfJqYXo6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "ulhYGfJqYXo6",
        "outputId": "a6e947c1-8965-44de-f4b0-df69f791561a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>original_target</th>\n",
              "      <th>target</th>\n",
              "      <th>tfidf_token_able</th>\n",
              "      <th>tfidf_token_access</th>\n",
              "      <th>tfidf_token_actually</th>\n",
              "      <th>tfidf_token_address</th>\n",
              "      <th>tfidf_token_application</th>\n",
              "      <th>tfidf_token_article</th>\n",
              "      <th>tfidf_token_ask</th>\n",
              "      <th>...</th>\n",
              "      <th>tfidf_token_work</th>\n",
              "      <th>tfidf_token_works</th>\n",
              "      <th>tfidf_token_world</th>\n",
              "      <th>tfidf_token_wrong</th>\n",
              "      <th>tfidf_token_x</th>\n",
              "      <th>tfidf_token_y</th>\n",
              "      <th>tfidf_token_year</th>\n",
              "      <th>tfidf_token_years</th>\n",
              "      <th>tfidf_token_yes</th>\n",
              "      <th>tfidf_token_z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yeah, do you expect people to read the FAQ, et...</td>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>religion</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.226770</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Notwithstanding all the legitimate fuss about ...</td>\n",
              "      <td>sci.crypt</td>\n",
              "      <td>science</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.198851</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.219193</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Well, I will have to change the scoring on my ...</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "      <td>recreation</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I read somewhere, I think in Morton Smith's _J...</td>\n",
              "      <td>soc.religion.christian</td>\n",
              "      <td>religion</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ok.  I have a record that shows a IIsi with an...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>computer</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.114576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.118824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9471</th>\n",
              "      <td>I'd like to share my thoughts on this topic of...</td>\n",
              "      <td>soc.religion.christian</td>\n",
              "      <td>religion</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117575</td>\n",
              "      <td>...</td>\n",
              "      <td>0.09222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.109909</td>\n",
              "      <td>0.19099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9472</th>\n",
              "      <td>My sunroof leaks.  I've always thought those t...</td>\n",
              "      <td>rec.autos</td>\n",
              "      <td>recreation</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9473</th>\n",
              "      <td>I agree.  Home runs off Clemens are always mem...</td>\n",
              "      <td>rec.sport.baseball</td>\n",
              "      <td>recreation</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9474</th>\n",
              "      <td>I used HP DeskJet with Orange Micros Grappler ...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>computer</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9475</th>\n",
              "      <td>No argument at all with Murphy.  He scared the...</td>\n",
              "      <td>rec.sport.baseball</td>\n",
              "      <td>recreation</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.163896</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.158854</td>\n",
              "      <td>0.260401</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9476 rows × 253 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          original_text  \\\n",
              "0     Yeah, do you expect people to read the FAQ, et...   \n",
              "1     Notwithstanding all the legitimate fuss about ...   \n",
              "2     Well, I will have to change the scoring on my ...   \n",
              "3     I read somewhere, I think in Morton Smith's _J...   \n",
              "4     Ok.  I have a record that shows a IIsi with an...   \n",
              "...                                                 ...   \n",
              "9471  I'd like to share my thoughts on this topic of...   \n",
              "9472  My sunroof leaks.  I've always thought those t...   \n",
              "9473  I agree.  Home runs off Clemens are always mem...   \n",
              "9474  I used HP DeskJet with Orange Micros Grappler ...   \n",
              "9475  No argument at all with Murphy.  He scared the...   \n",
              "\n",
              "             original_target      target  tfidf_token_able  \\\n",
              "0                alt.atheism    religion               0.0   \n",
              "1                  sci.crypt     science               0.0   \n",
              "2           rec.sport.hockey  recreation               0.0   \n",
              "3     soc.religion.christian    religion               0.0   \n",
              "4      comp.sys.mac.hardware    computer               0.0   \n",
              "...                      ...         ...               ...   \n",
              "9471  soc.religion.christian    religion               0.0   \n",
              "9472               rec.autos  recreation               0.0   \n",
              "9473      rec.sport.baseball  recreation               0.0   \n",
              "9474   comp.sys.mac.hardware    computer               0.0   \n",
              "9475      rec.sport.baseball  recreation               0.0   \n",
              "\n",
              "      tfidf_token_access  tfidf_token_actually  tfidf_token_address  \\\n",
              "0                    0.0              0.226770                  0.0   \n",
              "1                    0.0              0.000000                  0.0   \n",
              "2                    0.0              0.000000                  0.0   \n",
              "3                    0.0              0.000000                  0.0   \n",
              "4                    0.0              0.000000                  0.0   \n",
              "...                  ...                   ...                  ...   \n",
              "9471                 0.0              0.000000                  0.0   \n",
              "9472                 0.0              0.000000                  0.0   \n",
              "9473                 0.0              0.000000                  0.0   \n",
              "9474                 0.0              0.000000                  0.0   \n",
              "9475                 0.0              0.163896                  0.0   \n",
              "\n",
              "      tfidf_token_application  tfidf_token_article  tfidf_token_ask  ...  \\\n",
              "0                         0.0                  0.0         0.000000  ...   \n",
              "1                         0.0                  0.0         0.000000  ...   \n",
              "2                         0.0                  0.0         0.000000  ...   \n",
              "3                         0.0                  0.0         0.000000  ...   \n",
              "4                         0.0                  0.0         0.000000  ...   \n",
              "...                       ...                  ...              ...  ...   \n",
              "9471                      0.0                  0.0         0.117575  ...   \n",
              "9472                      0.0                  0.0         0.000000  ...   \n",
              "9473                      0.0                  0.0         0.000000  ...   \n",
              "9474                      0.0                  0.0         0.000000  ...   \n",
              "9475                      0.0                  0.0         0.000000  ...   \n",
              "\n",
              "      tfidf_token_work  tfidf_token_works  tfidf_token_world  \\\n",
              "0              0.00000                0.0           0.000000   \n",
              "1              0.00000                0.0           0.000000   \n",
              "2              0.00000                0.0           0.000000   \n",
              "3              0.00000                0.0           0.000000   \n",
              "4              0.00000                0.0           0.000000   \n",
              "...                ...                ...                ...   \n",
              "9471           0.09222                0.0           0.109909   \n",
              "9472           0.00000                0.0           0.000000   \n",
              "9473           0.00000                0.0           0.000000   \n",
              "9474           0.00000                0.0           0.000000   \n",
              "9475           0.00000                0.0           0.000000   \n",
              "\n",
              "      tfidf_token_wrong  tfidf_token_x  tfidf_token_y  tfidf_token_year  \\\n",
              "0               0.00000            0.0       0.000000          0.000000   \n",
              "1               0.00000            0.0       0.000000          0.198851   \n",
              "2               0.00000            0.0       0.000000          0.000000   \n",
              "3               0.00000            0.0       0.000000          0.000000   \n",
              "4               0.00000            0.0       0.114576          0.000000   \n",
              "...                 ...            ...            ...               ...   \n",
              "9471            0.19099            0.0       0.000000          0.000000   \n",
              "9472            0.00000            0.0       0.000000          0.000000   \n",
              "9473            0.00000            0.0       0.000000          0.000000   \n",
              "9474            0.00000            0.0       0.000000          0.000000   \n",
              "9475            0.00000            0.0       0.000000          0.158854   \n",
              "\n",
              "      tfidf_token_years  tfidf_token_yes  tfidf_token_z  \n",
              "0              0.000000         0.000000       0.000000  \n",
              "1              0.000000         0.219193       0.000000  \n",
              "2              0.000000         0.000000       0.000000  \n",
              "3              0.000000         0.000000       0.000000  \n",
              "4              0.000000         0.000000       0.118824  \n",
              "...                 ...              ...            ...  \n",
              "9471           0.000000         0.000000       0.000000  \n",
              "9472           0.000000         0.000000       0.000000  \n",
              "9473           0.000000         0.000000       0.000000  \n",
              "9474           0.000000         0.000000       0.000000  \n",
              "9475           0.260401         0.000000       0.000000  \n",
              "\n",
              "[9476 rows x 253 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all = pd.concat([df,tfidf_df], axis=1)\n",
        "df_all"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RBVKIHG_YdrD",
      "metadata": {
        "id": "RBVKIHG_YdrD"
      },
      "source": [
        "# Train a Multiclass Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "einKU3xGoHVF",
      "metadata": {
        "id": "einKU3xGoHVF"
      },
      "source": [
        "We are now ready to train a classifier to predict the labels assigned to each data sample. We use the logistic regression classifier from scikit-learn for this task. We split the data into train and test subsets and we use 25% of data points to train a logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ss9nv7SEYnEO",
      "metadata": {
        "id": "ss9nv7SEYnEO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JhFqymKoYrDM",
      "metadata": {
        "id": "JhFqymKoYrDM"
      },
      "outputs": [],
      "source": [
        "df_train, df_test = train_test_split(df_all, test_size=0.75, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5151ab9",
      "metadata": {
        "id": "c5151ab9"
      },
      "outputs": [],
      "source": [
        "clf = LogisticRegression(random_state=1).fit(df_train[embedding_col_names], df_train.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rog_WBnmYt7k",
      "metadata": {
        "id": "Rog_WBnmYt7k"
      },
      "outputs": [],
      "source": [
        "clf_classes = clf.classes_\n",
        "prob_col_names = ['prob_%s'%c for c in clf_classes]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y2UbdtqRpXlU",
      "metadata": {
        "id": "Y2UbdtqRpXlU"
      },
      "source": [
        "Using the logistic regression classifier for a multi-class classification problem, we get a probability for each target label. We store all the predicted class probabilities as well as the predicted target for each data point in the training and test sets and we compute the prediction accuracy in each set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4Dl64dFFYwQz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dl64dFFYwQz",
        "outputId": "9a885fa7-03ce-48fc-d9ef-dcd32e10d663"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on baseline:0.76\n"
          ]
        }
      ],
      "source": [
        "predictions_df_train = pd.DataFrame(index=df_train.index)\n",
        "predictions_df_train['predicted_target'] = clf.predict(df_train[embedding_col_names])\n",
        "predicted_probs = clf.predict_proba(df_train[embedding_col_names])\n",
        "for idx,col in enumerate(predicted_probs.T):\n",
        "    predictions_df_train[prob_col_names[idx]] = col\n",
        "baseline_df = pd.concat([predictions_df_train, df_train], axis=1)\n",
        "acc_baseline = sum(baseline_df['predicted_target'] == baseline_df['target'])/baseline_df.shape[0]\n",
        "print('accuracy on baseline:{:.2f}'.format(acc_baseline))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "plwP-HS4YyJ5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plwP-HS4YyJ5",
        "outputId": "c74ac33f-5aba-4979-e53f-32a0cc25f21d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on test data:0.67\n"
          ]
        }
      ],
      "source": [
        "predictions_df_test = pd.DataFrame(index=df_test.index)\n",
        "predictions_df_test['predicted_target'] = clf.predict(df_test[embedding_col_names])\n",
        "predicted_probs = clf.predict_proba(df_test[embedding_col_names])\n",
        "for idx,col in enumerate(predicted_probs.T):\n",
        "    predictions_df_test[prob_col_names[idx]] = col\n",
        "production_df = pd.concat([predictions_df_test, df_test], axis=1)\n",
        "acc_production = sum(production_df['predicted_target'] == production_df['target'])/production_df.shape[0]\n",
        "print('accuracy on test data:{:.2f}'.format(acc_production))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef407c52",
      "metadata": {
        "id": "ef407c52"
      },
      "source": [
        "# Store Data and Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efbfce5d",
      "metadata": {
        "scrolled": true,
        "id": "efbfce5d"
      },
      "outputs": [],
      "source": [
        "baseline_df.to_csv('20newsgroups_baseline',index=False)\n",
        "production_df.to_csv('20newsgroups_production',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d7c3cb5",
      "metadata": {
        "id": "7d7c3cb5"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = 'LogisticRegression_clf'\n",
        "pickle.dump(clf, open(filename, 'wb')) "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69",
        "F3ZScdVsgYzo",
        "JFzXvnYSYCcT",
        "RBVKIHG_YdrD",
        "sbUNWGfpZJrr",
        "roikR8aTmfNE",
        "30JODMh6mp1-"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}