{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c3549a",
   "metadata": {
    "id": "f0c3549a"
   },
   "source": [
    "# Onboarding IMDB Movie Reviews for NLP Explainability\n",
    "\n",
    "In this notebook, we present the steps for onboarding a model artifact to Fiddler that predicts the sentiment of IMDB movie reviews.  Fiddler is able to explain complex models with a variety of input types like unstructured text, images, and multi-modal.  \n",
    "\n",
    "Fiddler is the pioneer in enterprise Model Performance Management (MPM), offering a unified platform that enables Data Science, MLOps, Risk, Compliance, Analytics, and LOB teams to **monitor, explain, analyze, and improve ML deployments at enterprise scale**. \n",
    "Obtain contextual insights at any stage of the ML lifecycle, improve predictions, increase transparency and fairness, and optimize business revenue.\n",
    "\n",
    "---\n",
    "\n",
    "You can experience Fiddler's NLP monitoring ***in minutes*** by following these four quick steps:\n",
    "\n",
    "1. Connect to Fiddler\n",
    "2. Upload a baseline dataset\n",
    "3. Upload a model package directory containing the **1) package.py and 2) model artifact (plus any other files needed to load the model)**\n",
    "4. Explain your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1db734",
   "metadata": {
    "id": "9f1db734"
   },
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c2b2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f99c2b2f",
    "outputId": "40667583-548d-47e6-c7de-bea6b74151b8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q fiddler-client\n",
    "\n",
    "import fiddler as fdl\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"Running Fiddler client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69",
   "metadata": {
    "id": "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69"
   },
   "source": [
    "# 1. Connect to Fiddler\n",
    "\n",
    "Before you can add information about your model with Fiddler, you'll need to connect using our Python client.\n",
    "\n",
    "---\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your organization ID\n",
    "3. Your authorization token\n",
    "\n",
    "The latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21245781-c546-41de-9c18-9409361615e3",
   "metadata": {
    "id": "21245781-c546-41de-9c18-9409361615e3"
   },
   "outputs": [],
   "source": [
    "URL = ''  # Make sure to include the full URL (including https://).\n",
    "ORG_ID = ''\n",
    "AUTH_TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9678de-4d81-4b9b-905d-e2a6b0d8b141",
   "metadata": {
    "id": "cd9678de-4d81-4b9b-905d-e2a6b0d8b141"
   },
   "source": [
    "Now just run the following code block to connect the client to your Fiddler environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb4cb3-907a-4405-866e-dd4591c4957b",
   "metadata": {
    "id": "2abb4cb3-907a-4405-866e-dd4591c4957b"
   },
   "outputs": [],
   "source": [
    "client = fdl.FiddlerApi(\n",
    "    url=URL,\n",
    "    org_id=ORG_ID,\n",
    "    auth_token=AUTH_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88c43f3-1b5e-427d-92ed-307299d73bea",
   "metadata": {
    "id": "d88c43f3-1b5e-427d-92ed-307299d73bea"
   },
   "source": [
    "Once you connect, you can create a new project by specifying a unique project ID in the client's [create_project](https://docs.fiddler.ai/reference/clientcreate_project) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba61dc-a436-4186-8b07-68fa429d34d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82ba61dc-a436-4186-8b07-68fa429d34d3",
    "outputId": "e1055a05-fa15-45f8-fd78-5e20627b2417"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'imdb_explainability'\n",
    "\n",
    "if not PROJECT_ID in client.list_projects():\n",
    "    print(f'Creating project: {PROJECT_ID}')\n",
    "    client.create_project(PROJECT_ID)\n",
    "else:\n",
    "    print(f'Project: {PROJECT_ID} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900ae24-997b-4422-8349-b2a097025745",
   "metadata": {
    "id": "9900ae24-997b-4422-8349-b2a097025745"
   },
   "source": [
    "# 2. Upload a baseline dataset\n",
    "\n",
    "In this example, we'll be considering the case where we have a model that **predicts sentiment for movie reviews**.  \n",
    "  \n",
    "**Fiddler needs a small  sample of data that can serve as a baseline**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*For more information on how to design a baseline dataset, [click here](https://docs.fiddler.ai/docs/designing-a-baseline-dataset).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a715829-783e-4f72-9fcf-0ff78379ba33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "8a715829-783e-4f72-9fcf-0ff78379ba33",
    "outputId": "0031c673-d2ef-4fb7-98d6-d3248a5c5f68"
   },
   "outputs": [],
   "source": [
    "PATH_TO_BASELINE_CSV = 'https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/imdb_baseline.csv'\n",
    "\n",
    "baseline_df = pd.read_csv(PATH_TO_BASELINE_CSV)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821605b6-263d-4c95-9f0e-0812cdbc9961",
   "metadata": {
    "id": "821605b6-263d-4c95-9f0e-0812cdbc9961"
   },
   "source": [
    "Fiddler uses this baseline dataset to keep track of important information about your data.\n",
    "  \n",
    "This includes **data types**, **data ranges**, and **unique values** for categorical variables.\n",
    "\n",
    "---\n",
    "\n",
    "You can construct a [DatasetInfo](https://docs.fiddler.ai/reference/fdldatasetinfo) object to be used as **a schema for keeping track of this information** by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c15218-b987-4cf2-8f2b-e413c7aae49a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "b1c15218-b987-4cf2-8f2b-e413c7aae49a",
    "outputId": "e1d019e2-001d-428d-d599-74b608aa0ca0"
   },
   "outputs": [],
   "source": [
    "dataset_info = fdl.DatasetInfo.from_dataframe(baseline_df, max_inferred_cardinality=100)\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44dc2e6-37a0-4411-8a7e-420a12942ab4",
   "metadata": {
    "id": "a44dc2e6-37a0-4411-8a7e-420a12942ab4"
   },
   "source": [
    "Then use the client's [upload_dataset](https://docs.fiddler.ai/reference/clientupload_dataset) function to send this information to Fiddler.\n",
    "  \n",
    "*Just include:*\n",
    "1. A unique dataset ID\n",
    "2. The baseline dataset as a pandas DataFrame\n",
    "3. The `DatasetInfo` object you just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e6262-bd7d-4162-89ef-c2d1f140eb40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a47e6262-bd7d-4162-89ef-c2d1f140eb40",
    "outputId": "b1d5079a-9241-4d01-faac-50f7992fe177"
   },
   "outputs": [],
   "source": [
    "DATASET_ID = 'imdb_baseline2'\n",
    "\n",
    "client.upload_dataset(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    dataset={\n",
    "        'baseline': baseline_df\n",
    "    },\n",
    "    info=dataset_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58c04c-9735-4b16-a67e-85397debdd9d",
   "metadata": {
    "id": "7e58c04c-9735-4b16-a67e-85397debdd9d"
   },
   "source": [
    "Within your Fiddler environment's UI, you should now be able to see the newly created dataset within your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6af46-dd9b-46bf-a665-6224362bfa24",
   "metadata": {
    "id": "15c6af46-dd9b-46bf-a665-6224362bfa24"
   },
   "source": [
    "## 3. Upload your model package\n",
    "\n",
    "Now it's time to upload your model package to Fiddler.  To complete this step, we need to ensure we have the assets required to load the model and a package.py script that tells Fiddler how to call the model's prediction endpoint.  It doesn't matter what this directory is called, but for this example we will call it **/model**.  We also need a few subdirectories to house other assets needed to load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90f373-7f0a-4475-971a-d847eff7208f",
   "metadata": {
    "id": "df90f373-7f0a-4475-971a-d847eff7208f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"model\")\n",
    "os.makedirs(\"model/saved_model\")\n",
    "os.makedirs(\"model/saved_model/variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a7474-d52c-4257-8494-cc610e027804",
   "metadata": {
    "id": "e51a7474-d52c-4257-8494-cc610e027804"
   },
   "source": [
    "***Your model package directory will need to contain:***\n",
    "1. A **package.py** file which explains to Fiddler how to invoke your model's prediction endpoint\n",
    "2. And the **model artifact** and other files required to load the model\n",
    "3. A **requirements.txt** specifying which python libraries need by package.py\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1.a  Create the **model_info** object \n",
    "\n",
    "This is done by creating our [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d35d83-8548-400b-b648-88836cc9bc49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "id": "42d35d83-8548-400b-b648-88836cc9bc49",
    "outputId": "93b9c25e-3fdd-4ad0-d5df-f3a182c9ad2c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = 'polarity'\n",
    "features = ['sentence']\n",
    "output = ['sentiment']\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=client.get_dataset_info(PROJECT_ID, DATASET_ID),\n",
    "    target=target,\n",
    "    features=features,\n",
    "    input_type=fdl.ModelInputType.TEXT,\n",
    "    model_task=fdl.ModelTask.BINARY_CLASSIFICATION,\n",
    "    outputs=output,\n",
    "    display_name='IMDB Sentiment Classifier',\n",
    "    description='imdb rnn sentiment classifier',\n",
    "    preferred_explanation_method=fdl.ExplanationMethod.IG_FLEX\n",
    ")\n",
    "\n",
    "model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7c3e5",
   "metadata": {},
   "source": [
    "### 3.1.b Add Model Information to Fiddler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9VM-PLniLDg3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9VM-PLniLDg3",
    "outputId": "7388f960-f740-4f74-e915-97628153f173"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = 'imdb_rnn'\n",
    "\n",
    "client.add_model(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    model_id=MODEL_ID,\n",
    "    model_info=model_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb1f43-dd33-473d-b788-086cbbb3d10d",
   "metadata": {
    "id": "83bb1f43-dd33-473d-b788-086cbbb3d10d"
   },
   "source": [
    "### 3.2 Create the **package.py** file\n",
    "\n",
    "The contents of the cell below will be written into our ***package.py*** file.  This is the step that will be most unique based on model type, framework and use case.  The model's ***package.py*** file also allows for preprocessing transformations and other processing before the model's prediction endpoint is called.  For more information about how to create the ***package.py*** file for a variety of model tasks and frameworks, please reference the [Uploading a Model Artifact](https://docs.fiddler.ai/docs/uploading-a-model-artifact#packagepy-script) section of the Fiddler product documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0e075-34cf-425b-9fb5-d773c507cc48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fa0e075-34cf-425b-9fb5-d773c507cc48",
    "outputId": "5c3ea18d-a68c-46f0-897d-0ff183e14044"
   },
   "outputs": [],
   "source": [
    "%%writefile model/package.py\n",
    "\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "from fiddler.packtools import project_attributions_helpers, template_model\n",
    "\n",
    "# Name the output of your model here - this will need to match the model schema we define in the next notebook\n",
    "OUTPUT_COL = ['sentiment']\n",
    "\n",
    "# These are the names of the inputs of your TensorFlow model\n",
    "FEATURE_LABEL = 'sentence'\n",
    "\n",
    "MODEL_ARTIFACT_PATH = 'saved_model'\n",
    "\n",
    "TOKENIZER_PATH = 'tokenizer.pkl'\n",
    "\n",
    "ATTRIBUTABLE_LAYER_NAMES_MAPPING = {'embedding': ['sentence']}\n",
    "EMBEDDING_NAMES = ['embedding']\n",
    "\n",
    "MAX_SEQ_LENGTH = 150\n",
    "\n",
    "BATCH_INPUT_SHAPE_LIST = [(None, 150, 64)]\n",
    "\n",
    "\n",
    "class FiddlerModel(template_model.TemplateKerasTF2Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_artifact_path,\n",
    "        tokenizer_path,\n",
    "        attributable_layer_names_mapping,\n",
    "        embedding_names,\n",
    "        batch_input_shape_list,\n",
    "        output_col,\n",
    "    ):\n",
    "\n",
    "        self.model_dir = pathlib.Path(__file__).parent\n",
    "        super().__init__(\n",
    "            self.model_dir,\n",
    "            model_artifact_path,\n",
    "            attributable_layer_names_mapping,\n",
    "            output_col,\n",
    "            embedding_names,\n",
    "            batch_input_shape_list,\n",
    "        )\n",
    "\n",
    "        with open(str(self.model_dir / tokenizer_path), 'rb') as f:\n",
    "            self.tokenizer = pickle.load(f)\n",
    "\n",
    "    def get_ig_baseline(self, input_df):\n",
    "        \"\"\"This method is used to generate the baseline against which to compare the input.\n",
    "        It accepts a pandas DataFrame object containing rows of raw feature vectors that\n",
    "        need to be explained (in case e.g. the baseline must be sized according to the explain point).\n",
    "        Must return a pandas DataFrame that can be consumed by the predict method described earlier.\n",
    "        \"\"\"\n",
    "        baseline_df = input_df.copy()\n",
    "        baseline_df[FEATURE_LABEL] = input_df[FEATURE_LABEL].apply(lambda x: '')\n",
    "\n",
    "        return baseline_df\n",
    "\n",
    "    def _transform_input(self, input_df):\n",
    "        \"\"\"Helper function that accepts a pandas DataFrame object containing rows of raw feature vectors.\n",
    "        The output of this method can be any Python object. This function can also\n",
    "        be used to deserialize complex data types stored in dataset columns (e.g. arrays, or images\n",
    "        stored in a field in UTF-8 format).\n",
    "        \"\"\"\n",
    "        sequences = self.tokenizer.texts_to_sequences(input_df[FEATURE_LABEL])\n",
    "        sequences_matrix = sequence.pad_sequences(\n",
    "            sequences, maxlen=MAX_SEQ_LENGTH, padding='post'\n",
    "        )\n",
    "        return sequences_matrix.tolist()\n",
    "\n",
    "    def project_attributions(self, input_df, attributions):\n",
    "        proj_attr = project_attributions_helpers.IGTextAttributionsTF2Keras(\n",
    "            input_df, OUTPUT_COL\n",
    "        )\n",
    "        word_tokens = proj_attr.text_to_tokens_keras(\n",
    "            self.tokenizer, MAX_SEQ_LENGTH, FEATURE_LABEL\n",
    "        )\n",
    "\n",
    "        return proj_attr.get_project_attribution(\n",
    "            attributions, self.tokenizer, word_tokens, EMBEDDING_NAMES[0], FEATURE_LABEL\n",
    "        )\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    return FiddlerModel(\n",
    "        model_artifact_path=MODEL_ARTIFACT_PATH,\n",
    "        tokenizer_path=TOKENIZER_PATH,\n",
    "        attributable_layer_names_mapping=ATTRIBUTABLE_LAYER_NAMES_MAPPING,\n",
    "        embedding_names=EMBEDDING_NAMES,\n",
    "        batch_input_shape_list=BATCH_INPUT_SHAPE_LIST,\n",
    "        output_col=OUTPUT_COL,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4097b-3a18-405d-8f01-fde414fea49f",
   "metadata": {
    "id": "cda4097b-3a18-405d-8f01-fde414fea49f"
   },
   "source": [
    "### 3.3  Ensure your model's artifact is in the **/model** directory\n",
    "\n",
    "Make sure your model artifact is also present in the model package directory as well as any dependencies called out in a *requirements.txt* file.  The following cell will move this model's binary file, other required assets and our requirements.txt file into our */model* directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f8b88f-d5cf-4156-929d-751b175abf54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26f8b88f-d5cf-4156-929d-751b175abf54",
    "outputId": "b676bd1b-a62e-4da1-83ac-c46d69d8e69a"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/imdb/tokenizer.pkl\", \"model/tokenizer.pkl\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/requirements.txt\", \"model/requirements.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/imdb/saved_model/keras_metadata.pb\", \"model/saved_model/keras_metadata.pb\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/imdb/saved_model/saved_model.pb\", \"model/saved_model/saved_model.pb\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/imdb/saved_model/variables/variables.data-00000-of-00001\", \"model/saved_model/variables/variables.data-00000-of-00001\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/imdb/saved_model/variables/variables.index\", \"model/saved_model/variables/variables.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2efce",
   "metadata": {},
   "source": [
    "### 3.4 Define Model Parameters \n",
    "\n",
    "Fiddler provides extreme flexibility when onboarding a model artifact for explainability.  Each model runs in its own container with the libraries it needs as defined in the requirement.txt file.  The container is built from a base image and we can specify the compute needs our model requires.  This is done by creating our [DEPLOYMENT_PARAMETERS](https://docs.fiddler.ai/reference/fdldeploymentparams) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_PARAMETERS = fdl.DeploymentParams(image_uri=\"md-base/python/deep-learning:1.0.0\",\n",
    "                                                cpu=1000,\n",
    "                                                memory=1300,\n",
    "                                                replicas=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ddcab9-54fa-4367-92f0-b87306d14b7e",
   "metadata": {
    "id": "f8ddcab9-54fa-4367-92f0-b87306d14b7e"
   },
   "source": [
    "### Finally, upload the model package directory\n",
    "\n",
    "Once the model's artifact is in the */model* directory along with the **pacakge.py** file and requirments.txt the model package directory can be uploaded to Fiddler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff090a7-b4df-4dc0-8c1d-ac05f2f0eb3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ff090a7-b4df-4dc0-8c1d-ac05f2f0eb3f",
    "outputId": "43d22682-a361-4f65-8ad7-dcc86726f731"
   },
   "outputs": [],
   "source": [
    "client.add_model_artifact(model_dir='model/', project_id=PROJECT_ID, model_id=MODEL_ID, deployment_params=DEPLOYMENT_PARAMETERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd366b0-f40b-4e28-8325-12d429987349",
   "metadata": {
    "id": "acd366b0-f40b-4e28-8325-12d429987349"
   },
   "source": [
    "Within your Fiddler environment's UI, you should now be able to see the newly created model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e237cc-d7b6-4181-991f-ae27bf61cce3",
   "metadata": {
    "id": "25e237cc-d7b6-4181-991f-ae27bf61cce3"
   },
   "source": [
    "# 4. Explain your model\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "Now just head to your Fiddler environment's UI and check out NLP explainability for this model.  You can also run the explanation from the Fiddler client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1ad79-cb2b-414c-a32a-df43a284e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab a row from the baseline to run an explanation on\n",
    "row = baseline_df.to_dict(orient='records')[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd332b7-febc-4df0-b514-36cc9555d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = client.get_explanation(\n",
    "    project_id=PROJECT_ID,\n",
    "    model_id=MODEL_ID,\n",
    "    input_data_source=fdl.RowDataSource(row=row),\n",
    "    explanation_type='FIDDLER_SHAP'\n",
    ")\n",
    "explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f07628-f153-453d-b53a-e829e16f94ef",
   "metadata": {
    "id": "a9f07628-f153-453d-b53a-e829e16f94ef"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
    "\n",
    "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
