{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiddler Ranking Model Quick Start Guide\n",
    "\n",
    "Fiddler offer the ability for your teams to observe you ranking models to understand thier performance and catch issues like data drift before they affect your applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart: Expedia Search Ranking\n",
    "The following dataset is coming from Expedia. It includes shopping and purchase data as well as information on price competitiveness. The data are organized around a set of “search result impressions”, or the ordered list of hotels that the user sees after they search for a hotel on the Expedia website. In addition to impressions from the existing algorithm, the data contain impressions where the hotels were randomly sorted, to avoid the position bias of the existing algorithm. The user response is provided as a click on a hotel. From: https://www.kaggle.com/c/expedia-personalized-sort/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import time as time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Fiddler and Create a Project\n",
    "First we install and import the Fiddler Python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q fiddler-client\n",
    "import fiddler as fdl\n",
    "print(f\"Running client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can add information about your model with Fiddler, you'll need to connect using our API client.\n",
    "\n",
    "---\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your organization ID\n",
    "3. Your authorization token\n",
    "\n",
    "The latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = ''  # Make sure to include the full URL (including https://).\n",
    "ORG_ID = ''\n",
    "AUTH_TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the following code block to connect to the Fiddler API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = fdl.FiddlerApi(url=URL, org_id=ORG_ID, auth_token=AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you connect, you can create a new project by specifying a unique project ID in the client's `create_project` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'search_ranking_example'\n",
    "\n",
    "if not PROJECT_ID in client.list_projects():\n",
    "    print(f'Creating project: {PROJECT_ID}')\n",
    "    client.create_project(PROJECT_ID)\n",
    "else:\n",
    "    print(f'Project: {PROJECT_ID} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Upload the Baseline Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we retrieve the Expedia Dataset as a baseline for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = pd.read_csv(\"https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/expedia_baseline_data.csv\")\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiddler uses this baseline dataset to keep track of important information about your data.\n",
    "  \n",
    "This includes **data types**, **data ranges**, and **unique values** for categorical variables.\n",
    "\n",
    "---\n",
    "\n",
    "You can construct a `DatasetInfo` object to be used as **a schema for keeping track of this information** by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_info = fdl.DatasetInfo.from_dataframe(df=baseline_df, max_inferred_cardinality=100)\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use the client's [upload_dataset](https://docs.fiddler.ai/reference/clientupload_dataset) function to send this information to Fiddler!\n",
    "  \n",
    "*Just include:*\n",
    "1. A unique dataset ID\n",
    "2. The baseline dataset as a pandas DataFrame\n",
    "3. The [DatasetInfo](https://docs.fiddler.ai/reference/fdldatasetinfo) object you just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ID = 'expedia_data'\n",
    "client.upload_dataset(project_id=PROJECT_ID,\n",
    "                      dataset={'baseline': baseline_df},\n",
    "                      dataset_id=DATASET_ID,\n",
    "                      info=dataset_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Share Model Metadata and Upload the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model directory to store your model files\n",
    "import os\n",
    "model_dir = \"model\"\n",
    "os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a Adding model metadata to Fiddler\n",
    "To add a Ranking model you must specify the ModelTask as `RANKING` in the model info object.  \n",
    "\n",
    "Additionally, you must provide the `group_by` argument that corresponds to the query search id. This `group_by` column should be present either in:\n",
    "- `features` : if it is used to build and run the model\n",
    "- `metadata_cols` : if not used by the model \n",
    "\n",
    "Optionally, you can give a `ranking_top_k` number (default is 50). This will be the number of results within each query to take into account while computing the performance metrics in monitoring.  \n",
    "\n",
    "Unless the prediction column was part of your baseline dataset, you must provide the minimum and maximum values predictions can take in a dictionary format (see below).  \n",
    "\n",
    "If your target is categorical (string), you need to provide the `categorical_target_class_details` argument. If your target is numerical and you don't specify this argument, Fiddler will infer it.   \n",
    "\n",
    "This will be the list of possible values for the target **ordered**. The first element should be the least relevant target level, the last element should be the most relevant target level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'binary_relevance'\n",
    "features = list(baseline_df.drop(columns=['binary_relevance', 'score', 'graded_relevance', 'position']).columns)\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=client.get_dataset_info(project_id=PROJECT_ID, dataset_id=DATASET_ID),\n",
    "    target=target,\n",
    "    features=features,\n",
    "    input_type=fdl.ModelInputType.TABULAR,\n",
    "    model_task=fdl.ModelTask.RANKING,\n",
    "    outputs={'score':[-5.0, 3.0]},\n",
    "    group_by='srch_id',\n",
    "    ranking_top_k=20,\n",
    "    categorical_target_class_details=[0, 1]\n",
    ")\n",
    "\n",
    "# inspect model info and modify as needed\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 'expedia_model'\n",
    "\n",
    "if not MODEL_ID in client.list_models(project_id=PROJECT_ID):\n",
    "    client.add_model(\n",
    "        project_id=PROJECT_ID,\n",
    "        dataset_id=DATASET_ID,\n",
    "        model_id=MODEL_ID,\n",
    "        model_info=model_info\n",
    "    )\n",
    "else:\n",
    "    print(f'Model: {MODEL_ID} already exists in Project: {PROJECT_ID}. Please use a different name.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b Create a Model Wrapper Script\n",
    "\n",
    "Package.py is the interface between Fiddler’s backend and your model. This code helps Fiddler to understand the model, its inputs and outputs.\n",
    "\n",
    "You need to implement three parts:\n",
    "- init: Load the model, and any associated files such as feature transformers.\n",
    "- transform: If you use some pre-processing steps not part of the model file, transform the data into a format that the model recognizes.\n",
    "- predict: Make predictions using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model/package.py\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PACKAGE_PATH = Path(__file__).parent\n",
    "\n",
    "class ModelPackage:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "         Load the model file and any pre-processing files if needed.\n",
    "        \"\"\"\n",
    "        self.output_columns = ['score']\n",
    "        \n",
    "        with open(PACKAGE_PATH / 'model.pkl', 'rb') as infile:\n",
    "            self.model = pickle.load(infile)\n",
    "    \n",
    "    def transform(self, input_df):\n",
    "        \"\"\"\n",
    "        Accepts a pandas DataFrame object containing rows of raw feature vectors. \n",
    "        Use pre-processing file to transform the data if needed. \n",
    "        In this example we don't need to transform the data.\n",
    "        Outputs a pandas DataFrame object containing transformed data.\n",
    "        \"\"\"\n",
    "        return input_df\n",
    "    \n",
    "    def predict(self, input_df):\n",
    "        \"\"\"\n",
    "        Accepts a pandas DataFrame object containing rows of raw feature vectors. \n",
    "        Outputs a pandas DataFrame object containing the model predictions whose column labels \n",
    "        must match the output column names in model info.\n",
    "        \"\"\"\n",
    "        transformed_df = self.transform(input_df)\n",
    "        pred = self.model.predict(transformed_df)\n",
    "        return pd.DataFrame(pred, columns=self.output_columns)\n",
    "    \n",
    "def get_model():\n",
    "    return ModelPackage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c Retriving the model files \n",
    "\n",
    "To explain a model's inner workigs we need to upload the model artifacts. We will retrive a pre-trained model from the Fiddler Repo that was trained with **lightgbm 2.3.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/model_ranking.pkl\", \"model/model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d Upload the model files to Fiddler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now as a final step in the setup you can upload the model artifact files using `add_model_artifact`. \n",
    "   - The `model_dir` is the path for the folder containing the model file(s) and the `package.py` from ther last step.\n",
    "   - Since each model artifact uploaded to Fiddler gets deployed in its own container, the [deployment params](https://docs.fiddler.ai/reference/fdldeploymentparams) allow us to specify the compute needs and library set of the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading Model files\n",
    "deployment_params = fdl.DeploymentParams(\n",
    "    image_uri=\"md-base/python/machine-learning:1.1.0\",\n",
    "    cpu=100,\n",
    "    memory=256,\n",
    "    replicas=1,\n",
    ")\n",
    "\n",
    "client.add_model_artifact(\n",
    "    model_dir=model_dir, \n",
    "    project_id=PROJECT_ID, \n",
    "    model_id=MODEL_ID,\n",
    "    deployment_params=deployment_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Publish Events For Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.a Gather and prepare Production Events\n",
    "This is the production log file we are going to upload in Fiddler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = pd.read_csv('https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/expedia_logs.csv')\n",
    "df_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeshift the data to be current day\n",
    "df_logs['time_epoch'] = df_logs['time_epoch'] + (float(time.time()) - df_logs['time_epoch'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ranking, we need to ingest all events from a given query or search ID together. To do that, we need to transform the data to a grouped format.  \n",
    "You can use the `convert_flat_csv_data_to_grouped` utility function to do the transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs_grouped = fdl.utils.pandas_helper.convert_flat_csv_data_to_grouped(input_data=df_logs, group_by_col='srch_id')\n",
    "df_logs_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.b Publish events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.publish_events_batch(project_id=PROJECT_ID,\n",
    "                            model_id=MODEL_ID,\n",
    "                            batch_source=df_logs_grouped,\n",
    "                            timestamp_field='time_epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Get insights\n",
    "\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "You can now head to your Fiddler environment and start getting enhanced observability into your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/images/ranking_model_1.png\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
    "\n",
    "Join our [community Slack](http://fiddler-community.slack.com/) to ask any questions!\n",
    "\n",
    "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
