{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c3549a",
   "metadata": {
    "id": "f0c3549a"
   },
   "source": [
    "# Monitoring a Multiclass Classifier Model for NLP Data with Fiddler\n",
    "Unstructured data such as text are usually represented as high-dimensional vectors when processed by ML models. In this example notebook we present how [Fiddler Vector Monitoring](https://www.fiddler.ai/blog/monitoring-natural-language-processing-and-computer-vision-models-part-1) can be used to monitor NLP models using a text classification use case.\n",
    "\n",
    "Following the steps in this notebook you can see how to onboard models that deal with unstructured text inputs. In this example, we use the 20Newsgroups dataset and train a multi-class classifier that is applied to vector embeddings of text documents. \n",
    "\n",
    "We monitor this model at production time and assess the performance of Fiddler's vector monitoring by manufacturing synthetc drift via sampling from specific text categories at different deployment time intervals.\n",
    "\n",
    "---\n",
    "\n",
    "Now we perform the following steps to demonstrate how Fiddler NLP monitoring works: \n",
    "\n",
    "1. Connect to Fiddler \n",
    "2. Create a Project\n",
    "3. Upload Baseline Dataset\n",
    "4. Add Information About the Model's Schema\n",
    "5. Manufacture Synthetic Data Drift and Publish Production Events\n",
    "6. Get insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6IvnT5Rpwpcy",
   "metadata": {
    "id": "6IvnT5Rpwpcy"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380bfb82",
   "metadata": {
    "id": "380bfb82"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sbUNWGfpZJrr",
   "metadata": {
    "id": "sbUNWGfpZJrr"
   },
   "source": [
    "# 1. Connect to Fiddler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z1LoKQAouoDk",
   "metadata": {
    "id": "z1LoKQAouoDk"
   },
   "source": [
    "First we install and import the Fiddler Python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TJKuEt6oZkUy",
   "metadata": {
    "id": "TJKuEt6oZkUy",
    "outputId": "8554a7ec-d605-45d1-d3aa-5882b175dce9"
   },
   "outputs": [],
   "source": [
    "!pip install -q fiddler-client\n",
    "import fiddler as fdl\n",
    "print(f\"Running client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buFkZ_xkZgyN",
   "metadata": {
    "id": "buFkZ_xkZgyN"
   },
   "source": [
    "Before you can add information about your model with Fiddler, you'll need to connect using our API client.\n",
    "\n",
    "---\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your organization ID\n",
    "3. Your authorization token\n",
    "\n",
    "The latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e2e8d",
   "metadata": {
    "id": "a41e2e8d"
   },
   "outputs": [],
   "source": [
    "URL = ''\n",
    "ORG_ID = ''\n",
    "AUTH_TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b0fda",
   "metadata": {
    "id": "024b0fda"
   },
   "source": [
    "Next we run the following code block to connect to the Fiddler API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e583c",
   "metadata": {
    "id": "627e583c"
   },
   "outputs": [],
   "source": [
    "client = fdl.FiddlerApi(\n",
    "    url=URL,\n",
    "    org_id=ORG_ID,\n",
    "    auth_token=AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0099d99-a241-406b-97ba-05c8da60d924",
   "metadata": {},
   "source": [
    "## 2. Create a Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c513f82",
   "metadata": {
    "id": "3c513f82"
   },
   "source": [
    "Once you connect, you can create a new project by specifying a unique project ID in the client's `create_project` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CWukS_D9aEU4",
   "metadata": {
    "id": "CWukS_D9aEU4",
    "outputId": "9e46ce78-9383-4757-bf39-0a30dcde2dee"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'nlp_newsgroups'\n",
    "\n",
    "if not PROJECT_ID in client.list_projects():\n",
    "    print(f'Creating project: {PROJECT_ID}')\n",
    "    client.create_project(PROJECT_ID)\n",
    "else:\n",
    "    print(f'Project: {PROJECT_ID} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884a477",
   "metadata": {
    "id": "1884a477"
   },
   "source": [
    "## 3. Upload the Baseline Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kLTJ_yQ6z7Kk",
   "metadata": {
    "id": "kLTJ_yQ6z7Kk"
   },
   "source": [
    "Now we retrieve the 20Newsgroup dataset. This dataset is fetched from the [scikit-learn real-world datasets](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#) and pre-processed using [this notebook](https://colab.research.google.com/github/fiddler-labs/fiddler-examples/blob/main/pre-proccessing/20newsgroups_prep_vectorization.ipynb).  For simplicity sake, we have stored it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c45cddf",
   "metadata": {
    "id": "4c45cddf"
   },
   "outputs": [],
   "source": [
    "BASELINE_DATA_PATH = 'https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/baseline_nlp_text_multiclassifier.csv'\n",
    "baseline_df = pd.read_csv(BASELINE_DATA_PATH)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Tdixub9oG3S9",
   "metadata": {
    "id": "Tdixub9oG3S9"
   },
   "source": [
    "Now we create a [DatasetInfo](https://docs.fiddler.ai/reference/fdldatasetinfo) object to describe our baseline dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84084cb6",
   "metadata": {
    "id": "84084cb6",
    "outputId": "4bbaeed6-01ea-42cf-8b9e-cab94bd35d72"
   },
   "outputs": [],
   "source": [
    "dataset_info = fdl.DatasetInfo.from_dataframe(baseline_df, max_inferred_cardinality=100)\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dagjbUlUKcXW",
   "metadata": {
    "id": "dagjbUlUKcXW"
   },
   "source": [
    "Next we call the [upload_dataset()](https://docs.fiddler.ai/reference/clientupload_dataset) API to upload a baseline  to Fiddler. In addition to the baseline data, we also uploaded the whole production data framework as the 'test_data' dataset which allows us to look at the model performance metrics for unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eS3ofgYrapRm",
   "metadata": {
    "id": "eS3ofgYrapRm",
    "outputId": "5e04e87a-d2e1-4dd8-834b-120f25f5a61a"
   },
   "outputs": [],
   "source": [
    "DATASET_ID = 'newsgroups_baseline'\n",
    "\n",
    "if not DATASET_ID in client.list_datasets(project_id=PROJECT_ID):\n",
    "    print(f'Upload dataset {DATASET_ID}')\n",
    "    client.upload_dataset(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    dataset={'baseline':baseline_df},\n",
    "    info=dataset_info\n",
    ")\n",
    "else:\n",
    "    print(f'Dataset: {DATASET_ID} already exists in Project: {PROJECT_ID}.\\n'\n",
    "               'The new dataset is not uploaded. (please use a different name.)') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roikR8aTmfNE",
   "metadata": {
    "id": "roikR8aTmfNE"
   },
   "source": [
    "# 5. Add Information About the Model's Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Ex_5KxtiHs5",
   "metadata": {
    "id": "1Ex_5KxtiHs5"
   },
   "source": [
    "Next we should tell Fiddler a bit more about our model by creating a [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object that specifies the model's task, inputs, outputs, and other information such as the enrichments we want performed on our model's data.\n",
    "\n",
    "Fiddler offers a powerful set of enrichment services that we can opt in to use for to enhance how we monitor our model's performance.  In this example, we opt in to have Fiddler generate embeddings for our unstructured text.  These generated embedddings are a numerical vector that represent the content and the context of our unstructured input, \"original_text\".  These embeddings power Fiddler's vector monitoring capability for detecting drift."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bIWeThOD0XVh",
   "metadata": {
    "id": "bIWeThOD0XVh"
   },
   "source": [
    "### Opt in for Fiddler Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QJv_IGSb0jCS",
   "metadata": {
    "id": "QJv_IGSb0jCS"
   },
   "source": [
    "In addition to univariate numerical features which Fiddler monitors by default, users can define custom features and ask Fiddler to monitor them. A custom feature is specified by a group of dataset columns that need to be monitored together a a vector.\n",
    "\n",
    "Before creating a model info object, we define a custom feature using the [fdl.Enrichment()](https://docs.fiddler.ai/reference/fdlenrichment-beta) API. When creating an enrichment, a name must be assigned to the custom feature using the `name` argument. Each enrichment appears in the monitoring tab in Fiddler UI with this assigned name. Finally, the default clustering setup can be modified by passing the number of cluster centroids to the `n_clusters` argument.\n",
    "\n",
    "Here we define an [embedding fdl.Enrichment](https://docs.fiddler.ai/reference/embedding-enrichment-beta) and then use that embedding enrichment to create a [fdl.TextEnrichment](https://docs.fiddler.ai/reference/fdltextembedding) input that can be used to track drift and to be plotted in Fiddler's UMAP visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dlUZbFLya6rv",
   "metadata": {
    "id": "dlUZbFLya6rv"
   },
   "outputs": [],
   "source": [
    "fiddler_backend_enrichments = [\n",
    "    fdl.Enrichment(\n",
    "        name='Enrichment Text Embedding',\n",
    "        enrichment='embedding',\n",
    "        columns=['original_text'],\n",
    "    ),\n",
    "    fdl.TextEmbedding(\n",
    "        name='Original TextEmbedding',\n",
    "        source_column='original_text',\n",
    "        column='Enrichment Text Embedding',\n",
    "        n_clusters=6\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30JODMh6mp1-",
   "metadata": {
    "id": "30JODMh6mp1-"
   },
   "source": [
    "### Generate ModelInfo Object and Add Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hRZNx26pwTye",
   "metadata": {
    "id": "hRZNx26pwTye"
   },
   "source": [
    "Since this notebook demonstrates a monitoring-only use case and model predictions are already added to both baseline and production data, there is no need to access the model directly or to build a surrogate model and we use the [add_model()](https://docs.fiddler.ai/reference/clientadd_model) API. This requires passing a [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object which conitains information about our model's task, inputs, outputs, targets and enrichments that we would like to be monitored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p8D9FUQObBnA",
   "metadata": {
    "id": "p8D9FUQObBnA",
    "outputId": "5f013162-78e6-413d-ab7c-890ceeca1feb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_task = fdl.ModelTask.MULTICLASS_CLASSIFICATION\n",
    "model_target = 'target'\n",
    "model_outputs= [col for col in baseline_df.columns if col.startswith('prob_')]\n",
    "model_features = ['original_text']\n",
    "model_categorical_target_class_details = [col[5:] for col in model_outputs]\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=dataset_info,\n",
    "    dataset_id=DATASET_ID,\n",
    "    features=model_features,\n",
    "    target=model_target,\n",
    "    outputs=model_outputs,\n",
    "    custom_features = fiddler_backend_enrichments,\n",
    "    model_task=model_task,\n",
    "    decision_cols=['predicted_target'],\n",
    "    categorical_target_class_details=model_categorical_target_class_details,\n",
    "    metadata_cols=['n_tokens', 'string_size'],\n",
    "    description='A multi-class calssifier trained on NLP original text inputs.'\n",
    ")\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "poOvXsXzb1rz",
   "metadata": {
    "id": "poOvXsXzb1rz"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = 'logistic_regression_multiclassifier'\n",
    "\n",
    "if not MODEL_ID in client.list_models(project_id=PROJECT_ID):\n",
    "    client.add_model(\n",
    "        project_id=PROJECT_ID,\n",
    "        dataset_id=DATASET_ID,\n",
    "        model_id=MODEL_ID,\n",
    "        model_info=model_info\n",
    "    )\n",
    "else:\n",
    "    print(f'Model: {MODEL_ID} already exists in Project: {PROJECT_ID}. Please use a different name.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L6L9yGBdcVFU",
   "metadata": {
    "id": "L6L9yGBdcVFU"
   },
   "source": [
    "# 6. Manufacture Synthetic Data Drift and Publish Production Events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uWB1dDYPnRSf",
   "metadata": {
    "id": "uWB1dDYPnRSf"
   },
   "source": [
    "Now we publish some production events into Fiddler. We publish events in data batches and manually create data drift by sampling from particular newsgroups. This allows us to evaluate the effectiveness of Fiddler vector monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959a330-2713-4784-b909-e758c3131f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROD_EVENTS_DATA_PATH = 'https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/production_nlp_text_multiclassifier.csv'\n",
    "production_df = pd.read_csv(PROD_EVENTS_DATA_PATH)\n",
    "production_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8XjoPjatcfQq",
   "metadata": {
    "id": "8XjoPjatcfQq"
   },
   "outputs": [],
   "source": [
    "batch_size = 900 #number of events per (daily) bin\n",
    "event_batches_df=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZS59y4c6ck8v",
   "metadata": {
    "id": "ZS59y4c6ck8v"
   },
   "source": [
    "For sanity check, we use the baseline data as the first event batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dXt8J0xciwG",
   "metadata": {
    "id": "8dXt8J0xciwG"
   },
   "outputs": [],
   "source": [
    "event_batches_df.append(baseline_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TKE-B2WMcoos",
   "metadata": {
    "id": "TKE-B2WMcoos"
   },
   "source": [
    "Next sample from all categories (same as baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddfKZrScsmo",
   "metadata": {
    "id": "2ddfKZrScsmo"
   },
   "outputs": [],
   "source": [
    "n_intervals = 6\n",
    "for i in range(n_intervals):\n",
    "    event_batches_df.append(production_df.sample(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VjO7AtctcxB-",
   "metadata": {
    "id": "VjO7AtctcxB-"
   },
   "source": [
    "Now we generate synthetic data drift by adding event batches that are sampled from specific newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yHDujd4Hc2E7",
   "metadata": {
    "id": "yHDujd4Hc2E7"
   },
   "outputs": [],
   "source": [
    "T1 = ['computer','science','recreation']\n",
    "T2 = ['science','religion']\n",
    "T3 = ['religion']\n",
    "T4 = ['computer','science','religion','forsale']\n",
    "T5 = ['science','religion','forsale']\n",
    "T6 = ['forsale']\n",
    "synthetic_intervals = [T1,\n",
    "                       T2,\n",
    "                       T3,T3,T3,T3,\n",
    "                       T4,T4,T4,\n",
    "                       T5,T5,\n",
    "                       T6,\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4m92NT0lc4BJ",
   "metadata": {
    "id": "4m92NT0lc4BJ"
   },
   "outputs": [],
   "source": [
    "for categories in synthetic_intervals:\n",
    "    production_df_subset = production_df[production_df['target'].isin(categories)]\n",
    "    event_batches_df.append(production_df_subset.sample(batch_size, replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XFFVfF8Fc6Nj",
   "metadata": {
    "id": "XFFVfF8Fc6Nj"
   },
   "source": [
    "Add more intervals sampled from all categories (no data drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QuLXDzpqc9Pz",
   "metadata": {
    "id": "QuLXDzpqc9Pz"
   },
   "outputs": [],
   "source": [
    "n_intervals = 6\n",
    "for i in range(n_intervals):\n",
    "    event_batches_df.append(production_df.sample(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3Mj18tq6dBwG",
   "metadata": {
    "id": "3Mj18tq6dBwG"
   },
   "source": [
    "### Add Timestamp to Batches and Publish Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633adb8",
   "metadata": {
    "id": "9633adb8"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date, time \n",
    "today_beginning = datetime.combine(date.today(), time()).timestamp()\n",
    "daily_time_gap = 24*3600 #daily time gap in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a32f128",
   "metadata": {
    "id": "5a32f128"
   },
   "outputs": [],
   "source": [
    "#start from 29 days back\n",
    "timestamp= today_beginning - 29*daily_time_gap\n",
    "for event_df in event_batches_df:\n",
    "    timestamp_vec = [timestamp + random.randrange(daily_time_gap) for i in range(len(event_df))]\n",
    "    event_df['timestamp'] = timestamp_vec\n",
    "    timestamp += daily_time_gap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7QrQ_2KMdKZR",
   "metadata": {
    "id": "7QrQ_2KMdKZR"
   },
   "source": [
    "Lastly, let's publish events our events with synthetic drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197GcBxRdKGx",
   "metadata": {
    "id": "197GcBxRdKGx"
   },
   "outputs": [],
   "source": [
    "for event_df in event_batches_df:\n",
    "    client.publish_events_batch(\n",
    "        project_id=PROJECT_ID,\n",
    "        model_id=MODEL_ID,\n",
    "        batch_source=event_df,\n",
    "        timestamp_field= 'timestamp' #comment this line if you are not adding timestamps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf936e3-407b-4f1e-9374-3072930c4dc4",
   "metadata": {
    "id": "fbf936e3-407b-4f1e-9374-3072930c4dc4"
   },
   "source": [
    "# 7. Get insights\n",
    "\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "You can now head to Fiddler URL and start getting enhanced observability into your model's performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qeV8BFLe9Pby",
   "metadata": {
    "id": "qeV8BFLe9Pby"
   },
   "source": [
    "In particular, you can go to your model's default dashboard in Fiddler and check out the resulting drift chart . Bellow is a sceernshot of the data drift chart after running this notebook on the [Fiddler demo](https://demo.fiddler.ai/) deployment. (Annotation bubbles are not generated by the Fiddler UI.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b38a3-2716-486a-af95-e30f18ae1307",
   "metadata": {
    "tags": []
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/images/nlp_multiiclass_drift.png\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
