{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c3549a",
   "metadata": {
    "id": "f0c3549a"
   },
   "source": [
    "# Monitoring a Multiclass Classifier Model with Text Inputs\n",
    "Unstructured data such as text are usually represented as high-dimensional vectors when processed by ML models. In this example notebook we present how [Fiddler Vector Monitoring](https://www.fiddler.ai/blog/monitoring-natural-language-processing-and-computer-vision-models-part-1) can be used to monitor NLP models using a text classification use case.\n",
    "\n",
    "Following the steps in this notebook you can see how to onboard models that deal with unstructured text inputs. In this example, we use the 20Newsgroups dataset and train a multi-class classifier that is applied to vector embeddings of text documents. \n",
    "\n",
    "We monitor this model at production time and assess the performance of Fiddler's vector monitoring by manufacturing synthetc drift via sampling from specific text categories at different deployment time intervals.\n",
    "\n",
    "---\n",
    "\n",
    "Now we perform the following steps to demonstrate how Fiddler NLP monitoring works: \n",
    "\n",
    "1. Connect to Fiddler \n",
    "2. Create a Project\n",
    "3. Upload Baseline Dataset\n",
    "4. Add Information About the Model's Schema\n",
    "5. Manufacture Synthetic Data Drift and Publish Production Events\n",
    "6. Get insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6IvnT5Rpwpcy",
   "metadata": {
    "id": "6IvnT5Rpwpcy"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380bfb82",
   "metadata": {
    "id": "380bfb82"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sbUNWGfpZJrr",
   "metadata": {
    "id": "sbUNWGfpZJrr"
   },
   "source": [
    "# 1. Connect to Fiddler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z1LoKQAouoDk",
   "metadata": {
    "id": "z1LoKQAouoDk"
   },
   "source": [
    "First we install and import the Fiddler Python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TJKuEt6oZkUy",
   "metadata": {
    "id": "TJKuEt6oZkUy",
    "outputId": "8554a7ec-d605-45d1-d3aa-5882b175dce9"
   },
   "outputs": [],
   "source": [
    "!pip install -q fiddler-client\n",
    "import fiddler as fdl\n",
    "print(f\"Running client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buFkZ_xkZgyN",
   "metadata": {
    "id": "buFkZ_xkZgyN"
   },
   "source": [
    "Before you can add information about your model with Fiddler, you'll need to connect using our API client.\n",
    "\n",
    "---\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your organization ID\n",
    "3. Your authorization token\n",
    "\n",
    "The latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e2e8d",
   "metadata": {
    "id": "a41e2e8d"
   },
   "outputs": [],
   "source": [
    "URL = ''\n",
    "ORG_ID = ''\n",
    "AUTH_TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b0fda",
   "metadata": {
    "id": "024b0fda"
   },
   "source": [
    "Next we run the following code block to connect to the Fiddler API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e583c",
   "metadata": {
    "id": "627e583c"
   },
   "outputs": [],
   "source": [
    "client = fdl.FiddlerApi(\n",
    "    url=URL,\n",
    "    org_id=ORG_ID,\n",
    "    auth_token=AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0099d99-a241-406b-97ba-05c8da60d924",
   "metadata": {},
   "source": [
    "# 2. Create a Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c513f82",
   "metadata": {
    "id": "3c513f82"
   },
   "source": [
    "Once you connect, you can create a new project by specifying a unique project ID in the client's `create_project` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CWukS_D9aEU4",
   "metadata": {
    "id": "CWukS_D9aEU4",
    "outputId": "9e46ce78-9383-4757-bf39-0a30dcde2dee"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'nlp_newsgroups'\n",
    "\n",
    "if not PROJECT_ID in client.list_projects():\n",
    "    print(f'Creating project: {PROJECT_ID}')\n",
    "    client.create_project(PROJECT_ID)\n",
    "else:\n",
    "    print(f'Project: {PROJECT_ID} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884a477",
   "metadata": {
    "id": "1884a477"
   },
   "source": [
    "# 3. Upload the Baseline Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kLTJ_yQ6z7Kk",
   "metadata": {
    "id": "kLTJ_yQ6z7Kk"
   },
   "source": [
    "Now we retrieve the 20Newsgroup dataset. This dataset is fetched from the [scikit-learn real-world datasets](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#) and pre-processed using [this notebook](https://colab.research.google.com/github/fiddler-labs/fiddler-examples/blob/main/pre-proccessing/20newsgroups_prep_vectorization.ipynb).  For simplicity sake, we have stored it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c45cddf",
   "metadata": {
    "id": "4c45cddf"
   },
   "outputs": [],
   "source": [
    "BASELINE_DATA_PATH = 'https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/baseline_nlp_text_multiclassifier.csv'\n",
    "baseline_df = pd.read_csv(BASELINE_DATA_PATH)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Tdixub9oG3S9",
   "metadata": {
    "id": "Tdixub9oG3S9"
   },
   "source": [
    "Now we create a [DatasetInfo](https://docs.fiddler.ai/reference/fdldatasetinfo) object to describe our baseline dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84084cb6",
   "metadata": {
    "id": "84084cb6",
    "outputId": "4bbaeed6-01ea-42cf-8b9e-cab94bd35d72"
   },
   "outputs": [],
   "source": [
    "dataset_info = fdl.DatasetInfo.from_dataframe(baseline_df, max_inferred_cardinality=100)\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dagjbUlUKcXW",
   "metadata": {
    "id": "dagjbUlUKcXW"
   },
   "source": [
    "Next we call the [upload_dataset()](https://docs.fiddler.ai/reference/clientupload_dataset) API to upload a baseline  to Fiddler. In addition to the baseline data, we also uploaded the whole production data framework as the 'test_data' dataset which allows us to look at the model performance metrics for unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eS3ofgYrapRm",
   "metadata": {
    "id": "eS3ofgYrapRm",
    "outputId": "5e04e87a-d2e1-4dd8-834b-120f25f5a61a"
   },
   "outputs": [],
   "source": [
    "DATASET_ID = 'newsgroups_baseline'\n",
    "\n",
    "if not DATASET_ID in client.list_datasets(project_id=PROJECT_ID):\n",
    "    print(f'Upload dataset {DATASET_ID}')\n",
    "    client.upload_dataset(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    dataset={'baseline':baseline_df},\n",
    "    info=dataset_info\n",
    ")\n",
    "else:\n",
    "    print(f'Dataset: {DATASET_ID} already exists in Project: {PROJECT_ID}.\\n'\n",
    "               'The new dataset is not uploaded. (please use a different name.)') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roikR8aTmfNE",
   "metadata": {
    "id": "roikR8aTmfNE"
   },
   "source": [
    "# 4. Add Information About the Model's Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Ex_5KxtiHs5",
   "metadata": {
    "id": "1Ex_5KxtiHs5"
   },
   "source": [
    "Next we should tell Fiddler a bit more about our model by creating a [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object that specifies the model's task, inputs, outputs, and other information such as the enrichments we want performed on our model's data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bIWeThOD0XVh",
   "metadata": {
    "id": "bIWeThOD0XVh"
   },
   "source": [
    "### Instruct Fiddler to generate embeddings for our unstructured model input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QJv_IGSb0jCS",
   "metadata": {
    "id": "QJv_IGSb0jCS"
   },
   "source": [
    "Fiddler offers a powerful set of enrichment services that we can use to enhance how we monitor our model's performance.  In this example, we instruct Fiddler to generate embeddings for our unstructured text.  These generated embedddings are a numerical vector that represent the content and the context of our unstructured input field, _original_text_.  These embeddings then power Fiddler's vector monitoring capability for detecting drift.\n",
    "\n",
    "Before creating a [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object, we define a custom feature using the [fdl.Enrichment()](https://docs.fiddler.ai/reference/fdlenrichment-beta) API. When creating an enrichment, a name must be assigned to the custom feature using the `name` argument. Each enrichment appears in the monitoring tab in Fiddler UI with this assigned name. Finally, the default clustering setup can be modified by passing the number of cluster centroids to the `n_clusters` argument.\n",
    "\n",
    "Here we define an [embedding fdl.Enrichment](https://docs.fiddler.ai/reference/embedding-enrichment-beta) and then use that embedding enrichment to create a [fdl.TextEnrichment](https://docs.fiddler.ai/reference/fdltextembedding) input that can be used to track drift and to be plotted in Fiddler's UMAP visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dlUZbFLya6rv",
   "metadata": {
    "id": "dlUZbFLya6rv"
   },
   "outputs": [],
   "source": [
    "fiddler_backend_enrichments = [\n",
    "    fdl.Enrichment(\n",
    "        name='Enrichment Text Embedding',\n",
    "        enrichment='embedding',\n",
    "        columns=['original_text'],\n",
    "    ),\n",
    "    fdl.TextEmbedding(\n",
    "        name='Original TextEmbedding',\n",
    "        source_column='original_text',\n",
    "        column='Enrichment Text Embedding',\n",
    "        n_clusters=6\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30JODMh6mp1-",
   "metadata": {
    "id": "30JODMh6mp1-"
   },
   "source": [
    "### Generate Model_Info Object and Add Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hRZNx26pwTye",
   "metadata": {
    "id": "hRZNx26pwTye"
   },
   "source": [
    "Since this notebook demonstrates a monitoring-only use case and model predictions are already added to both baseline and production data, there is no need to access the model directly or to build a surrogate model and we use the [add_model()](https://docs.fiddler.ai/reference/clientadd_model) API. This requires passing a [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object which conitains information about our model's task, inputs, outputs, targets and enrichments that we would like to be monitored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p8D9FUQObBnA",
   "metadata": {
    "id": "p8D9FUQObBnA",
    "outputId": "5f013162-78e6-413d-ab7c-890ceeca1feb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_task = fdl.ModelTask.MULTICLASS_CLASSIFICATION\n",
    "model_target = 'target'\n",
    "model_outputs= [col for col in baseline_df.columns if col.startswith('prob_')]\n",
    "model_features = ['original_text']\n",
    "model_categorical_target_class_details = [col[5:] for col in model_outputs]\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=dataset_info,\n",
    "    dataset_id=DATASET_ID,\n",
    "    features=model_features,\n",
    "    target=model_target,\n",
    "    outputs=model_outputs,\n",
    "    custom_features = fiddler_backend_enrichments,\n",
    "    model_task=model_task,\n",
    "    decision_cols=['predicted_target'],\n",
    "    categorical_target_class_details=model_categorical_target_class_details,\n",
    "    metadata_cols=['n_tokens', 'string_size'],\n",
    "    description='A multi-class calssifier trained on NLP original text inputs.'\n",
    ")\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "poOvXsXzb1rz",
   "metadata": {
    "id": "poOvXsXzb1rz"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = 'logistic_regression_multiclassifier'\n",
    "\n",
    "if not MODEL_ID in client.list_models(project_id=PROJECT_ID):\n",
    "    client.add_model(\n",
    "        project_id=PROJECT_ID,\n",
    "        dataset_id=DATASET_ID,\n",
    "        model_id=MODEL_ID,\n",
    "        model_info=model_info\n",
    "    )\n",
    "else:\n",
    "    print(f'Model: {MODEL_ID} already exists in Project: {PROJECT_ID}. Please use a different name.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L6L9yGBdcVFU",
   "metadata": {
    "id": "L6L9yGBdcVFU"
   },
   "source": [
    "# 5. Manufacture Synthetic Data Drift and Publish Production Events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uWB1dDYPnRSf",
   "metadata": {
    "id": "uWB1dDYPnRSf"
   },
   "source": [
    "Now we publish some production events into Fiddler. We publish events in data batches and manually create data drift by sampling from particular newsgroups. This allows us to evaluate the effectiveness of Fiddler vector monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c959a330-2713-4784-b909-e758c3131f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_target</th>\n",
       "      <th>prob_computer</th>\n",
       "      <th>prob_forsale</th>\n",
       "      <th>prob_recreation</th>\n",
       "      <th>prob_religion</th>\n",
       "      <th>prob_science</th>\n",
       "      <th>original_text</th>\n",
       "      <th>original_target</th>\n",
       "      <th>target</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>string_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.076641</td>\n",
       "      <td>0.060584</td>\n",
       "      <td>0.568645</td>\n",
       "      <td>0.108312</td>\n",
       "      <td>0.185817</td>\n",
       "      <td>Saku isn't that small any longer I guess I hea...</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>recreation</td>\n",
       "      <td>22</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer</td>\n",
       "      <td>0.944998</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.018384</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.020182</td>\n",
       "      <td>Has anyone had problems with Ami Pro 3.0 after...</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>computer</td>\n",
       "      <td>204</td>\n",
       "      <td>1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forsale</td>\n",
       "      <td>0.080242</td>\n",
       "      <td>0.599389</td>\n",
       "      <td>0.164612</td>\n",
       "      <td>0.013835</td>\n",
       "      <td>0.141921</td>\n",
       "      <td>Whistler Spectrum 2-SE.  X, K, Ka.  Pulse prot...</td>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>forsale</td>\n",
       "      <td>20</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>science</td>\n",
       "      <td>0.057480</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>0.045148</td>\n",
       "      <td>0.038236</td>\n",
       "      <td>0.836596</td>\n",
       "      <td>:Thousands?  Tens of thousands?  Do some arith...</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>science</td>\n",
       "      <td>55</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>religion</td>\n",
       "      <td>0.036691</td>\n",
       "      <td>0.021405</td>\n",
       "      <td>0.104772</td>\n",
       "      <td>0.772644</td>\n",
       "      <td>0.064488</td>\n",
       "      <td>Being a parent in need of some help, I ask tha...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>religion</td>\n",
       "      <td>589</td>\n",
       "      <td>3207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6994</th>\n",
       "      <td>computer</td>\n",
       "      <td>0.785213</td>\n",
       "      <td>0.032077</td>\n",
       "      <td>0.046269</td>\n",
       "      <td>0.025683</td>\n",
       "      <td>0.110758</td>\n",
       "      <td>wing the suggestion of Stu Lynne, I have poste...</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>computer</td>\n",
       "      <td>19</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>science</td>\n",
       "      <td>0.067842</td>\n",
       "      <td>0.041828</td>\n",
       "      <td>0.151476</td>\n",
       "      <td>0.190409</td>\n",
       "      <td>0.548445</td>\n",
       "      <td>As many people have mentioned, there is no rea...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>religion</td>\n",
       "      <td>113</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>computer</td>\n",
       "      <td>0.834109</td>\n",
       "      <td>0.032805</td>\n",
       "      <td>0.046836</td>\n",
       "      <td>0.021237</td>\n",
       "      <td>0.065012</td>\n",
       "      <td>Hmmmmmm...I got my comp with windows pre-insta...</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>computer</td>\n",
       "      <td>53</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>computer</td>\n",
       "      <td>0.933943</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>0.008445</td>\n",
       "      <td>0.034915</td>\n",
       "      <td>Well, the temp file thing creates an obvious p...</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>computer</td>\n",
       "      <td>38</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>recreation</td>\n",
       "      <td>0.046934</td>\n",
       "      <td>0.031574</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.040050</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>DS&gt;From: viking@iastate.edu (Dan Sorenson)   D...</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>recreation</td>\n",
       "      <td>1172</td>\n",
       "      <td>4693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6999 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted_target  prob_computer  prob_forsale  prob_recreation  \\\n",
       "0          recreation       0.076641      0.060584         0.568645   \n",
       "1            computer       0.944998      0.011931         0.018384   \n",
       "2             forsale       0.080242      0.599389         0.164612   \n",
       "3             science       0.057480      0.022540         0.045148   \n",
       "4            religion       0.036691      0.021405         0.104772   \n",
       "...               ...            ...           ...              ...   \n",
       "6994         computer       0.785213      0.032077         0.046269   \n",
       "6995          science       0.067842      0.041828         0.151476   \n",
       "6996         computer       0.834109      0.032805         0.046836   \n",
       "6997         computer       0.933943      0.011013         0.011684   \n",
       "6998       recreation       0.046934      0.031574         0.782716   \n",
       "\n",
       "      prob_religion  prob_science  \\\n",
       "0          0.108312      0.185817   \n",
       "1          0.004506      0.020182   \n",
       "2          0.013835      0.141921   \n",
       "3          0.038236      0.836596   \n",
       "4          0.772644      0.064488   \n",
       "...             ...           ...   \n",
       "6994       0.025683      0.110758   \n",
       "6995       0.190409      0.548445   \n",
       "6996       0.021237      0.065012   \n",
       "6997       0.008445      0.034915   \n",
       "6998       0.040050      0.098726   \n",
       "\n",
       "                                          original_text  \\\n",
       "0     Saku isn't that small any longer I guess I hea...   \n",
       "1     Has anyone had problems with Ami Pro 3.0 after...   \n",
       "2     Whistler Spectrum 2-SE.  X, K, Ka.  Pulse prot...   \n",
       "3     :Thousands?  Tens of thousands?  Do some arith...   \n",
       "4     Being a parent in need of some help, I ask tha...   \n",
       "...                                                 ...   \n",
       "6994  wing the suggestion of Stu Lynne, I have poste...   \n",
       "6995  As many people have mentioned, there is no rea...   \n",
       "6996  Hmmmmmm...I got my comp with windows pre-insta...   \n",
       "6997  Well, the temp file thing creates an obvious p...   \n",
       "6998  DS>From: viking@iastate.edu (Dan Sorenson)   D...   \n",
       "\n",
       "               original_target      target  n_tokens  string_size  \n",
       "0             rec.sport.hockey  recreation        22          106  \n",
       "1      comp.os.ms-windows.misc    computer       204         1087  \n",
       "2                 misc.forsale     forsale        20          107  \n",
       "3                    sci.crypt     science        55          303  \n",
       "4       soc.religion.christian    religion       589         3207  \n",
       "...                        ...         ...       ...          ...  \n",
       "6994             comp.graphics    computer        19          112  \n",
       "6995        talk.religion.misc    religion       113          647  \n",
       "6996  comp.sys.ibm.pc.hardware    computer        53          284  \n",
       "6997             comp.graphics    computer        38          221  \n",
       "6998           rec.motorcycles  recreation      1172         4693  \n",
       "\n",
       "[6999 rows x 11 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROD_EVENTS_DATA_PATH = 'https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/production_nlp_text_multiclassifier.csv'\n",
    "production_df = pd.read_csv(PROD_EVENTS_DATA_PATH)\n",
    "production_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8XjoPjatcfQq",
   "metadata": {
    "id": "8XjoPjatcfQq"
   },
   "outputs": [],
   "source": [
    "batch_size = 900 #number of events per (daily) bin\n",
    "event_batches_df=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZS59y4c6ck8v",
   "metadata": {
    "id": "ZS59y4c6ck8v"
   },
   "source": [
    "For sanity check, we use the baseline data as the first event batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8dXt8J0xciwG",
   "metadata": {
    "id": "8dXt8J0xciwG"
   },
   "outputs": [],
   "source": [
    "event_batches_df.append(baseline_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TKE-B2WMcoos",
   "metadata": {
    "id": "TKE-B2WMcoos"
   },
   "source": [
    "Next sample from all categories (same as baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ddfKZrScsmo",
   "metadata": {
    "id": "2ddfKZrScsmo"
   },
   "outputs": [],
   "source": [
    "n_intervals = 6\n",
    "for i in range(n_intervals):\n",
    "    event_batches_df.append(production_df.sample(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VjO7AtctcxB-",
   "metadata": {
    "id": "VjO7AtctcxB-"
   },
   "source": [
    "Now we generate synthetic data drift by adding event batches that are sampled from specific newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "yHDujd4Hc2E7",
   "metadata": {
    "id": "yHDujd4Hc2E7"
   },
   "outputs": [],
   "source": [
    "T1 = ['computer','science','recreation']\n",
    "T2 = ['science','religion']\n",
    "T3 = ['religion']\n",
    "T4 = ['computer','science','religion','forsale']\n",
    "T5 = ['science','religion','forsale']\n",
    "T6 = ['forsale']\n",
    "synthetic_intervals = [T1,\n",
    "                       T2,\n",
    "                       T3,T3,T3,T3,\n",
    "                       T4,T4,T4,\n",
    "                       T5,T5,\n",
    "                       T6,\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4m92NT0lc4BJ",
   "metadata": {
    "id": "4m92NT0lc4BJ"
   },
   "outputs": [],
   "source": [
    "for categories in synthetic_intervals:\n",
    "    production_df_subset = production_df[production_df['target'].isin(categories)]\n",
    "    event_batches_df.append(production_df_subset.sample(batch_size, replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XFFVfF8Fc6Nj",
   "metadata": {
    "id": "XFFVfF8Fc6Nj"
   },
   "source": [
    "Add more intervals sampled from all categories (no data drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "QuLXDzpqc9Pz",
   "metadata": {
    "id": "QuLXDzpqc9Pz"
   },
   "outputs": [],
   "source": [
    "n_intervals = 6\n",
    "for i in range(n_intervals):\n",
    "    event_batches_df.append(production_df.sample(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3Mj18tq6dBwG",
   "metadata": {
    "id": "3Mj18tq6dBwG"
   },
   "source": [
    "### Add Timestamp to Batches and Publish Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9633adb8",
   "metadata": {
    "id": "9633adb8"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date, time \n",
    "today_beginning = datetime.combine(date.today(), time()).timestamp()\n",
    "daily_time_gap = 24*3600 #daily time gap in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a32f128",
   "metadata": {
    "id": "5a32f128"
   },
   "outputs": [],
   "source": [
    "#start from 29 days back\n",
    "timestamp= today_beginning - 29*daily_time_gap\n",
    "for event_df in event_batches_df:\n",
    "    timestamp_vec = [timestamp + random.randrange(daily_time_gap) for i in range(len(event_df))]\n",
    "    event_df['timestamp'] = timestamp_vec\n",
    "    timestamp += daily_time_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c3df5f7-6fd8-4243-877c-4ad32a846e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_new_df = pd.DataFrame()\n",
    "# for event_df in event_batches_df:\n",
    "#     event_new_df = pd.concat(event_new_df, event_df)\n",
    "\n",
    "# event_new_df\n",
    "\n",
    "concatenated_df = pd.concat(event_batches_df)\n",
    "concatenated_df.to_csv('production_nlp_text_multiclassifier.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7QrQ_2KMdKZR",
   "metadata": {
    "id": "7QrQ_2KMdKZR"
   },
   "source": [
    "Lastly, let's publish events our events with synthetic drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197GcBxRdKGx",
   "metadata": {
    "id": "197GcBxRdKGx"
   },
   "outputs": [],
   "source": [
    "for event_df in event_batches_df:\n",
    "    client.publish_events_batch(\n",
    "        project_id=PROJECT_ID,\n",
    "        model_id=MODEL_ID,\n",
    "        batch_source=event_df,\n",
    "        timestamp_field= 'timestamp' #comment this line if you are not adding timestamps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf936e3-407b-4f1e-9374-3072930c4dc4",
   "metadata": {
    "id": "fbf936e3-407b-4f1e-9374-3072930c4dc4"
   },
   "source": [
    "# 6. Get insights\n",
    "\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "You can now head to Fiddler URL and start getting enhanced observability into your model's performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qeV8BFLe9Pby",
   "metadata": {
    "id": "qeV8BFLe9Pby"
   },
   "source": [
    "In particular, you can go to your model's default dashboard in Fiddler and check out the resulting drift chart . Bellow is a sceernshot of the data drift chart after running this notebook on the [Fiddler demo](https://demo.fiddler.ai/) deployment. (Annotation bubbles are not generated by the Fiddler UI.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b38a3-2716-486a-af95-e30f18ae1307",
   "metadata": {
    "tags": []
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/images/nlp_multiiclass_drift.png\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
