{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sF3cOBoVx9Ji"
   },
   "source": [
    "# Fiddler LLM Application Quick Start Guide\n",
    "\n",
    "Fiddler is the pioneer in enterprise AI Observability, offering a unified platform that enables all model stakeholders to monitor model performance and to investigate the true source of model degredation.  Fiddler's AI Observability platform supports both traditional ML models as well as Generative AI applications.  This guide walks you through how to onboard a LLM chatbot application that is built using a RAG architecture.\n",
    "\n",
    "---\n",
    "\n",
    "You can start using Fiddler ***in minutes*** by following these 8 quick steps:\n",
    "\n",
    "1. Imports\n",
    "2. Connect to Fiddler\n",
    "3. Create a Fiddler project\n",
    "4. Upload a baseline dataset\n",
    "5. Opt-in to specific Fiddler's LLM Enrichments\n",
    "6. Add information about the LLM application\n",
    "7. Publish LLM inputs and outputs\n",
    "8. Get insights\n",
    "\n",
    "**Don't have a Fiddler account? [Sign-up for a 14-day free trial](https://www.fiddler.ai/trial?utm_source=fiddler_docs&utm_medium=referral).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUZi_5s7wsGA"
   },
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T19:02:01.749620Z",
     "start_time": "2023-07-27T19:01:56.285723Z"
    },
    "id": "Pg-BdRJ4w3LM"
   },
   "outputs": [],
   "source": [
    "!pip install -q fiddler-client\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time as time\n",
    "import fiddler as fdl\n",
    "import datetime\n",
    "\n",
    "print(f\"Running client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcP0yWfV1GoZ"
   },
   "source": [
    "## 2. Connect to Fiddler\n",
    "\n",
    "Before you can add information about your LLM application with Fiddler, you'll need to connect using our API client.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your organization ID\n",
    "3. Your authorization token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T19:02:01.753366Z",
     "start_time": "2023-07-27T19:02:01.751323Z"
    },
    "id": "05hPBZHr1eBv"
   },
   "outputs": [],
   "source": [
    "URL = ''\n",
    "ORG_ID = ''\n",
    "AUTH_TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2B7cgPa2Ajo"
   },
   "source": [
    "These parameters can be found on the **Settings** page of your Fiddler environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EttApX9BBIn"
   },
   "source": [
    "Now just run the following code block to connect to the Fiddler API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T19:02:58.459534Z",
     "start_time": "2023-07-27T19:02:57.976152Z"
    },
    "id": "g6ONUHliBAsH"
   },
   "outputs": [],
   "source": [
    "client = fdl.FiddlerApi(url=URL, org_id=ORG_ID, auth_token=AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpUHeE3dBTHD"
   },
   "source": [
    "## 3. Create a Fiddler Project\n",
    "\n",
    "Once you connect, you can create a new project by specifying a unique project ID in the client's `add_project` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T19:02:34.637727Z",
     "start_time": "2023-07-27T19:02:34.590808Z"
    },
    "id": "CWErNsofAz6B"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'fiddler_chatbot'\n",
    "DATASET_ID = 'fiddler_chatbot_history'\n",
    "MODEL_ID = 'rag_chatbot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T18:54:19.978019Z",
     "start_time": "2023-07-27T18:54:19.874012Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.add_project(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3V2EhIdwA_Q"
   },
   "source": [
    "## 4. Upload a baseline dataset\n",
    "\n",
    "In this example, we'll be onboarding data in order to observe our **Fiddler chatbot application**.  Any Fiddler AI application under observation must first establish a baseline dataset that establishes what the data should look like.   \n",
    "  \n",
    "In order to get insights into the model's performance, **Fiddler needs a small sample of data that can serve as a baseline** for making comparisons with data in production.  Let's use a file with some historical prompts, source docs, and responses from our Fiddler chatbot for our baseline.\n",
    "\n",
    "---\n",
    "\n",
    "*For more information on how to design a baseline dataset, [click here](https://docs.fiddler.ai/docs/designing-a-baseline-dataset).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_BASELINE_CSV = 'https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/chatbot_llm_baseline.csv'\n",
    "\n",
    "baseline_df = pd.read_csv(PATH_TO_BASELINE_CSV)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niKle55HCgIj"
   },
   "source": [
    "Fiddler uses this baseline dataset to keep track of important information about your data.  This includes **data types**, **data ranges**, and **unique values** for categorical variables.\n",
    "\n",
    "---\n",
    "\n",
    "You can construct a `DatasetInfo` object to be used as **a schema for keeping track of this information** by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T20:11:06.219352Z",
     "start_time": "2023-07-19T20:11:06.173582Z"
    },
    "id": "TI_x9-T93G-v"
   },
   "outputs": [],
   "source": [
    "dataset_info = fdl.DatasetInfo.from_dataframe(baseline_df, max_inferred_cardinality=5)\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use the client's [upload_dataset](https://docs.fiddler.ai/reference/clientupload_dataset) function to send this information to Fiddler.\n",
    "  \n",
    "*Just include:*\n",
    "1. A unique dataset ID\n",
    "2. The baseline dataset as a pandas DataFrame\n",
    "3. The [DatasetInfo](https://docs.fiddler.ai/reference/fdldatasetinfo) object you just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T18:55:05.429945Z",
     "start_time": "2023-07-27T18:55:05.407413Z"
    },
    "id": "Nk0Bpus92oJK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.upload_dataset(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    dataset={\n",
    "        'baseline': baseline_df\n",
    "    },\n",
    "    info=dataset_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Opt-in to specific Fiddler LLM Enrichments\n",
    "\n",
    "After publishing our chatbot's prompts and responses to our Fiddler environment, we can request that Fiddler execute a series of enrichment services that can \"score\" our prompts and responses for a variety of insights.  These enrichment services can detect AI safety issues like PII leakage, hallucinations, toxicity, and more.  We can also opt-in for enrichment services like embedding generation which will allow us to track prompt and response outliers and drift.  A full description of these enrichments can be found here.\n",
    "\n",
    "---\n",
    "\n",
    "Let's define the enrichment services we'd like to use.  Here we will opt in for embedding generation for our prompts, responses and source docs.  Additionally, let's opt in for PII detection, outlier detection through centroid distance metrics, and some other text based evaluation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiddler_llm_enrichments = [\n",
    "    fdl.Enrichment(\n",
    "        name='Enrichment Prompt Embedding',\n",
    "        enrichment='embedding',\n",
    "        columns=['question'],\n",
    "    ),\n",
    "    fdl.TextEmbedding(\n",
    "        name='Prompt TextEmbedding',\n",
    "        source_column='question',\n",
    "        column='Enrichment Prompt Embedding',\n",
    "        n_tags=10\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Enrichment Prompt Centroid Distance',\n",
    "        enrichment='centroid_distance',\n",
    "        columns=['Prompt TextEmbedding'],\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Enrichment Source Docs Embedding',\n",
    "        enrichment='embedding',\n",
    "        columns=['source_docs'],\n",
    "    ),\n",
    "    fdl.TextEmbedding(\n",
    "        name='Source Docs TextEmbedding',\n",
    "        source_column='source_docs',\n",
    "        column='Enrichment Source Docs Embedding',\n",
    "        n_tags=10\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Enrichment Source Docs Centroid Distance',\n",
    "        enrichment='centroid_distance',\n",
    "        columns=['Source Docs TextEmbedding'],\n",
    "    ),    \n",
    "     fdl.Enrichment(\n",
    "        name='Enrichment Response Embedding',\n",
    "        enrichment='embedding',\n",
    "        columns=['response'],\n",
    "    ),\n",
    "    fdl.TextEmbedding(\n",
    "        name='Response TextEmbedding',\n",
    "        source_column='response',\n",
    "        column='Enrichment Response Embedding',\n",
    "        n_tags=10\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Enrichment Response Centroid Distance',\n",
    "        enrichment='centroid_distance',\n",
    "        columns=['Response TextEmbedding'],\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Enrichment QA TextStat',\n",
    "        enrichment='textstat',\n",
    "        columns=['question', 'response'],\n",
    "        config={'statistics': [\n",
    "                'char_count',\n",
    "                'flesch_reading_ease',\n",
    "                'flesch_kincaid_grade',\n",
    "            ]\n",
    "        }\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Enrichment QA Sentiment',\n",
    "        enrichment='sentiment',\n",
    "        columns=['question', 'response'],\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Faithfulness',\n",
    "        enrichment='faithfulness',\n",
    "        columns=['response', 'source_docs'],\n",
    "        config={\n",
    "            'response' : 'response',\n",
    "            'context' : ['source_docs'],\n",
    "        }\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Answer Relevance',\n",
    "        enrichment='answer_relevance',\n",
    "        columns=['question', 'response'],\n",
    "        config={\n",
    "            'prompt' : 'question',\n",
    "            'response' : 'response',\n",
    "        }\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Coherence',\n",
    "        enrichment='coherence',\n",
    "        columns=['response'],\n",
    "        config={\n",
    "            'response' : 'response',\n",
    "        }\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Conciseness',\n",
    "        enrichment='conciseness',\n",
    "        columns=['response'],\n",
    "        config={\n",
    "            'response' : 'response',\n",
    "        }\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Toxicity',\n",
    "        enrichment='toxicity',\n",
    "        columns=['question', 'response'],\n",
    "    ),\n",
    "    fdl.Enrichment(\n",
    "        name='Regex - only digits',\n",
    "        enrichment='regex_match',\n",
    "        columns=['question', 'response'],\n",
    "        config = {\n",
    "            'regex' : '^\\d+$',\n",
    "        }\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.  Add information about the LLM application\n",
    "\n",
    "Now it's time to onboard information about our LLM application to Fiddler.  We do this by defining a [ModelInfo](https://docs.fiddler.ai/reference/fdlmodelinfo) object.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "The [ModelInfo](https://docs.fiddler.ai/reference/fdlmodelinfo) object will contain some **information about how your LLM application operates**.\n",
    "  \n",
    "*Just include:*\n",
    "1. The **dataset_info** object which defines our data types and columns\n",
    "2. The **dataset_id** of our baseline dataset.  The baseline dataset will also be enriched during this step based on the enrichments we've configured.\n",
    "3. The **task** your model is performing (LLM, regression, binary classification, etc.)\n",
    "4. The **features** columns.  For a LLM application, these are just the raw inputs and outputs of our LLM application.\n",
    "5. The **custom_features** which contain the configuration of the enrichments we opted for.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=dataset_info,\n",
    "    dataset_id='baseline',\n",
    "    model_task=fdl.ModelTask.LLM,\n",
    "    features=['question', 'response', 'source_docs'],\n",
    "    target='feedback',\n",
    "    metadata_cols = ['comment'],\n",
    "    custom_features=fiddler_llm_enrichments\n",
    ")\n",
    "model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azE_UU6HE6vW"
   },
   "source": [
    "Almost done! Now just specify a unique model ID and use the client's [add_model](https://docs.fiddler.ai/reference/clientadd_model) function to send this information to Fiddler.  This step can take a little longer as the baseline dataset will also be enriched with the LLM enrichments we chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T18:54:59.368286Z",
     "start_time": "2023-07-27T18:54:59.358977Z"
    },
    "id": "HMDG9vei24pw"
   },
   "outputs": [],
   "source": [
    "client.add_model(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    model_id=MODEL_ID,\n",
    "    model_info=model_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Publish LLM inputs and outputs\n",
    "\n",
    "Information about our LLM application is onboarded to Fiddler and now it's time to start publishing some input and output data from your LLM application!  \n",
    "Fiddler will **monitor this data and compare it to your baseline to generate powerful insights into how your application is behaving**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Each record sent to Fiddler is called **an event**.  Events simply contain the inputs and outputs of a predictive model or LLM application.\n",
    "  \n",
    "Let's load in some sample events (prompts and responses) from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_EVENTS_CSV = 'https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/chatbot_llm_events.csv'\n",
    "\n",
    "llm_events_df = pd.read_csv(PATH_TO_EVENTS_CSV)\n",
    " \n",
    "# Timeshifting the timestamp column in the events file so the events are as recent as today\n",
    "llm_events_df['ts'] = pd.to_datetime(llm_events_df['ts'])\n",
    "time_diff = pd.Timestamp.now().normalize() - llm_events_df['ts'].max()\n",
    "llm_events_df['ts'] += time_diff\n",
    "\n",
    "llm_events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the client's `publish_events_batch` function to start pumping data into Fiddler!\n",
    "  \n",
    "*Just include:*\n",
    "1. The DataFrame containing your events\n",
    "2. The name of the column containing event timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.publish_events_batch(\n",
    "    project_id=PROJECT_ID,\n",
    "    model_id=MODEL_ID,\n",
    "    batch_source=llm_events_df,\n",
    "    timestamp_field='ts'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Get insights\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "You can now head to your Fiddler environment and start getting enhanced observability into your LLM application's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/images/LLM_chatbot_UMAP.png\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jdkj1eHgOTAO"
   },
   "source": [
    "**What's Next?**\n",
    "\n",
    "Try the [NLP Monitoring - Quickstart Notebook](https://docs.fiddler.ai/docs/simple-nlp-monitoring-quick-start)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
    "\n",
    "Join our [community Slack](http://fiddler-community.slack.com/) to ask any questions!\n",
    "\n",
    "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
