{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c3549a",
   "metadata": {
    "id": "f0c3549a"
   },
   "source": [
    "# Adding a Model Artifact\n",
    "\n",
    "In this notebook, we present the steps for onboarding a model with its model artifact.  When Fiddler is provided with your real model artifact, it can produce high-fidelity explanations.  In contrast, models within Fiddler that use a surrogate model or no model artifact at all provide approximative explainability or no explainability at all.\n",
    "\n",
    "Fiddler is the pioneer in enterprise A Observability, offering a unified platform that enables Data Science, MLOps, Risk, Compliance, Analytics, and LOB teams to **monitor, explain, analyze, and improve AI deployments at enterprise scale**. \n",
    "Obtain contextual insights at any stage of the ML lifecycle, improve predictions, increase transparency and fairness, and optimize business revenue.\n",
    "\n",
    "---\n",
    "\n",
    "You can experience Fiddler's NLP monitoring ***in minutes*** by following these five quick steps:\n",
    "\n",
    "\n",
    "1. Connect to Fiddler\n",
    "2. Define Your Model Specifications\n",
    "3. Add Your Model\n",
    "4. Upload The Model Package \n",
    "5. Publish Production Events and Get Insights (including high-fidelity explainability, or XAI!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1db734",
   "metadata": {
    "id": "9f1db734"
   },
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c2b2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f99c2b2f",
    "outputId": "40667583-548d-47e6-c7de-bea6b74151b8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q fiddler-client\n",
    "\n",
    "import fiddler as fdl\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"Running Fiddler client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69",
   "metadata": {
    "id": "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69"
   },
   "source": [
    "# 1. Connect to Fiddler\n",
    "\n",
    "Before you can add information about your model with Fiddler, you'll need to connect using our Python client.\n",
    "\n",
    "---\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "3. Your authorization token\n",
    "\n",
    "The latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21245781-c546-41de-9c18-9409361615e3",
   "metadata": {
    "id": "21245781-c546-41de-9c18-9409361615e3"
   },
   "outputs": [],
   "source": [
    "URL = ''  # Make sure to include the full URL (including https://).\n",
    "TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9678de-4d81-4b9b-905d-e2a6b0d8b141",
   "metadata": {
    "id": "cd9678de-4d81-4b9b-905d-e2a6b0d8b141"
   },
   "source": [
    "Now just run the following code block to connect the client to your Fiddler environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb4cb3-907a-4405-866e-dd4591c4957b",
   "metadata": {
    "id": "2abb4cb3-907a-4405-866e-dd4591c4957b"
   },
   "outputs": [],
   "source": [
    "fdl.init(\n",
    "    url=URL,\n",
    "    token=TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88c43f3-1b5e-427d-92ed-307299d73bea",
   "metadata": {
    "id": "d88c43f3-1b5e-427d-92ed-307299d73bea"
   },
   "source": [
    "Once you connect, you can create a new project by specifying a project name using Fiddler's [Project API](https://docs.fiddler.ai/client-guide/create-a-project-and-model#create-a-project) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba61dc-a436-4186-8b07-68fa429d34d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82ba61dc-a436-4186-8b07-68fa429d34d3",
    "outputId": "e1055a05-fa15-45f8-fd78-5e20627b2417"
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'simple_model_artifact_upload'\n",
    "\n",
    "project = fdl.Project(\n",
    "    name=PROJECT_NAME)\n",
    "\n",
    "project.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900ae24-997b-4422-8349-b2a097025745",
   "metadata": {
    "id": "9900ae24-997b-4422-8349-b2a097025745"
   },
   "source": [
    "# 2. Define your model specifications\n",
    "\n",
    "In this example, we'll be considering the case where we're a bank and we have **a model that predicts credit approval worthiness**.\n",
    "  \n",
    "In order to get insights into the model's performance, **Fiddler needs a small  sample of data that can serve as a baseline** for making comparisons with data in production.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*For more information on how to design a sample dataset, [click here](https://docs.fiddler.ai/client-guide/creating-a-baseline-dataset).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a715829-783e-4f72-9fcf-0ff78379ba33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "8a715829-783e-4f72-9fcf-0ff78379ba33",
    "outputId": "0031c673-d2ef-4fb7-98d6-d3248a5c5f68"
   },
   "outputs": [],
   "source": [
    "PATH_TO_SAMPLE_CSV = 'https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/data/v3/churn_data_sample.csv'\n",
    "\n",
    "sample_df = pd.read_csv(PATH_TO_SAMPLE_CSV)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821605b6-263d-4c95-9f0e-0812cdbc9961",
   "metadata": {
    "id": "821605b6-263d-4c95-9f0e-0812cdbc9961"
   },
   "source": [
    "### 2.a Define Model Specification\n",
    "In order to add your model to Fiddler, simply create a ModelSpec object with information about what each column of your data sample should used for.\n",
    "\n",
    "Fiddler supports four column types:\n",
    "1. **Inputs**\n",
    "2. **Outputs** (Model predictions)\n",
    "3. **Targets** (Ground truth values)\n",
    "4. **Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42645ddd-f4ed-444a-8a5f-80c1e784a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec = fdl.ModelSpec(\n",
    "    inputs=[\n",
    "        'creditscore',\n",
    "        'geography',\n",
    "        'gender',\n",
    "        'age',\n",
    "        'tenure',\n",
    "        'balance',\n",
    "        'numofproducts',\n",
    "        'hascrcard',\n",
    "        'isactivemember',\n",
    "        'estimatedsalary'\n",
    "    ],\n",
    "    outputs=['predicted_churn'],\n",
    "    targets=['churn'],\n",
    "    metadata=['customer_id', 'timestamp']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458bc93e-c284-45d8-972c-c8f477aa3e4e",
   "metadata": {},
   "source": [
    "If you have columns in your ModelSpec that denote prediction IDs or timestamps, then Fiddler can use these to power its analytics accordingly. Let's define those as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ccc5e-67ef-4445-82f7-142186f2ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = 'customer_id'\n",
    "timestamp_column = 'timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f4d29c-c7d1-4892-b0e4-718b96918237",
   "metadata": {},
   "source": [
    "### 2.b Define Model Task\n",
    "\n",
    "Fiddler supports a variety of model tasks. In this case, we're adding a binary classification model.\n",
    "\n",
    "For this, we'll create a ModelTask object and an additional ModelTaskParams object to specify the ordering of our positive and negative labels.\n",
    "\n",
    "For a detailed breakdown of all supported model tasks, click here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0650248e-1efc-4e9c-8449-38084b49d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task = fdl.ModelTask.BINARY_CLASSIFICATION\n",
    "\n",
    "task_params = fdl.ModelTaskParams(target_class_order=['no', 'yes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2488b69-f709-4053-b41a-2fac3d4e9738",
   "metadata": {},
   "source": [
    "## 3. Add your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af7765-e0c1-4bf7-9037-9eb1df14d0bc",
   "metadata": {},
   "source": [
    "Create a Model object and publish it to Fiddler, passing in:\n",
    "1. Your data sample\n",
    "2. Your ModelSpec object\n",
    "3. Your ModelTask and ModelTaskParams objects\n",
    "4. Your ID and timestamp columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168728d3-5fe5-4773-8ed7-0a41e90ebeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bank_churn'\n",
    "\n",
    "model = fdl.Model.from_data(\n",
    "    name=MODEL_NAME,\n",
    "    project_id=fdl.Project.from_name(PROJECT_NAME).id,\n",
    "    source=sample_df,\n",
    "    spec=model_spec,\n",
    "    task=model_task,\n",
    "    task_params=task_params,\n",
    "    event_id_col=id_column,\n",
    "    event_ts_col=timestamp_column\n",
    ")\n",
    "\n",
    "model.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6af46-dd9b-46bf-a665-6224362bfa24",
   "metadata": {
    "id": "15c6af46-dd9b-46bf-a665-6224362bfa24"
   },
   "source": [
    "## 4. Upload your model package\n",
    "\n",
    "Now it's time to upload your model package to Fiddler.  To complete this step, we need to ensure we have 2 assets in a directory.  It doesn't matter what this directory is called, but for this example we will call it **/model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90f373-7f0a-4475-971a-d847eff7208f",
   "metadata": {
    "id": "df90f373-7f0a-4475-971a-d847eff7208f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a7474-d52c-4257-8494-cc610e027804",
   "metadata": {
    "id": "e51a7474-d52c-4257-8494-cc610e027804"
   },
   "source": [
    "***Your model package directory will need to contain:***\n",
    "1. A **package.py** file which explains to Fiddler how to invoke your model's prediction endpoint\n",
    "2. And the **model artifact** itself\n",
    "3. A **requirements.txt** specifying which python libraries need by package.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d716d4d-6fab-471c-8ecd-93e219d51a6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "id": "42d35d83-8548-400b-b648-88836cc9bc49",
    "outputId": "93b9c25e-3fdd-4ad0-d5df-f3a182c9ad2c",
    "scrolled": true
   },
   "source": [
    "### 4.a Create the **package.py** file\n",
    "\n",
    "The contents of the cell below will be written into our ***package.py*** file.  This is the step that will be most unique based on model type, framework and use case.  The model's ***package.py*** file also allows for preprocessing transformations and other processing before the model's prediction endpoint is called.  For more information about how to create the ***package.py*** file for a variety of model tasks and frameworks, [see here](https://docs.fiddler.ai/platform-guide/explainability/artifacts-and-surrogates#package.py-wrapper-script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3688045c-8456-4ed4-81a9-d5838290e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model/package.py\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle as pkl\n",
    "\n",
    " \n",
    "PACKAGE_PATH = Path(__file__).parent\n",
    "TARGET = 'churn'\n",
    "PREDICTION = 'predicted_churn'\n",
    "\n",
    "class Random_Forest:\n",
    "\n",
    "\n",
    "    def __init__(self, model_path, output_column=None):\n",
    "        \"\"\"\n",
    "        :param model_path: The directory where the model is saved.\n",
    "        :param output_column: list of column name(s) for the output.\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.output_column = output_column\n",
    "        \n",
    "       \n",
    "        file_path = os.path.join(self.model_path, 'model.pkl')\n",
    "        with open(file_path, 'rb') as file:\n",
    "            self.model = pkl.load(file)\n",
    "    \n",
    "    \n",
    "    def predict(self, input_df):\n",
    "        return pd.DataFrame(\n",
    "            self.model.predict_proba(input_df.loc[:, input_df.columns != TARGET])[:,1], \n",
    "            columns=self.output_column)\n",
    "    \n",
    "\n",
    "def get_model():\n",
    "    return Random_Forest(model_path=PACKAGE_PATH, output_column=[PREDICTION])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15a1a3-a239-4081-b922-b6826d79b266",
   "metadata": {},
   "source": [
    "### 4.b  Ensure your model's artifact is in the **/model** directory\n",
    "\n",
    "Make sure your model artifact (*e.g. the model_unfair.pkl file*) is also present in the model package directory.  The following cell will move this model's pkl file into our */model* directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26463e-708e-41a1-b08d-d69345b452bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/model.pkl\", \"model/model.pkl\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/requirements.txt\", \"model/requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7c3e5",
   "metadata": {},
   "source": [
    "### 4.c Upload Sample Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9VM-PLniLDg3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9VM-PLniLDg3",
    "outputId": "7388f960-f740-4f74-e915-97628153f173",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = 'baseline' \n",
    "#Publishing Pre-prod dataset\n",
    "job = model.publish(\n",
    "  source=sample_df, # we are using the same sample dataset we used earlier in model onboarding\n",
    "  environment=fdl.EnvType.PRE_PRODUCTION, #environemnt parameter is used to designate this dataset as a pre-production data\n",
    "  dataset_name=DATASET_NAME)\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1352b158-fbeb-4fcc-83f6-c8361dc4725a",
   "metadata": {},
   "source": [
    "Let's get the Dataset Object which we will use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000df2a9-d981-4327-bb36-75abdc69888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = fdl.Project.from_name(name=PROJECT_NAME)\n",
    "MODEL = fdl.Model.from_name(name=MODEL_NAME, project_id=PROJECT.id)\n",
    "DATASET = fdl.Dataset.from_name(name=DATASET_NAME, model_id=MODEL.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb1f43-dd33-473d-b788-086cbbb3d10d",
   "metadata": {
    "id": "83bb1f43-dd33-473d-b788-086cbbb3d10d"
   },
   "source": [
    "### 4.d Define Model Parameters and Upload Model Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54efcb88-e5b1-41e5-a344-3562448da990",
   "metadata": {},
   "source": [
    "Before we add the model artifacts to Fiddler we need to specify Model Parameters. You can read more about these configs [here.](https://docs.fiddler.ai/platform-guide/explainability/flexible-model-deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0e075-34cf-425b-9fb5-d773c507cc48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fa0e075-34cf-425b-9fb5-d773c507cc48",
    "outputId": "5c3ea18d-a68c-46f0-897d-0ff183e14044"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = 'model/'\n",
    "\n",
    "DEPLOYMENT_PARAMS = {'memory': 1024, 'cpu': 1000}\n",
    "\n",
    "#finally let's add the model artifacts to Fiddler\n",
    "job = model.add_artifact(\n",
    "  model_dir=MODEL_DIR,\n",
    "  deployment_params=fdl.DeploymentParams(**DEPLOYMENT_PARAMS)\n",
    ") \n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc64cde9-a38a-4a02-8b62-c80bb793d98b",
   "metadata": {},
   "source": [
    "Lastly, we will tell Fiddler to initiate pre-computing the feature impact so it is available to us as we navigate to your Fiddler environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96242c2-1580-4187-9e6f-2c211c938f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.precompute_feature_impact(DATASET.id) # This is done by referencing the dataset object we initiated earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4097b-3a18-405d-8f01-fde414fea49f",
   "metadata": {
    "id": "cda4097b-3a18-405d-8f01-fde414fea49f"
   },
   "source": [
    "Within your Fiddler environment's UI, you should now be able to see the newly created model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2efce",
   "metadata": {},
   "source": [
    "# 5. Publish Production Events and Get Insights (including high-fidelity explainability, or XAI!)\n",
    "\n",
    "Let's grab some more data and publish it as production events to simulate real model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbcb68-d960-4ab8-8a4a-499b66a60e6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "cbbbcb68-d960-4ab8-8a4a-499b66a60e6a",
    "outputId": "3b7df67f-46e3-4bb5-ec4c-de84faf65d6d"
   },
   "outputs": [],
   "source": [
    "PATH_TO_EVENTS_CSV = 'https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/data/v3/churn_production_data.csv'\n",
    "\n",
    "production_df = pd.read_csv(PATH_TO_EVENTS_CSV)\n",
    "# Shift the timestamps of the production events to be as recent as today \n",
    "production_df['timestamp'] = production_df['timestamp'] + (int(time.time() * 1000) - production_df['timestamp'].max())\n",
    "production_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f347e1e-7b22-4590-9bc4-6172dcd7cdf1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f347e1e-7b22-4590-9bc4-6172dcd7cdf1",
    "outputId": "67a11dc5-f145-4cfd-a6a4-d6385b7a4840"
   },
   "outputs": [],
   "source": [
    "dataset = model.publish(\n",
    "  source=production_df, \n",
    "  environment=fdl.EnvType.PRODUCTION) #make sure to specify this environment as PRODUCTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985d21bd-3aeb-4046-b15e-e0440a8877df",
   "metadata": {},
   "source": [
    "**You're all done!**\n",
    "  \n",
    "Now just head to your Fiddler environment's UI and explore the model's explainability by navigating to the model and selecting the **Explain** tab on the top right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f07628-f153-453d-b53a-e829e16f94ef",
   "metadata": {
    "id": "a9f07628-f153-453d-b53a-e829e16f94ef"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
    "\n",
    "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
