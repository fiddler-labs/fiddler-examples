{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c3549a",
   "metadata": {
    "id": "f0c3549a"
   },
   "source": [
    "# Model Versions\n",
    "\n",
    "In this notebook, we present the steps for updating a model schema/version.  When a model is onboarded on to fiddler as a version 1, there can be multiple incremental updates or iterations to that model, the history to which is maintained in fiddler, called model versioning. The users can update existing model schema/versions and also access the older versions. \n",
    "\n",
    "This notebook is an example of how changes can be made in a model/schema and how fiddler maintains them.\n",
    "\n",
    "\n",
    "Fiddler is the pioneer in enterprise A Observability, offering a unified platform that enables Data Science, MLOps, Risk, Compliance, Analytics, and LOB teams to **monitor, explain, analyze, and improve AI deployments at enterprise scale**. \n",
    "Obtain contextual insights at any stage of the ML lifecycle, improve predictions, increase transparency and fairness, and optimize business revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53aec19",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook creates different scenarios for adding new versions for a model.\n",
    "Model Versions are supported on fiddler client version 3.1.0 and above\n",
    "Make sure that the python version is 3.10 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594a3c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/Users/konark/.pyenv/versions/3.10.11/lib/python3.10/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "pip install -q fiddler-client==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1b522",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from '/Users/konark/.pyenv/versions/3.10.11/lib/python3.10/site-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiddler as fdl\n",
    "import tempfile\n",
    "import time as time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from uuid import uuid4\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fdl.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ccba29",
   "metadata": {},
   "source": [
    "# Set log levels\n",
    "\n",
    "Set the log level for verbose information. Python Client mostly focus on programatic usage, rather than being interactive. Set the log level appropriately for notebook friendly usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ebcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdl.set_logging(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab980f9",
   "metadata": {},
   "source": [
    "# Connect to Fiddler\n",
    "\n",
    "Before you can add information about your model with Fiddler, you'll need to connect using our Python client.\n",
    "\n",
    "---\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "3. Your authorization token\n",
    "\n",
    "The latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a16fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://preprod.fiddler.ai' # UPDATE ME\n",
    "TOKEN = '-B5h3iKsUBk2yrYEbamxGHcDggXZTPb7URD6lvzWkrk' # UPDATE ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a660d12b",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "Initilize the connection to Fiddler Client. This call will also validate the client vs server version compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee421c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdl.init(url=URL, token=TOKEN)\n",
    "\n",
    "print(f'Client version: {fdl.__version__}')\n",
    "print(f'Server version: {fdl.conn.server_version}')\n",
    "print(f'Organization id: {fdl.conn.organization_id}')\n",
    "print(f'Organization name: {fdl.conn.organization_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61233f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE_PATH = \"/Users/konark/fiddler-examples/churn_data_sample.csv\" # UPDATE ME    \n",
    "#MODEL_DIR = \"/Users/rajesh/Downloads/OldMacBook/fiddler-2-notebooks/bank_churn_sklearn_102\" # UPDATE ME\n",
    "PROJECT_NAME = 'konark_project_1' # UPDATE ME\n",
    "DATASET_NAME = 'dataset_1' # UPDATE ME\n",
    "MODEL_NAME = 'model_1' # UPDATE ME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb4b7b",
   "metadata": {},
   "source": [
    "Drop some output columns from the CSV file and pick the columns for inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f634f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(DATASET_FILE_PATH)\n",
    "column_list  = sample_df.columns\n",
    "\n",
    "input_columns  = list(column_list.drop([\"predicted_churn\",\"churn\", \"customer_id\", \"timestamp\"]))\n",
    "# list(column_list.drop([\"predicted_churn\",\"churn\", \"customer_id\", \"timestamp\"]))\n",
    "\n",
    "# sample_df\n",
    "input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad50dc",
   "metadata": {},
   "source": [
    "## Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_timestamp(df, event_ts_col: str, start: datetime = datetime.now(), end: datetime = datetime.now() - timedelta(days=30)):\n",
    "    \"\"\"\n",
    "    This function will add a random timestamp to df between\n",
    "    two datetime objects - start and end.\n",
    "    \"\"\"\n",
    "    start_time = start.timestamp() * 1000\n",
    "    end_time = end.timestamp() * 1000\n",
    "    df[event_ts_col] = np.linspace(start_time, end_time, df.shape[0]).astype(int)\n",
    "    df.sort_values(by=[event_ts_col], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbcb24a",
   "metadata": {},
   "source": [
    "## Create project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ac1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create project\n",
    "    project = fdl.Project(name=PROJECT_NAME).create()\n",
    "    print(f'New project created with id = {project.id}')\n",
    "except fdl.Conflict:\n",
    "    # Get project by name\n",
    "    project = fdl.Project.from_name(name=PROJECT_NAME)\n",
    "    print(f'Loaded existing project with id = {project.id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b28bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in fdl.Project.list():\n",
    "    print(f'Project: {x.id} - {x.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700ad1c6",
   "metadata": {},
   "source": [
    "## First version with no task\n",
    "\n",
    "Create the first version of model in the project with NOT_SET task and pre-publish production and production events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d90138",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_v1 = 'v1'\n",
    "\n",
    "model_spec = fdl.ModelSpec(\n",
    "    inputs=input_columns,\n",
    "    outputs=['predicted_churn'],\n",
    "    targets=['churn'],\n",
    "    metadata=['customer_id', 'timestamp'],\n",
    "    decisions=[],\n",
    "    metadata=[],\n",
    "    custom_features=[],\n",
    ")\n",
    "\n",
    "try:\n",
    "    model_v1 = fdl.Model.from_name(\n",
    "        name=MODEL_NAME,\n",
    "        project_id=project.id,\n",
    "        version=version_v1\n",
    "    )\n",
    "    print(f'Loaded existing model with id = {model_v1.id}')\n",
    "except fdl.NotFound:\n",
    "    model_v1 = fdl.Model.from_data(\n",
    "        source=sample_df, \n",
    "        name=MODEL_NAME, \n",
    "        version=version_v1,\n",
    "        project_id=project.id,\n",
    "        spec=model_spec,\n",
    "        task=fdl.ModelTask.BINARY_CLASSIFICATION,\n",
    "        event_ts_col='__timestamp',\n",
    "        event_id_col='__event_id',\n",
    "    )\n",
    "\n",
    "    model_v1.create()\n",
    "    print(f'New model created with id = {model_v1.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3217ec58",
   "metadata": {},
   "source": [
    "## Second version with a task\n",
    "Add Second version with binary classification task and publish production and pre-production events\n",
    "Update the datatype of input feature Geography & update the age min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e86ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_v2 = 'v2'\n",
    "\n",
    "model_spec1 = fdl.ModelSpec(\n",
    "    inputs = [\n",
    "        fdl.schemas.model_schema.Column(\n",
    "            name='Geography',\n",
    "            data_type=fdl.DataType.STRING\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "task_params = fdl.ModelTaskParams(\n",
    "    binary_classification_threshold=0.5,\n",
    "    target_class_order=['no', 'yes'],\n",
    "    class_weights=None,\n",
    "    group_by=None,\n",
    "    top_k=None,\n",
    "    weighted_ref_histograms=None,\n",
    ")\n",
    "\n",
    "xai_params = fdl.XaiParams(\n",
    "    custom_explain_methods=[],\n",
    "    default_explain_method=None,\n",
    ")\n",
    "\n",
    "try:\n",
    "    model_v2 = fdl.Model.from_name(\n",
    "        name=MODEL_NAME,\n",
    "        spec=model_spec1,\n",
    "        project_id=project.id,\n",
    "        version=version_v2\n",
    "    )\n",
    "    print(f'Loaded existing model with id = {model_v2.id}')\n",
    "except fdl.NotFound:\n",
    "    model_v2 = model_v1.duplicate(version=version_v2)\n",
    "    model_v2.schema['age'].min = 21\n",
    "    model_v2.schema['age'].max = 55\n",
    "    model_v2.task_params = task_params\n",
    "    model_v2.xai_params = xai_params\n",
    "    model_v2.task = fdl.ModelTask.BINARY_CLASSIFICATION\n",
    "    model_v2.create()\n",
    "    print(f'New model created with id = {model_v2.id}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd4951b",
   "metadata": {},
   "source": [
    "## Third version with schema change\n",
    "Add third version with change in schema\n",
    "here we are changing the age min/max, deleting an input param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_v3 = 'v3'\n",
    "\n",
    "try:\n",
    "    model_v3 = fdl.Model.from_name(\n",
    "        name=MODEL_NAME,\n",
    "        project_id=project.id,\n",
    "        version=version_v3\n",
    "    )\n",
    "    print(f'Loaded existing model with id = {model_v3.id}')\n",
    "except fdl.NotFound:\n",
    "    model_v3 = model_v2.duplicate(version=version_v3)\n",
    "    model_v3.schema['creditscore'].name = 'CreditScore'\n",
    "    model_v3.schema['geography'].name = 'Geography'\n",
    "    model_v3.schema['balance'].name = 'BalanceNew'\n",
    "    model_v3.schema['numofproducts'].name = 'NumOfProducts'\n",
    "    model_v3.schema['hascrcard'].name = 'HasCrCard'\n",
    "    model_v3.schema['isactivemember'].name = 'IsActiveMember'\n",
    "    model_v3.schema['estimatedsalary'].name = 'EstimatedSalary'\n",
    "    model_v3.schema['age'].name = 'Age'\n",
    "    model_v3.schema['Age'].min = 18\n",
    "    model_v3.schema['Age'].max = 85\n",
    "    del model_v3.schema['tenure']\n",
    "\n",
    "    model_v3.spec.inputs = ['CreditScore', 'Geography', 'Age', 'BalanceNew', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "    \n",
    "    model_v3.create()\n",
    "    print(f'New model created with id = {model_v3.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badd17a1",
   "metadata": {},
   "source": [
    "## Fourth version with schema change\n",
    "Add fourth version with change in schema, where \n",
    "we are changing the weights of the class, removing some input params, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886accfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_v4 = 'v4'\n",
    "\n",
    "try:\n",
    "    model_v4 = fdl.Model.from_name(\n",
    "        name=MODEL_NAME,\n",
    "        project_id=project.id,\n",
    "        version=version_v4\n",
    "    )\n",
    "    print(f'Loaded existing model with id = {model_v4.id}')\n",
    "except fdl.NotFound as e:\n",
    "    print('konark is here 1st block ')\n",
    "    print(e.message)\n",
    "    model_v4 = model_v3.duplicate(version=version_v4)\n",
    "    \n",
    "    model_v4.spec.inputs = ['CreditScore', 'Geography', 'Age', 'BalanceNew', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "    model_v4.schema['BalanceNew'].max = 250000\n",
    "\n",
    "    task_params = fdl.ModelTaskParams(\n",
    "        class_weights = [23.0, 12.0, 25.0, 12.5, 12.5, 7.5, 7.5, 0.0],\n",
    "    weighted_ref_histograms = True,\n",
    "    )\n",
    "    \n",
    "    model_v4.task_params = task_params    \n",
    "    model_v4.create()\n",
    "    print(f'New model created with id = {model_v4.id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0881c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_v5 = 'v5'\n",
    "\n",
    "try:\n",
    "    model_v5 = fdl.Model.from_name(\n",
    "        name=MODEL_NAME,\n",
    "        project_id=project.id,\n",
    "        version=version_v5\n",
    "    )\n",
    "    print(f'Loaded existing model with id = {model_v4.id}')\n",
    "except fdl.NotFound as e:\n",
    "    model_v5 = model_v4.duplicate(version=version_v5)\n",
    "    \n",
    "    model_v5.spec.inputs = ['CreditScore', 'Geography', 'Age', 'BalanceNew', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "    model_v5.schema['BalanceNew'].max = 1250000    \n",
    "    model_v5.create()\n",
    "    print(f'New model created with id = {model_v5.id}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3693662",
   "metadata": {},
   "source": [
    "## Publish pre-production events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff684242",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3, model_v4. model_v5]:\n",
    "    try:\n",
    "        fdl.Dataset.from_name(name=DATASET_NAME, model_id=model.id)\n",
    "    except fdl.NotFound:\n",
    "        print(f\"Publishing dataset for {model.name}/{model.version}\")\n",
    "        job = model.publish(\n",
    "            source=DATASET_FILE_PATH,\n",
    "            environment=fdl.EnvType.PRE_PRODUCTION,\n",
    "            dataset_name=DATASET_NAME,\n",
    "        )\n",
    "        job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e002679",
   "metadata": {},
   "source": [
    "## Publish events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de9f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pd.read_csv(DATASET_FILE_PATH)\n",
    "\n",
    "for model in [model_v1, model_v2, model_v3, model_v4]:    \n",
    "    print(f\"Publishing events for {model.name}/{model.version}\")\n",
    "    \n",
    "    events_df[model.event_id_col] = [str(uuid4()) for _ in range(len(events_df))]\n",
    "    _add_timestamp(df=events_df, event_ts_col=model.event_ts_col)\n",
    "    \n",
    "    job = model.publish(source=events_df)\n",
    "    job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663c7220",
   "metadata": {},
   "source": [
    "## Update version name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52343d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v4.version = 'v4-old'\n",
    "model_v4.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c111b0a",
   "metadata": {},
   "source": [
    "## List model versions\n",
    "\n",
    "List all the versions of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1072253",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in fdl.Model.list(project_id=project.id, name=MODEL_NAME):\n",
    "    print(f'Model: {x.id} - {x.name} {x.version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a0374",
   "metadata": {},
   "source": [
    "## Delete model version\n",
    "Delete v4 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = model_v5.delete()\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7498b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = model.duplicate(version='v2')\n",
    "\n",
    "new_model.schema['Age'].min = 18\n",
    "new_model.schema['Age'].max = 60\n",
    "new_model.task = fdl.ModelTask.BINARY_CLASSIFICATION\n",
    "\n",
    "try:\n",
    "    new_model.create()\n",
    "    print(f'New model version created with id = {model.id}')\n",
    "except fdl.Conflict:\n",
    "    new_model = fdl.Model.from_name(name=model.name, project_id=project.id, version=new_model.version)\n",
    "    print(f'Loaded existing model version with id = {model.id}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e6b82",
   "metadata": {},
   "source": [
    "## Publish pre-production events\n",
    "\n",
    "Only batch publish is supported for now. Dataframes are not supported, use parquet or csv file for uploading dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880306fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pre-production datasets\n",
    "\n",
    "for x in model.datasets:\n",
    "    print(f'Dataset: {x.id} - {x.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e0dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pre-production datasets\n",
    "\n",
    "for x in fdl.Dataset.list(model_id=model.id):\n",
    "    print(f'Dataset: {x.id} - {x.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71552ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.event_ts_col = '__timestamp'\n",
    "model.event_id_col = '__event_id'\n",
    "model.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16bb89d",
   "metadata": {},
   "source": [
    "## Publish production events - stream\n",
    "\n",
    "Dataframes will be uploaded as stream of events to avoid converting dataframe to csv / parquet which is prone to errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_FILE_PATH)\n",
    "\n",
    "# Generate event_id which is later needed for label updates\n",
    "df[model.event_id_col] = [str(uuid4()) for _ in range(len(df))]\n",
    "_add_timestamp(df=df, event_ts_col=model.event_ts_col)\n",
    "\n",
    "fiddler_ids = model.publish(source=df)\n",
    "\n",
    "print(f'{len(fiddler_ids)} events published')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebcc3ca",
   "metadata": {},
   "source": [
    "## Publish list of events\n",
    "\n",
    "Python Client 3.0 supports publishing micro batch streams (upto 1K events, configurable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = df.sample(10).to_dict(orient='records') # this will give list of event dictionaries\n",
    "\n",
    "fiddler_ids = model.publish(source=events)\n",
    "\n",
    "print(f'{len(fiddler_ids)} events published')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e5ad31",
   "metadata": {},
   "source": [
    "## Publish production label updates - stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_events = [\n",
    "        {\n",
    "            model.event_id_col: event_id,\n",
    "            model.spec.targets[0]: model.task_params.target_class_order[0],\n",
    "        }\n",
    "        for event_id in df.sample(100)[model.event_id_col]\n",
    "]\n",
    "\n",
    "fiddler_ids = model.publish(source=updated_events, update=True)\n",
    "\n",
    "print(f'{len(fiddler_ids)} events updated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef16799a",
   "metadata": {},
   "source": [
    "## Publish production events - batch\n",
    "\n",
    "Batch publish is only supported on files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2581259",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(suffix='.csv', mode='w') as temp_file:\n",
    "    df.to_csv(temp_file.name, index=False)\n",
    "\n",
    "    job = model.publish(source=temp_file.name)\n",
    "\n",
    "job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee181b2",
   "metadata": {},
   "source": [
    "## Add static pre-production baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e625f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3]:\n",
    "    dataset = next(fdl.Dataset.list(model_id=model.id))\n",
    "    \n",
    "    static_pre_prod_baseline = fdl.Baseline(\n",
    "        name='static_preprod_1',\n",
    "        model_id=model.id,\n",
    "        environment=fdl.EnvType.PRE_PRODUCTION,\n",
    "        type_=fdl.BaselineType.STATIC,\n",
    "        dataset_id=dataset.id,\n",
    "    )\n",
    "    static_pre_prod_baseline.create()\n",
    "    \n",
    "    print(f'Static pre-production baseline created with id - {static_pre_prod_baseline.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f4c95f",
   "metadata": {},
   "source": [
    "## Add static production baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019746a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3]:\n",
    "    static_prod_baseline = fdl.Baseline(\n",
    "        name='static_prod_1',\n",
    "        model_id=model.id,\n",
    "        environment=fdl.EnvType.PRODUCTION,\n",
    "        type_=fdl.BaselineType.STATIC,\n",
    "        start_time=(datetime.now() - timedelta(days=0.5)).timestamp(),\n",
    "        end_time=(datetime.now() - timedelta(days=0.25)).timestamp(),\n",
    "    )\n",
    "    static_prod_baseline.create()\n",
    "    \n",
    "    print(f'Static production baseline created with id - {static_prod_baseline.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f8bdc9",
   "metadata": {},
   "source": [
    "## Add rolling production baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e90fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3]:\n",
    "    rolling_prod_baseline = fdl.Baseline(\n",
    "        name='rolling_prod_1',\n",
    "        model_id=model.id,\n",
    "        environment=fdl.EnvType.PRODUCTION,\n",
    "        type_=fdl.BaselineType.ROLLING,\n",
    "        window_bin_size=fdl.WindowBinSize.HOUR,\n",
    "        offset_delta=1,\n",
    "    )\n",
    "    rolling_prod_baseline.create()\n",
    "    \n",
    "    print(f'Rolling production baseline created with id - {rolling_prod_baseline.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9fec4b",
   "metadata": {},
   "source": [
    "## List of baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24feb966",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3]:\n",
    "    for x in model.baselines:\n",
    "        print(f'Baseline: {x.id} - {x.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d9ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3]:\n",
    "    for x in fdl.Baseline.list(model_id=model.id):\n",
    "        print(f'Baseline: {x.id} - {x.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33185012",
   "metadata": {},
   "source": [
    "## Add custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a9736",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3]:\n",
    "    custom_metric = fdl.CustomMetric(\n",
    "        name='avg age 1',\n",
    "        model_id=model.id,\n",
    "        definition='average(Age)'\n",
    "    ).create()\n",
    "    print(f'Custom metric created with id - {custom_metric.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c93d96",
   "metadata": {},
   "source": [
    "## Add segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46495109",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3]:\n",
    "    segment = fdl.Segment(\n",
    "        name='age below 40',\n",
    "        model_id=model.id,\n",
    "        definition='Age < 40'\n",
    "    ).create()\n",
    "    print(f'Segment created with id - {custom_metric.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb5a5d",
   "metadata": {},
   "source": [
    "# Artifact/Surrogate methods\n",
    "\n",
    "Artifact or surrogate model flow requires at least 1 pre-production dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec27b41",
   "metadata": {},
   "source": [
    "## Add surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc66ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_v1 and model_v2 does not have task set, hence add surrogate will fail\n",
    "for model in [model_v3]:\n",
    "    job = model.add_surrogate(\n",
    "        dataset_id=next(model.datasets).id\n",
    "    )\n",
    "    job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf752be7",
   "metadata": {},
   "source": [
    "## Update surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80233bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_v1 and model_v2 does not have task set, hence add surrogate will fail\n",
    "for model in [model_v3]:\n",
    "    job = model.update_surrogate(dataset_id=next(model.datasets).id)\n",
    "\n",
    "    job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc06fd7",
   "metadata": {},
   "source": [
    "## Add model artifact\n",
    "If the surrogate model is already added then update with an artifact. add_artifact only works if there are no artifact attached to the model already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a90047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_v1 and model_v2 does not have task set, hence add artifact will fail\n",
    "# model_v3 will fail as there is a surrogate added already, use model.update_artifact instead\n",
    "# for model in [model_v3]:\n",
    "#     job = model.add_artifact(model_dir=MODEL_DIR)\n",
    "#     job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e9041",
   "metadata": {},
   "source": [
    "## Update artiafct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd09a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_v1 and model_v2 does not have task set, hence add artifact will fail\n",
    "for model in [model_v3]:\n",
    "    job = model.update_artifact(\n",
    "        model_dir=MODEL_DIR,\n",
    "    )\n",
    "    job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ce57e",
   "metadata": {},
   "source": [
    "## Update model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ef0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v3]:\n",
    "    model.deployment.cpu = 200\n",
    "    job = model.deployment.update()\n",
    "    job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5756c8",
   "metadata": {},
   "source": [
    "# Pre-compute feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867869f",
   "metadata": {},
   "source": [
    "## Pre-compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a344931",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v3]:\n",
    "    job = model.precompute_feature_importance(\n",
    "        dataset_id=next(model.datasets).id\n",
    "    )\n",
    "    job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2ecc39",
   "metadata": {},
   "source": [
    "## Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38dfb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v3]:\n",
    "    job = model.precompute_feature_importance(dataset_id=next(model.datasets).id, update=True)\n",
    "    job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb949e",
   "metadata": {},
   "source": [
    "## Fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f634351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v3]:\n",
    "    model.get_precomputed_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855cd91",
   "metadata": {},
   "source": [
    "# Pre-compute feature impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478cd520",
   "metadata": {},
   "source": [
    "## Pre-compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v3]:\n",
    "    job = model.precompute_feature_impact(dataset_id=next(model.datasets).id)\n",
    "    job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0261483c",
   "metadata": {},
   "source": [
    "## Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d49340",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v3]:\n",
    "    job = model.precompute_feature_impact(dataset_id=next(model.datasets).id, update=True)\n",
    "    job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c728a85",
   "metadata": {},
   "source": [
    "## Fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v3]:\n",
    "    model.get_precomputed_feature_impact()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d601f47d",
   "metadata": {},
   "source": [
    "## Pre-compute predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2487177",
   "metadata": {},
   "source": [
    "## Pre-compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb24581",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v3]:\n",
    "    job = model.precompute_predictions(dataset_id=next(model.datasets).id)\n",
    "    job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad34b5",
   "metadata": {},
   "source": [
    "## Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649c42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v3]:\n",
    "    job = model.precompute_predictions(dataset_id=next(model.datasets).id, update=True)\n",
    "    job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a45ed4",
   "metadata": {},
   "source": [
    "# Alert methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3354977",
   "metadata": {},
   "source": [
    "## Add alert rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3]:\n",
    "    rule = fdl.AlertRule(\n",
    "        name=f'test_rule - {model.version}',\n",
    "        model_id=model.id,\n",
    "        metric_id='null_violation_count',\n",
    "        priority=fdl.Priority.MEDIUM,\n",
    "        compare_to=fdl.CompareTo.RAW_VALUE,\n",
    "        condition=fdl.AlertCondition.GREATER,\n",
    "        bin_size=fdl.BinSize.HOUR,\n",
    "        critical_threshold=1,\n",
    "        warning_threshold=0.32,\n",
    "        columns=[model.spec.inputs[0]],\n",
    "    )\n",
    "    rule.create()\n",
    "    \n",
    "    print(f'Alert rule created with id - {rule.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98966ee1",
   "metadata": {},
   "source": [
    "## List of alert rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3]:\n",
    "    for rule in fdl.AlertRule.list(\n",
    "        model_id=model.id,\n",
    "        metric_id='null_violation_count',\n",
    "        ordering=['warning_threshold']\n",
    "    ):\n",
    "        print(f'AlertRule: {x.id} - {x.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7633a03",
   "metadata": {},
   "source": [
    "# XAI methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac68944",
   "metadata": {},
   "source": [
    "## Get pre-production slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77400dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3]:\n",
    "    df = model.get_slice(\n",
    "        query=f'select * from {dataset.name}.{model.name}',\n",
    "        sample=True,\n",
    "        max_rows=100,\n",
    "        columns=model.spec.inputs,\n",
    "    )\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de2b4f",
   "metadata": {},
   "source": [
    "## Get production slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37306319",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v1, model_v2, model_v3]:\n",
    "    df = model.get_slice(\n",
    "        query=f'select * from production.{model.name} limit 10',\n",
    "    )\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d818428",
   "metadata": {},
   "source": [
    "## Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f24b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_v1 and model_v2 does not have task set, hence this will fail\n",
    "for model in [model_v3]:\n",
    "    fairness = model.get_fairness(\n",
    "        data_source=fdl.DatasetDataSource(\n",
    "            env_type=fdl.EnvType.PRE_PRODUCTION,\n",
    "            dataset_id=dataset.id,\n",
    "        ),\n",
    "        protected_features=['Gender'],\n",
    "        positive_outcome='Churned',\n",
    "    )\n",
    "    print(fairness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89fd602",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8655d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [model_v3]:\n",
    "    row = df.sample(1).to_dict(orient='records')[0]\n",
    "                     \n",
    "    explain = model.explain(\n",
    "        input_data_source=fdl.RowDataSource(row=row),\n",
    "        ref_data_source=fdl.DatasetDataSource(\n",
    "            env_type=fdl.EnvType.PRE_PRODUCTION,\n",
    "            dataset_id=dataset.id,\n",
    "        ),\n",
    "    )\n",
    "    print(explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756992e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "985d21bd-3aeb-4046-b15e-e0440a8877df",
   "metadata": {},
   "source": [
    "**You're all done!**\n",
    "  \n",
    "Now just head to your Fiddler environment's UI and explore the model's explainability by navigating to the model and selecting the **Explain** tab on the top right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f07628-f153-453d-b53a-e829e16f94ef",
   "metadata": {
    "id": "a9f07628-f153-453d-b53a-e829e16f94ef"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
    "\n",
    "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
