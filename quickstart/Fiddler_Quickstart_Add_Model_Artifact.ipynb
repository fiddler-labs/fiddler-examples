{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c3549a",
   "metadata": {
    "id": "f0c3549a"
   },
   "source": [
    "# Adding a Model Artifact\n",
    "\n",
    "In this notebook, we present the steps for onboarding a model with its model artifact.  When Fiddler is provided with your real model artifact, it can produce high-fidelity explanations.  In contrast, models within Fiddler that use a surrogate model or no model artifact at all provide approximative explainability or no explainability at all.\n",
    "\n",
    "Fiddler is the pioneer in enterprise Model Performance Management (MPM), offering a unified platform that enables Data Science, MLOps, Risk, Compliance, Analytics, and LOB teams to **monitor, explain, analyze, and improve ML deployments at enterprise scale**. \n",
    "Obtain contextual insights at any stage of the ML lifecycle, improve predictions, increase transparency and fairness, and optimize business revenue.\n",
    "\n",
    "---\n",
    "\n",
    "You can experience Fiddler's NLP monitoring ***in minutes*** by following these five quick steps:\n",
    "\n",
    "1. Connect to Fiddler\n",
    "2. Upload a baseline dataset\n",
    "3. Upload a model package directory containing the **1) package.py and 2) model artifact**\n",
    "4. Publish production events\n",
    "5. Get insights (including high-fidelity explainability, or XAI!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1db734",
   "metadata": {
    "id": "9f1db734"
   },
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c2b2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f99c2b2f",
    "outputId": "40667583-548d-47e6-c7de-bea6b74151b8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q fiddler-client\n",
    "\n",
    "import fiddler as fdl\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"Running Fiddler client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69",
   "metadata": {
    "id": "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69"
   },
   "source": [
    "# 1. Connect to Fiddler\n",
    "\n",
    "Before you can add information about your model with Fiddler, you'll need to connect using our Python client.\n",
    "\n",
    "---\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your organization ID\n",
    "3. Your authorization token\n",
    "\n",
    "The latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21245781-c546-41de-9c18-9409361615e3",
   "metadata": {
    "id": "21245781-c546-41de-9c18-9409361615e3"
   },
   "outputs": [],
   "source": [
    "URL = '' # Make sure to include the full URL (including https://).\n",
    "ORG_ID = ''\n",
    "AUTH_TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9678de-4d81-4b9b-905d-e2a6b0d8b141",
   "metadata": {
    "id": "cd9678de-4d81-4b9b-905d-e2a6b0d8b141"
   },
   "source": [
    "Now just run the following code block to connect the client to your Fiddler environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb4cb3-907a-4405-866e-dd4591c4957b",
   "metadata": {
    "id": "2abb4cb3-907a-4405-866e-dd4591c4957b"
   },
   "outputs": [],
   "source": [
    "client = fdl.FiddlerApi(\n",
    "    url=URL,\n",
    "    org_id=ORG_ID,\n",
    "    auth_token=AUTH_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88c43f3-1b5e-427d-92ed-307299d73bea",
   "metadata": {
    "id": "d88c43f3-1b5e-427d-92ed-307299d73bea"
   },
   "source": [
    "Once you connect, you can create a new project by specifying a unique project ID in the client's [create_project](https://docs.fiddler.ai/reference/clientcreate_project) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba61dc-a436-4186-8b07-68fa429d34d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82ba61dc-a436-4186-8b07-68fa429d34d3",
    "outputId": "e1055a05-fa15-45f8-fd78-5e20627b2417"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'example_model'\n",
    "\n",
    "if not PROJECT_ID in client.list_projects():\n",
    "    print(f'Creating project: {PROJECT_ID}')\n",
    "    client.create_project(PROJECT_ID)\n",
    "else:\n",
    "    print(f'Project: {PROJECT_ID} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900ae24-997b-4422-8349-b2a097025745",
   "metadata": {
    "id": "9900ae24-997b-4422-8349-b2a097025745"
   },
   "source": [
    "# 2. Upload a baseline dataset\n",
    "\n",
    "In this example, we'll be considering the case where we're a bank and we have **a model that predicts churn for our customers**.  \n",
    "  \n",
    "In order to get insights into the model's performance, **Fiddler needs a small  sample of data that can serve as a baseline** for making comparisons with data in production.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*For more information on how to design a baseline dataset, [click here](https://docs.fiddler.ai/docs/designing-a-baseline-dataset).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a715829-783e-4f72-9fcf-0ff78379ba33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "8a715829-783e-4f72-9fcf-0ff78379ba33",
    "outputId": "0031c673-d2ef-4fb7-98d6-d3248a5c5f68"
   },
   "outputs": [],
   "source": [
    "PATH_TO_BASELINE_CSV = 'https://raw.githubusercontent.com/fiddler-labs/fiddler-samples/master/content_root/tutorial/quickstart/churn_baseline.csv'\n",
    "\n",
    "baseline_df = pd.read_csv(PATH_TO_BASELINE_CSV)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821605b6-263d-4c95-9f0e-0812cdbc9961",
   "metadata": {
    "id": "821605b6-263d-4c95-9f0e-0812cdbc9961"
   },
   "source": [
    "Fiddler uses this baseline dataset to keep track of important information about your data.\n",
    "  \n",
    "This includes **data types**, **data ranges**, and **unique values** for categorical variables.\n",
    "\n",
    "---\n",
    "\n",
    "You can construct a [DatasetInfo](https://docs.fiddler.ai/reference/fdldatasetinfo) object to be used as **a schema for keeping track of this information** by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c15218-b987-4cf2-8f2b-e413c7aae49a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "b1c15218-b987-4cf2-8f2b-e413c7aae49a",
    "outputId": "e1d019e2-001d-428d-d599-74b608aa0ca0"
   },
   "outputs": [],
   "source": [
    "dataset_info = fdl.DatasetInfo.from_dataframe(baseline_df, max_inferred_cardinality=100)\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44dc2e6-37a0-4411-8a7e-420a12942ab4",
   "metadata": {
    "id": "a44dc2e6-37a0-4411-8a7e-420a12942ab4"
   },
   "source": [
    "Then use the client's [upload_dataset](https://docs.fiddler.ai/reference/clientupload_dataset) function to send this information to Fiddler.\n",
    "  \n",
    "*Just include:*\n",
    "1. A unique dataset ID\n",
    "2. The baseline dataset as a pandas DataFrame\n",
    "3. The `DatasetInfo` object you just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e6262-bd7d-4162-89ef-c2d1f140eb40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a47e6262-bd7d-4162-89ef-c2d1f140eb40",
    "outputId": "b1d5079a-9241-4d01-faac-50f7992fe177"
   },
   "outputs": [],
   "source": [
    "DATASET_ID = 'churn_data'\n",
    "\n",
    "client.upload_dataset(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    dataset={\n",
    "        'baseline': baseline_df\n",
    "    },\n",
    "    info=dataset_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58c04c-9735-4b16-a67e-85397debdd9d",
   "metadata": {
    "id": "7e58c04c-9735-4b16-a67e-85397debdd9d"
   },
   "source": [
    "Within your Fiddler environment's UI, you should now be able to see the newly created dataset within your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6af46-dd9b-46bf-a665-6224362bfa24",
   "metadata": {
    "id": "15c6af46-dd9b-46bf-a665-6224362bfa24"
   },
   "source": [
    "## 3. Upload your model package\n",
    "\n",
    "Now it's time to upload your model package to Fiddler.  To complete this step, we need to ensure we have 2 assets in a directory.  It doesn't matter what this directory is called, but for this example we will call it **/model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90f373-7f0a-4475-971a-d847eff7208f",
   "metadata": {
    "id": "df90f373-7f0a-4475-971a-d847eff7208f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a7474-d52c-4257-8494-cc610e027804",
   "metadata": {
    "id": "e51a7474-d52c-4257-8494-cc610e027804"
   },
   "source": [
    "***Your model package directory will need to contain:***\n",
    "1. A **package.py** file which explains to Fiddler how to invoke your model's prediction endpoint\n",
    "2. And the **model artifact** itself\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1  Create the **model.yaml** file \n",
    "\n",
    "This is done by first creating our [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object and then writing it out to a **model.yaml** file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d35d83-8548-400b-b648-88836cc9bc49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "id": "42d35d83-8548-400b-b648-88836cc9bc49",
    "outputId": "93b9c25e-3fdd-4ad0-d5df-f3a182c9ad2c"
   },
   "outputs": [],
   "source": [
    "metadata_cols = ['gender']\n",
    "decision_cols = ['decision']\n",
    "feature_columns = ['creditscore', 'geography', 'age', 'tenure',\n",
    "       'balance', 'numofproducts', 'hascrcard', 'isactivemember',\n",
    "       'estimatedsalary']\n",
    "\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=client.get_dataset_info(PROJECT_ID, DATASET_ID),\n",
    "    target='churn', \n",
    "    features=feature_columns,\n",
    "    decision_cols = decision_cols,\n",
    "    metadata_cols = metadata_cols,\n",
    "    outputs=['predicted_churn'],\n",
    "    display_name='Random Forest Model',\n",
    "    description='This is models customer bank churn'\n",
    ")\n",
    "\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9VM-PLniLDg3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9VM-PLniLDg3",
    "outputId": "7388f960-f740-4f74-e915-97628153f173"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = 'customer_churn_rf'\n",
    "\n",
    "client.add_model(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    model_id=MODEL_ID,\n",
    "    model_info=model_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb1f43-dd33-473d-b788-086cbbb3d10d",
   "metadata": {
    "id": "83bb1f43-dd33-473d-b788-086cbbb3d10d"
   },
   "source": [
    "### 3.2 Create the **package.py** file\n",
    "\n",
    "The contents of the cell below will be written into our ***package.py*** file.  This is the step that will be most unique based on model type, framework and use case.  The model's ***package.py*** file also allows for preprocessing transformations and other processing before the model's prediction endpoint is called.  For more information about how to create the ***package.py*** file for a variety of model tasks and frameworks, please reference the [Uploading a Model Artifact](https://docs.fiddler.ai/docs/uploading-a-model-artifact#packagepy-script) section of the Fiddler product documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0e075-34cf-425b-9fb5-d773c507cc48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fa0e075-34cf-425b-9fb5-d773c507cc48",
    "outputId": "5c3ea18d-a68c-46f0-897d-0ff183e14044"
   },
   "outputs": [],
   "source": [
    "%%writefile model/package.py\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle as pkl\n",
    "\n",
    " \n",
    "PACKAGE_PATH = Path(__file__).parent\n",
    "TARGET = 'churn'\n",
    "PREDICTION = 'predicted_churn'\n",
    "\n",
    "class Random_Forest:\n",
    "\n",
    "\n",
    "    def __init__(self, model_path, output_column=None):\n",
    "        \"\"\"\n",
    "        :param model_path: The directory where the model is saved.\n",
    "        :param output_column: list of column name(s) for the output.\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.output_column = output_column\n",
    "        \n",
    "       \n",
    "        file_path = os.path.join(self.model_path, 'model.pkl')\n",
    "        with open(file_path, 'rb') as file:\n",
    "            self.model = pkl.load(file)\n",
    "    \n",
    "    \n",
    "    def predict(self, input_df):\n",
    "        return pd.DataFrame(\n",
    "            self.model.predict_proba(input_df.loc[:, input_df.columns != TARGET])[:,1], \n",
    "            columns=self.output_column)\n",
    "    \n",
    "\n",
    "def get_model():\n",
    "    return Random_Forest(model_path=PACKAGE_PATH, output_column=[PREDICTION])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4097b-3a18-405d-8f01-fde414fea49f",
   "metadata": {
    "id": "cda4097b-3a18-405d-8f01-fde414fea49f"
   },
   "source": [
    "### 3.3  Ensure your model's artifact is in the **/model** directory\n",
    "\n",
    "Make sure your model artifact (*e.g. the model .pkl file*) is also present in the model package directory.  The following cell will move this model's pkl file into our */model* directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f8b88f-d5cf-4156-929d-751b175abf54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26f8b88f-d5cf-4156-929d-751b175abf54",
    "outputId": "b676bd1b-a62e-4da1-83ac-c46d69d8e69a"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-samples/master/content_root/tutorial/quickstart/model.pkl\", \"model/model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ddcab9-54fa-4367-92f0-b87306d14b7e",
   "metadata": {
    "id": "f8ddcab9-54fa-4367-92f0-b87306d14b7e"
   },
   "source": [
    "### Finally, upload the model package directory\n",
    "\n",
    "Once the model's artifact is in the */model* directory along with the **pacakge.py** file, the model package directory can be uploaded to Fiddler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff090a7-b4df-4dc0-8c1d-ac05f2f0eb3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ff090a7-b4df-4dc0-8c1d-ac05f2f0eb3f",
    "outputId": "43d22682-a361-4f65-8ad7-dcc86726f731"
   },
   "outputs": [],
   "source": [
    "client.add_model_artifact(model_dir='model/', project_id=PROJECT_ID, model_id=MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd366b0-f40b-4e28-8325-12d429987349",
   "metadata": {
    "id": "acd366b0-f40b-4e28-8325-12d429987349"
   },
   "source": [
    "Within your Fiddler environment's UI, you should now be able to see the newly created model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5fd2f5-bd49-4194-9183-7896a7294904",
   "metadata": {
    "id": "9a5fd2f5-bd49-4194-9183-7896a7294904"
   },
   "source": [
    "# 4. Publish production events\n",
    "\n",
    "Your model artifact is uploaded.  Now it's time to start publishing some production data! \n",
    "\n",
    "Fiddler will **monitor this data and compare it to your baseline to generate powerful insights into how your model is behaving**.  \n",
    "\n",
    "With the model artifact available to Fiddler, **high-fidelity explanations are also avaialbe**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Each record sent to Fiddler is called **an event**.  An event is just **a dictionary that maps column names to column values**.\n",
    "  \n",
    "Let's load in some sample events from a CSV file.  Then we can create an artificial timestamp for the events and publish them to fiddler one by one in a streaming fashion using the Fiddler client's [publish_event](https://docs.fiddler.ai/reference/clientpublish_event) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbcb68-d960-4ab8-8a4a-499b66a60e6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "cbbbcb68-d960-4ab8-8a4a-499b66a60e6a",
    "outputId": "3b7df67f-46e3-4bb5-ec4c-de84faf65d6d"
   },
   "outputs": [],
   "source": [
    "PATH_TO_EVENTS_CSV = 'https://raw.githubusercontent.com/fiddler-labs/fiddler-samples/master/content_root/tutorial/quickstart/hawaii_drift_demo_large.csv'\n",
    "\n",
    "event_log = pd.read_csv(PATH_TO_EVENTS_CSV)\n",
    "event_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f347e1e-7b22-4590-9bc4-6172dcd7cdf1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f347e1e-7b22-4590-9bc4-6172dcd7cdf1",
    "outputId": "67a11dc5-f145-4cfd-a6a4-d6385b7a4840"
   },
   "outputs": [],
   "source": [
    "NUM_EVENTS_TO_SEND = 11500\n",
    "\n",
    "FIVE_MINUTES_MS = 300000\n",
    "ONE_DAY_MS = 8.64e+7\n",
    "NUM_DAYS_BACK_TO_START=39 #set the start of the event data publishing this many days in the past\n",
    "start_date = round(time.time() * 1000) - (ONE_DAY_MS * NUM_DAYS_BACK_TO_START) \n",
    "print(datetime.datetime.fromtimestamp(start_date/1000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9a6d8-d253-43c5-8e8f-344101bfa14c",
   "metadata": {
    "id": "d7b9a6d8-d253-43c5-8e8f-344101bfa14c"
   },
   "outputs": [],
   "source": [
    "def event_generator_df():\n",
    "    for ind, row in event_log.iterrows():\n",
    "        event_dict = dict(row)\n",
    "        event_id = event_dict.pop('event_id')\n",
    "        event_time = start_date + ind * FIVE_MINUTES_MS #publish an event every FIVE_MINUTES_MS\n",
    "        yield event_id, event_dict, event_time\n",
    "        \n",
    "event_queue_df = event_generator_df()\n",
    "\n",
    "def get_next_event_df():\n",
    "    return next(event_queue_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68718372-7dbb-4e6d-b12d-05833d6dd701",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68718372-7dbb-4e6d-b12d-05833d6dd701",
    "outputId": "900a88c2-82f0-43e3-c0c8-d634ea40ff14"
   },
   "outputs": [],
   "source": [
    "for ind in range(NUM_EVENTS_TO_SEND):\n",
    "    event_id_tmp, event_dict, event_time = get_next_event_df()\n",
    "   \n",
    "    result = client.publish_event(PROJECT_ID,\n",
    "                                  MODEL_ID,\n",
    "                                  event_dict,\n",
    "                                  event_timestamp=event_time,\n",
    "                                  event_id= event_id_tmp,\n",
    "                                  update_event= False)\n",
    "    \n",
    "    readable_timestamp = datetime.datetime.fromtimestamp(event_time/1000.0)\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    print(f'Sending {ind+1} / {NUM_EVENTS_TO_SEND} \\n{readable_timestamp} UTC: \\n{event_dict}')\n",
    "    time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e237cc-d7b6-4181-991f-ae27bf61cce3",
   "metadata": {
    "id": "25e237cc-d7b6-4181-991f-ae27bf61cce3"
   },
   "source": [
    "# 5. Get insights\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "Now just head to your Fiddler environment's UI and start getting enhanced monitoring, analytics, and explainability.\n",
    "\n",
    "Run the following code block to get your URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd4ee9-1f9e-4ae4-af52-93ab6807ba95",
   "metadata": {
    "id": "79cd4ee9-1f9e-4ae4-af52-93ab6807ba95"
   },
   "outputs": [],
   "source": [
    "print('/'.join([URL, 'projects', PROJECT_ID, 'models', MODEL_ID, 'monitor']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881a5d05-85d2-4ecb-abe6-febdbd8a9ea1",
   "metadata": {
    "id": "881a5d05-85d2-4ecb-abe6-febdbd8a9ea1"
   },
   "source": [
    "*Please allow 3-5 minutes for monitoring data to populate the charts.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f07628-f153-453d-b53a-e829e16f94ef",
   "metadata": {
    "id": "a9f07628-f153-453d-b53a-e829e16f94ef"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
    "\n",
    "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
