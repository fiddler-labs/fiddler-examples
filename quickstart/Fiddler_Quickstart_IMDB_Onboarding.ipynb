{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c3549a",
   "metadata": {
    "id": "f0c3549a"
   },
   "source": [
    "# Onboarding IMDB Movie Reviews for NLP Explainability\n",
    "\n",
    "In this notebook, we present the steps for onboarding a model artifact to Fiddler that predicts the sentiment of IMDB movie reviews.  Fiddler is able to explain complex models with a variety of input types like unstructured text, images, and multi-modal.  \n",
    "\n",
    "Fiddler is the pioneer in enterprise Model Performance Management (MPM), offering a unified platform that enables Data Science, MLOps, Risk, Compliance, Analytics, and LOB teams to **monitor, explain, analyze, and improve ML deployments at enterprise scale**. \n",
    "Obtain contextual insights at any stage of the ML lifecycle, improve predictions, increase transparency and fairness, and optimize business revenue.\n",
    "\n",
    "---\n",
    "\n",
    "You can experience Fiddler's NLP monitoring ***in minutes*** by following these five quick steps:\n",
    "\n",
    "1. Connect to Fiddler\n",
    "2. Upload a baseline dataset\n",
    "3. Upload a model package directory containing the **1) package.py and 2) model artifact**\n",
    "4. Explain your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1db734",
   "metadata": {
    "id": "9f1db734"
   },
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99c2b2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f99c2b2f",
    "outputId": "40667583-548d-47e6-c7de-bea6b74151b8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Running Fiddler client version 1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -q fiddler-client==1.8.1\n",
    "\n",
    "import fiddler as fdl\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"Running Fiddler client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69",
   "metadata": {
    "id": "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69"
   },
   "source": [
    "# 1. Connect to Fiddler\n",
    "\n",
    "Before you can add information about your model with Fiddler, you'll need to connect using our Python client.\n",
    "\n",
    "---\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your organization ID\n",
    "3. Your authorization token\n",
    "\n",
    "The latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21245781-c546-41de-9c18-9409361615e3",
   "metadata": {
    "id": "21245781-c546-41de-9c18-9409361615e3"
   },
   "outputs": [],
   "source": [
    "URL = 'https://preprod.fiddler.ai'  # Make sure to include the full URL (including https://).\n",
    "ORG_ID = 'preprod'\n",
    "AUTH_TOKEN = '6lxdgyAZ3B2PNFxR3GZ7N4ao6As6UvicPQdamdaU13g'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9678de-4d81-4b9b-905d-e2a6b0d8b141",
   "metadata": {
    "id": "cd9678de-4d81-4b9b-905d-e2a6b0d8b141"
   },
   "source": [
    "Now just run the following code block to connect the client to your Fiddler environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2abb4cb3-907a-4405-866e-dd4591c4957b",
   "metadata": {
    "id": "2abb4cb3-907a-4405-866e-dd4591c4957b"
   },
   "outputs": [],
   "source": [
    "client = fdl.FiddlerApi(\n",
    "    url=URL,\n",
    "    org_id=ORG_ID,\n",
    "    auth_token=AUTH_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88c43f3-1b5e-427d-92ed-307299d73bea",
   "metadata": {
    "id": "d88c43f3-1b5e-427d-92ed-307299d73bea"
   },
   "source": [
    "Once you connect, you can create a new project by specifying a unique project ID in the client's [create_project](https://docs.fiddler.ai/reference/clientcreate_project) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ba61dc-a436-4186-8b07-68fa429d34d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82ba61dc-a436-4186-8b07-68fa429d34d3",
    "outputId": "e1055a05-fa15-45f8-fd78-5e20627b2417"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: imdb_explainability already exists\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'imdb_explainability'\n",
    "\n",
    "if not PROJECT_ID in client.list_projects():\n",
    "    print(f'Creating project: {PROJECT_ID}')\n",
    "    client.create_project(PROJECT_ID)\n",
    "else:\n",
    "    print(f'Project: {PROJECT_ID} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900ae24-997b-4422-8349-b2a097025745",
   "metadata": {
    "id": "9900ae24-997b-4422-8349-b2a097025745"
   },
   "source": [
    "# 2. Upload a baseline dataset\n",
    "\n",
    "In this example, we'll be considering the case where we have a model that **predicts sentiment for movie reviews**.  \n",
    "  \n",
    "**Fiddler needs a small  sample of data that can serve as a baseline**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*For more information on how to design a baseline dataset, [click here](https://docs.fiddler.ai/docs/designing-a-baseline-dataset).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a715829-783e-4f72-9fcf-0ff78379ba33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "8a715829-783e-4f72-9fcf-0ff78379ba33",
    "outputId": "0031c673-d2ef-4fb7-98d6-d3248a5c5f68"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A real blow-up of the film literally. This Bri...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.190378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I only wish that Return of the Jedi, have been...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.282132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"I like cheap perfume better; it doesn't last ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.238484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On the eighth day God created Georges. But the...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.650361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No, this is not no Alice fairy tale my friends...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.859355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Boris Karloff and Bela Lugosi made many films ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.845252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>As horror fans we all know that blind rentals ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.282349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>While visiting Romania with his CIA dad, Tony(...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.730350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>This one was marred by potentially great match...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.619230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Adrian has just gone out of the asylum, being ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.386681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  polarity  sentiment\n",
       "0      A real blow-up of the film literally. This Bri...     False   0.190378\n",
       "1      I only wish that Return of the Jedi, have been...      True   0.282132\n",
       "2      \"I like cheap perfume better; it doesn't last ...      True   0.238484\n",
       "3      On the eighth day God created Georges. But the...      True   0.650361\n",
       "4      No, this is not no Alice fairy tale my friends...      True   0.859355\n",
       "...                                                  ...       ...        ...\n",
       "24995  Boris Karloff and Bela Lugosi made many films ...      True   0.845252\n",
       "24996  As horror fans we all know that blind rentals ...     False   0.282349\n",
       "24997  While visiting Romania with his CIA dad, Tony(...      True   0.730350\n",
       "24998  This one was marred by potentially great match...     False   0.619230\n",
       "24999  Adrian has just gone out of the asylum, being ...     False   0.386681\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_BASELINE_CSV = 'https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/imdb_baseline.csv'\n",
    "\n",
    "baseline_df = pd.read_csv(PATH_TO_BASELINE_CSV)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821605b6-263d-4c95-9f0e-0812cdbc9961",
   "metadata": {
    "id": "821605b6-263d-4c95-9f0e-0812cdbc9961"
   },
   "source": [
    "Fiddler uses this baseline dataset to keep track of important information about your data.\n",
    "  \n",
    "This includes **data types**, **data ranges**, and **unique values** for categorical variables.\n",
    "\n",
    "---\n",
    "\n",
    "You can construct a [DatasetInfo](https://docs.fiddler.ai/reference/fdldatasetinfo) object to be used as **a schema for keeping track of this information** by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1c15218-b987-4cf2-8f2b-e413c7aae49a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "b1c15218-b987-4cf2-8f2b-e413c7aae49a",
    "outputId": "e1d019e2-001d-428d-d599-74b608aa0ca0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"border: thin solid rgb(41, 57, 141); padding: 10px;\"><h3 style=\"text-align: center; margin: auto;\">DatasetInfo\n",
       "</h3><pre>display_name: \n",
       "files: []\n",
       "</pre><hr>Columns:<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>count(possible_values)</th>\n",
       "      <th>is_nullable</th>\n",
       "      <th>value_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence</td>\n",
       "      <td>STRING</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>polarity</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0.002 - 0.994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>"
      ],
      "text/plain": [
       "DatasetInfo:\n",
       "  display_name: \n",
       "  files: []\n",
       "  columns:\n",
       "          column    dtype count(possible_values) is_nullable    value_range\n",
       "    0   sentence   STRING                              False               \n",
       "    1   polarity  BOOLEAN                      2       False               \n",
       "    2  sentiment    FLOAT                              False  0.002 - 0.994"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info = fdl.DatasetInfo.from_dataframe(baseline_df, max_inferred_cardinality=100)\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44dc2e6-37a0-4411-8a7e-420a12942ab4",
   "metadata": {
    "id": "a44dc2e6-37a0-4411-8a7e-420a12942ab4"
   },
   "source": [
    "Then use the client's [upload_dataset](https://docs.fiddler.ai/reference/clientupload_dataset) function to send this information to Fiddler.\n",
    "  \n",
    "*Just include:*\n",
    "1. A unique dataset ID\n",
    "2. The baseline dataset as a pandas DataFrame\n",
    "3. The `DatasetInfo` object you just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a47e6262-bd7d-4162-89ef-c2d1f140eb40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a47e6262-bd7d-4162-89ef-c2d1f140eb40",
    "outputId": "b1d5079a-9241-4d01-faac-50f7992fe177"
   },
   "outputs": [],
   "source": [
    "DATASET_ID = 'imdb_baseline'\n",
    "\n",
    "client.upload_dataset(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    dataset={\n",
    "        'baseline': baseline_df\n",
    "    },\n",
    "    info=dataset_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58c04c-9735-4b16-a67e-85397debdd9d",
   "metadata": {
    "id": "7e58c04c-9735-4b16-a67e-85397debdd9d"
   },
   "source": [
    "Within your Fiddler environment's UI, you should now be able to see the newly created dataset within your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6af46-dd9b-46bf-a665-6224362bfa24",
   "metadata": {
    "id": "15c6af46-dd9b-46bf-a665-6224362bfa24"
   },
   "source": [
    "## 3. Upload your model package\n",
    "\n",
    "Now it's time to upload your model package to Fiddler.  To complete this step, we need to ensure we have the assets required to load the model and a package.py script that tells Fiddler how to call the model's prediction endpoint.  It doesn't matter what this directory is called, but for this example we will call it **/model**.  We also need a few subdirectories to house other assets needed to load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df90f373-7f0a-4475-971a-d847eff7208f",
   "metadata": {
    "id": "df90f373-7f0a-4475-971a-d847eff7208f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"model\")\n",
    "os.makedirs(\"model/saved_model\")\n",
    "os.makedirs(\"model/saved_model/variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a7474-d52c-4257-8494-cc610e027804",
   "metadata": {
    "id": "e51a7474-d52c-4257-8494-cc610e027804"
   },
   "source": [
    "***Your model package directory will need to contain:***\n",
    "1. A **package.py** file which explains to Fiddler how to invoke your model's prediction endpoint\n",
    "2. And the **model artifact** and other files required to load the model\n",
    "3. A **requirements.txt** specifying which python libraries need by package.py\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1.a  Create the **model_info** object \n",
    "\n",
    "This is done by creating our [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42d35d83-8548-400b-b648-88836cc9bc49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "id": "42d35d83-8548-400b-b648-88836cc9bc49",
    "outputId": "93b9c25e-3fdd-4ad0-d5df-f3a182c9ad2c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using binary_classification_threshold=0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"border: thin solid rgb(41, 57, 141); padding: 10px;\"><h3 style=\"text-align: center; margin: auto;\">ModelInfo\n",
       "</h3><pre>  display_name: IMDB Sentiment Classifier\n",
       "  description: imdb rnn sentiment classifier\n",
       "  input_type: ModelInputType.TEXT\n",
       "  model_task: ModelTask.BINARY_CLASSIFICATION\n",
       "  target_class_order: [False, True]\n",
       "  preferred_explanation: ig_flex\n",
       "  custom_explanation_names: []\n",
       "  misc: {}</pre><hr>targets:<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>count(possible_values)</th>\n",
       "      <th>is_nullable</th>\n",
       "      <th>value_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polarity</td>\n",
       "      <td>BOOLEAN</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><hr>inputs:<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>count(possible_values)</th>\n",
       "      <th>is_nullable</th>\n",
       "      <th>value_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence</td>\n",
       "      <td>STRING</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><hr>outputs:<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>count(possible_values)</th>\n",
       "      <th>is_nullable</th>\n",
       "      <th>value_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0 - 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>"
      ],
      "text/plain": [
       "ModelInfo:\n",
       "  display_name: IMDB Sentiment Classifier\n",
       "  description: imdb rnn sentiment classifier\n",
       "  input_type: ModelInputType.TEXT\n",
       "  model_task: ModelTask.BINARY_CLASSIFICATION\n",
       "  target_class_order: [False, True]\n",
       "  preferred_explanation: ig_flex\n",
       "  custom_explanation_names: []\n",
       "  inputs:\n",
       "         column   dtype count(possible_values) is_nullable value_range\n",
       "    0  sentence  STRING                              False            \n",
       "  outputs:\n",
       "          column  dtype count(possible_values) is_nullable value_range\n",
       "    0  sentiment  FLOAT                              False       0 - 0\n",
       "\n",
       "\n",
       "\n",
       "  targets:\n",
       "         column    dtype  count(possible_values) is_nullable value_range\n",
       "    0  polarity  BOOLEAN                       2       False              misc:\n",
       "    {}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'polarity'\n",
    "features = ['sentence']\n",
    "output = ['sentiment']\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=client.get_dataset_info(PROJECT_ID, DATASET_ID),\n",
    "    target=target,\n",
    "    features=features,\n",
    "    input_type=fdl.ModelInputType.TEXT,\n",
    "    model_task=fdl.ModelTask.BINARY_CLASSIFICATION,\n",
    "    outputs=output,\n",
    "    display_name='IMDB Sentiment Classifier',\n",
    "    description='imdb rnn sentiment classifier',\n",
    "    preferred_explanation_method=fdl.ExplanationMethod.IG_FLEX\n",
    ")\n",
    "\n",
    "model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7c3e5",
   "metadata": {},
   "source": [
    "### 3.1.b Add Model Information to Fiddler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9VM-PLniLDg3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9VM-PLniLDg3",
    "outputId": "7388f960-f740-4f74-e915-97628153f173"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = 'imdb_rnn'\n",
    "\n",
    "client.add_model(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    model_id=MODEL_ID,\n",
    "    model_info=model_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb1f43-dd33-473d-b788-086cbbb3d10d",
   "metadata": {
    "id": "83bb1f43-dd33-473d-b788-086cbbb3d10d"
   },
   "source": [
    "### 3.2 Create the **package.py** file\n",
    "\n",
    "The contents of the cell below will be written into our ***package.py*** file.  This is the step that will be most unique based on model type, framework and use case.  The model's ***package.py*** file also allows for preprocessing transformations and other processing before the model's prediction endpoint is called.  For more information about how to create the ***package.py*** file for a variety of model tasks and frameworks, please reference the [Uploading a Model Artifact](https://docs.fiddler.ai/docs/uploading-a-model-artifact#packagepy-script) section of the Fiddler product documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa0e075-34cf-425b-9fb5-d773c507cc48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fa0e075-34cf-425b-9fb5-d773c507cc48",
    "outputId": "5c3ea18d-a68c-46f0-897d-0ff183e14044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model/package.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/package.py\n",
    "\n",
    "import pathlib\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import fiddler as fdl\n",
    "\n",
    "# Name the output of your model here - this will need to match the model schema we define in the next notebook\n",
    "OUTPUT_COL = ['sentiment']\n",
    "\n",
    "# These are the names of the inputs of yout TensorFlow model\n",
    "FEATURE_LABEL = 'sentence'\n",
    "\n",
    "MODEL_ARTIFACT_PATH = 'saved_model'\n",
    "\n",
    "TOKENIZER_PATH = 'tokenizer.pkl'\n",
    "\n",
    "ATTRIBUTABLE_LAYER_NAMES = EMBEDDING_NAMES = ['embedding']\n",
    "\n",
    "MAX_SEQ_LENGTH = 150\n",
    "\n",
    "\n",
    "def _pad(seq):\n",
    "    return pad_sequences(seq, MAX_SEQ_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "class FiddlerModel:\n",
    "    def __init__(self):\n",
    "        \"\"\"Model deserialization and initialization goes here.  Any additional serialized preprocession\n",
    "        transformations would be initialized as well - e.g. tokenizers, embedding lookups, etc.\n",
    "        \"\"\"\n",
    "        self.model_dir = pathlib.Path(__file__).parent\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            str(self.model_dir / MODEL_ARTIFACT_PATH)\n",
    "        )\n",
    "\n",
    "        # Construct sub-models (for each ATTRIBUTABLE_LAYER_NAME)\n",
    "        # if not possible to attribute directly to the input (e.g. embeddings).\n",
    "        self.att_sub_models = {\n",
    "            att_layer: Model(\n",
    "                self.model.inputs, outputs=self.model.get_layer(att_layer).output\n",
    "            )\n",
    "            for att_layer in ATTRIBUTABLE_LAYER_NAMES\n",
    "        }\n",
    "\n",
    "        with open(str(self.model_dir / TOKENIZER_PATH), 'rb') as f:\n",
    "            self.tokenizer = pickle.load(f)\n",
    "\n",
    "        self.grad_model = self._define_model_grads()\n",
    "\n",
    "    def get_settings(self):\n",
    "\n",
    "        # from ig_flex_exec.py\n",
    "        # DEFAULT_START_STEPS = 32\n",
    "        # DEFAULT_MAX_STEPS = 2048\n",
    "        # DEFAULT_MAX_ERROR_PCT = 1.0\n",
    "\n",
    "        return {\n",
    "            'ig_start_steps': 32,  # 32\n",
    "            'ig_max_steps': 4096,  # 2048\n",
    "            'ig_min_error_pct': 5.0,  # 1.0\n",
    "        }\n",
    "\n",
    "    def transform_to_attributable_input(self, input_df):\n",
    "        \"\"\"This method is called by the platform and is responsible for transforming the input dataframe\n",
    "        to the upstream-most representation of model inputs that belongs to a continuous vector-space.\n",
    "        For this example, the model inputs themselves meet this requirement.  For models with embedding\n",
    "        layers (esp. NLP models) the first attributable layer is downstream of that.\n",
    "        \"\"\"\n",
    "        transformed_input = self._transform_input(input_df)\n",
    "\n",
    "        return {\n",
    "            att_layer: att_sub_model.predict(transformed_input)\n",
    "            for att_layer, att_sub_model in self.att_sub_models.items()\n",
    "        }\n",
    "\n",
    "    def get_ig_baseline(self, input_df):\n",
    "        \"\"\"This method is used to generate the baseline against which to compare the input.\n",
    "        It accepts a pandas DataFrame object containing rows of raw feature vectors that\n",
    "        need to be explained (in case e.g. the baseline must be sized according to the explain point).\n",
    "        Must return a pandas DataFrame that can be consumed by the predict method described earlier.\n",
    "        \"\"\"\n",
    "        baseline_df = input_df.copy()\n",
    "        baseline_df[FEATURE_LABEL] = input_df[FEATURE_LABEL].apply(lambda x: '')\n",
    "\n",
    "        return baseline_df\n",
    "\n",
    "    def _transform_input(self, input_df):\n",
    "        \"\"\"Helper function that accepts a pandas DataFrame object containing rows of raw feature vectors.\n",
    "        The output of this method can be any Python object. This function can also\n",
    "        be used to deserialize complex data types stored in dataset columns (e.g. arrays, or images\n",
    "        stored in a field in UTF-8 format).\n",
    "        \"\"\"\n",
    "        sequences = self.tokenizer.texts_to_sequences(input_df[FEATURE_LABEL])\n",
    "        sequences_matrix = sequence.pad_sequences(\n",
    "            sequences, maxlen=MAX_SEQ_LENGTH, padding='post'\n",
    "        )\n",
    "        return sequences_matrix.tolist()\n",
    "\n",
    "    def predict(self, input_df):\n",
    "        \"\"\"Basic predict wrapper.  Takes a DataFrame of input features and returns a DataFrame\n",
    "        of predictions.\n",
    "        \"\"\"\n",
    "        transformed_input = self._transform_input(input_df)\n",
    "        pred = self.model.predict(transformed_input)\n",
    "        return pd.DataFrame(pred, columns=OUTPUT_COL)\n",
    "\n",
    "    def compute_gradients(self, attributable_input):\n",
    "        \"\"\"This method computes gradients of the model output wrt to the differentiable input.\n",
    "        If there are embeddings, the attributable_input should be the output of the embedding\n",
    "        layer. In the backend, this method receives the output of the transform_to_attributable_input()\n",
    "        method. This must return an array of dictionaries, where each entry of the array is the attribution\n",
    "        for an output. As in the example provided, in case of single output models, this is an array with\n",
    "        single entry. For the dictionary, the key is the name of the input layer and the values are the\n",
    "        attributions.\n",
    "        \"\"\"\n",
    "        gradients_by_output = []\n",
    "        attributable_input_tensor = {\n",
    "            k: tf.identity(v) for k, v in attributable_input.items()\n",
    "        }\n",
    "        gradients_dic_tf = self._gradients_input(attributable_input_tensor)\n",
    "        gradients_dic_numpy = dict(\n",
    "            [key, np.asarray(value)] for key, value in gradients_dic_tf.items()\n",
    "        )\n",
    "        gradients_by_output.append(gradients_dic_numpy)\n",
    "        return gradients_by_output\n",
    "\n",
    "    def _gradients_input(self, x):\n",
    "        \"\"\"\n",
    "        Function to Compute gradients.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x)\n",
    "            preds = self.grad_model(x)\n",
    "\n",
    "        grads = tape.gradient(preds, x)\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def _define_model_grads(self):\n",
    "        \"\"\"\n",
    "        Define a differentiable model, cut from the Embedding Layers.\n",
    "        This will take as input what the transform_to_attributable_input function defined.\n",
    "        \"\"\"\n",
    "        model = tf.keras.models.load_model(str(self.model_dir / 'saved_model'))\n",
    "\n",
    "        for index, name in enumerate(EMBEDDING_NAMES):\n",
    "            model.layers.remove(model.get_layer(name))\n",
    "            model.layers[index]._batch_input_shape = (None, 150, 64)\n",
    "            model.layers[index]._dtype = 'float32'\n",
    "            model.layers[index]._name = name\n",
    "\n",
    "        new_model = tf.keras.models.model_from_json(model.to_json())\n",
    "\n",
    "        for layer in new_model.layers:\n",
    "            try:\n",
    "                layer.set_weights(self.model.get_layer(name=layer.name).get_weights())\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return new_model\n",
    "\n",
    "    #  Here's a project_attributions that works for a different single text input model\n",
    "\n",
    "    # input_df: explain_point df from raw feature space (model_info)\n",
    "    # attributions: array[<output_dims>] of dict{tensor_names: }\n",
    "    #     of array[tensor_dims...]\n",
    "    # returns: dict{output_names: } of feature attributions described in\n",
    "    #     GEM [generalized explanation markup].\n",
    "    def project_attributions(self, input_df, attributions):\n",
    "        explanations_by_output = {}\n",
    "\n",
    "        for output_field_index, att in enumerate(attributions):\n",
    "            segments = re.split(\n",
    "                r'([ ' + self.tokenizer.filters + '])', input_df.iloc[0][FEATURE_LABEL]\n",
    "            )\n",
    "\n",
    "            unpadded_tokens = [\n",
    "                self.tokenizer.texts_to_sequences([x])[0]\n",
    "                for x in input_df[FEATURE_LABEL].values\n",
    "            ]\n",
    "\n",
    "            padded_tokens = _pad(unpadded_tokens)\n",
    "\n",
    "            word_tokens = self.tokenizer.sequences_to_texts(\n",
    "                [[x] for x in padded_tokens[0]]\n",
    "            )\n",
    "\n",
    "            # Note - summing over attributions in the embedding direction\n",
    "            word_attributions = np.sum(att['embedding'][-len(word_tokens) :], axis=1)\n",
    "\n",
    "            i = 0\n",
    "            final_attributions = []\n",
    "            final_segments = []\n",
    "            for segment in segments:\n",
    "                if segment is not '':  # dump empty tokens\n",
    "                    final_segments.append(segment)\n",
    "                    seg_low = segment.lower()\n",
    "                    if len(word_tokens) > i and seg_low == word_tokens[i]:\n",
    "                        final_attributions.append(word_attributions[i])\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        final_attributions.append(0)\n",
    "\n",
    "            gem_text = fdl.gem.GEMText(\n",
    "                feature_name=FEATURE_LABEL,\n",
    "                text_segments=final_segments,\n",
    "                text_attributions=final_attributions,\n",
    "            )\n",
    "\n",
    "            gem_container = fdl.gem.GEMContainer(contents=[gem_text])\n",
    "\n",
    "            explanations_by_output[\n",
    "                OUTPUT_COL[output_field_index]\n",
    "            ] = gem_container.render()\n",
    "\n",
    "        return explanations_by_output\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    return FiddlerModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4097b-3a18-405d-8f01-fde414fea49f",
   "metadata": {
    "id": "cda4097b-3a18-405d-8f01-fde414fea49f"
   },
   "source": [
    "### 3.3  Ensure your model's artifact is in the **/model** directory\n",
    "\n",
    "Make sure your model artifact is also present in the model package directory as well as any dependencies called out in a *requirements.txt* file.  The following cell will move this model's binary file, other required assets and our requirements.txt file into our */model* directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26f8b88f-d5cf-4156-929d-751b175abf54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26f8b88f-d5cf-4156-929d-751b175abf54",
    "outputId": "b676bd1b-a62e-4da1-83ac-c46d69d8e69a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model/saved_model/variables/variables.index',\n",
       " <http.client.HTTPMessage at 0x7fbbe53d12e0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/imdb/tokenizer.pkl\", \"model/tokenizer.pkl\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/requirements.txt\", \"model/requirements.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/imdb/saved_model/keras_metadata.pb\", \"model/saved_model/keras_metadata.pb\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/imdb/saved_model/saved_model.pb\", \"model/saved_model/saved_model.pb\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/imdb/saved_model/variables/variables.data-00000-of-00001\", \"model/saved_model/variables/variables.data-00000-of-00001\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/imdb/saved_model/variables/variables.index\", \"model/saved_model/variables/variables.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2efce",
   "metadata": {},
   "source": [
    "### 3.4 Define Model Parameters \n",
    "\n",
    "Fiddler provides extreme flexibility when onboarding a model artifact for explainability.  Each model runs in its own container with the libraries it needs as defined in the requirement.txt file.  The container is built from a base image and we can specify the compute needs our model requires.  This is done by creating our [DEPLOYMENT_PARAMETERS](https://docs.fiddler.ai/reference/fdldeploymentparams) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff9e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_PARAMETERS = fdl.DeploymentParams(image_uri=\"md-base/python/deep-learning:1.0.0\",\n",
    "                                                cpu=1000,\n",
    "                                                memory=1024,\n",
    "                                                replicas=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ddcab9-54fa-4367-92f0-b87306d14b7e",
   "metadata": {
    "id": "f8ddcab9-54fa-4367-92f0-b87306d14b7e"
   },
   "source": [
    "### Finally, upload the model package directory\n",
    "\n",
    "Once the model's artifact is in the */model* directory along with the **pacakge.py** file and requirments.txt the model package directory can be uploaded to Fiddler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ff090a7-b4df-4dc0-8c1d-ac05f2f0eb3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ff090a7-b4df-4dc0-8c1d-ac05f2f0eb3f",
    "outputId": "43d22682-a361-4f65-8ad7-dcc86726f731"
   },
   "outputs": [],
   "source": [
    "client.add_model_artifact(model_dir='model/', project_id=PROJECT_ID, model_id=MODEL_ID, deployment_params=DEPLOYMENT_PARAMETERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd366b0-f40b-4e28-8325-12d429987349",
   "metadata": {
    "id": "acd366b0-f40b-4e28-8325-12d429987349"
   },
   "source": [
    "Within your Fiddler environment's UI, you should now be able to see the newly created model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e237cc-d7b6-4181-991f-ae27bf61cce3",
   "metadata": {
    "id": "25e237cc-d7b6-4181-991f-ae27bf61cce3"
   },
   "source": [
    "# 4. Explain your model\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "Now just head to your Fiddler environment's UI and check out NLP explainability for this model.  You can also run the explanation from the Fiddler client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1ad79-cb2b-414c-a32a-df43a284e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slice to run explanation on\n",
    "explain_df = df_baseline[1:2]\n",
    "explain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd332b7-febc-4df0-b514-36cc9555d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = client.run_explanation(\n",
    "    project_id=PROJECT_ID,\n",
    "    model_id=MODEL_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    df=explain_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e40fa7-6e1e-43c8-8959-839b2599e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f07628-f153-453d-b53a-e829e16f94ef",
   "metadata": {
    "id": "a9f07628-f153-453d-b53a-e829e16f94ef"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
    "\n",
    "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
