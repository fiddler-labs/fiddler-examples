{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c3549a",
   "metadata": {
    "id": "f0c3549a"
   },
   "source": [
    "# Onboard a Credit Approval Model to Evaluate Fairness\n",
    "\n",
    "In this notebook, we present the steps for onboarding a model to evaluate model fairness.  \n",
    "\n",
    "Fiddler is the pioneer in enterprise Model Performance Management (MPM), offering a unified platform that enables Data Science, MLOps, Risk, Compliance, Analytics, and LOB teams to **monitor, explain, analyze, and improve ML deployments at enterprise scale**. \n",
    "Obtain contextual insights at any stage of the ML lifecycle, improve predictions, increase transparency and fairness, and optimize business revenue.\n",
    "\n",
    "---\n",
    "\n",
    "You can experience Fiddler's Fairness Offering ***in minutes*** by following these four quick steps:\n",
    "\n",
    "1. Connect to Fiddler\n",
    "2. Upload a baseline dataset\n",
    "3. Upload a model package directory containing the **1) package.py and 2) model artifact**\n",
    "4. Get Fairness insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1db734",
   "metadata": {
    "id": "9f1db734"
   },
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c2b2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f99c2b2f",
    "outputId": "40667583-548d-47e6-c7de-bea6b74151b8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q fiddler-client\n",
    "\n",
    "import fiddler as fdl\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"Running Fiddler client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69",
   "metadata": {
    "id": "dcc2ed42-2cd9-424c-bc04-f8fcd3c01a69"
   },
   "source": [
    "# 1. Connect to Fiddler\n",
    "\n",
    "Before you can add information about your model with Fiddler, you'll need to connect using our Python client.\n",
    "\n",
    "---\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your organization ID\n",
    "3. Your authorization token\n",
    "\n",
    "The latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21245781-c546-41de-9c18-9409361615e3",
   "metadata": {
    "id": "21245781-c546-41de-9c18-9409361615e3"
   },
   "outputs": [],
   "source": [
    "URL = '' # Make sure to include the full URL (including https://).\n",
    "ORG_ID = ''\n",
    "AUTH_TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9678de-4d81-4b9b-905d-e2a6b0d8b141",
   "metadata": {
    "id": "cd9678de-4d81-4b9b-905d-e2a6b0d8b141"
   },
   "source": [
    "Now just run the following code block to connect the client to your Fiddler environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb4cb3-907a-4405-866e-dd4591c4957b",
   "metadata": {
    "id": "2abb4cb3-907a-4405-866e-dd4591c4957b"
   },
   "outputs": [],
   "source": [
    "client = fdl.FiddlerApi(\n",
    "    url=URL,\n",
    "    org_id=ORG_ID,\n",
    "    auth_token=AUTH_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88c43f3-1b5e-427d-92ed-307299d73bea",
   "metadata": {
    "id": "d88c43f3-1b5e-427d-92ed-307299d73bea"
   },
   "source": [
    "Once you connect, you can create a new project by specifying a unique project ID in the client's [create_project](https://docs.fiddler.ai/reference/clientcreate_project) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba61dc-a436-4186-8b07-68fa429d34d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82ba61dc-a436-4186-8b07-68fa429d34d3",
    "outputId": "e1055a05-fa15-45f8-fd78-5e20627b2417"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'credit_approval'\n",
    "\n",
    "if not PROJECT_ID in client.list_projects():\n",
    "    print(f'Creating project: {PROJECT_ID}')\n",
    "    client.create_project(PROJECT_ID)\n",
    "else:\n",
    "    print(f'Project: {PROJECT_ID} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900ae24-997b-4422-8349-b2a097025745",
   "metadata": {
    "id": "9900ae24-997b-4422-8349-b2a097025745"
   },
   "source": [
    "# 2. Upload a baseline dataset\n",
    "\n",
    "In this example, we'll be considering the case where we're a bank and we have **a model that predicts credit approval worthiness**.\n",
    "  \n",
    "In order to get insights into the model's performance, **Fiddler needs a small  sample of data that can serve as a baseline** for making comparisons with data in production.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*For more information on how to design a baseline dataset, [click here](https://docs.fiddler.ai/docs/designing-a-baseline-dataset).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a715829-783e-4f72-9fcf-0ff78379ba33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "8a715829-783e-4f72-9fcf-0ff78379ba33",
    "outputId": "0031c673-d2ef-4fb7-98d6-d3248a5c5f68"
   },
   "outputs": [],
   "source": [
    "PATH_TO_BASELINE_CSV = 'https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/intersectionally_unfair_baseline.csv'\n",
    "\n",
    "baseline_df = pd.read_csv(PATH_TO_BASELINE_CSV)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821605b6-263d-4c95-9f0e-0812cdbc9961",
   "metadata": {
    "id": "821605b6-263d-4c95-9f0e-0812cdbc9961"
   },
   "source": [
    "Fiddler uses this baseline dataset to keep track of important information about your data.\n",
    "  \n",
    "This includes **data types**, **data ranges**, and **unique values** for categorical variables.\n",
    "\n",
    "---\n",
    "\n",
    "You can construct a [DatasetInfo](https://docs.fiddler.ai/reference/fdldatasetinfo) object to be used as **a schema for keeping track of this information** by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c15218-b987-4cf2-8f2b-e413c7aae49a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "b1c15218-b987-4cf2-8f2b-e413c7aae49a",
    "outputId": "e1d019e2-001d-428d-d599-74b608aa0ca0"
   },
   "outputs": [],
   "source": [
    "dataset_info = fdl.DatasetInfo.from_dataframe(baseline_df, max_inferred_cardinality=100)\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44dc2e6-37a0-4411-8a7e-420a12942ab4",
   "metadata": {
    "id": "a44dc2e6-37a0-4411-8a7e-420a12942ab4"
   },
   "source": [
    "Then use the client's [upload_dataset](https://docs.fiddler.ai/reference/clientupload_dataset) function to send this information to Fiddler.\n",
    "  \n",
    "*Just include:*\n",
    "1. A unique dataset ID\n",
    "2. The baseline dataset as a pandas DataFrame\n",
    "3. The `DatasetInfo` object you just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e6262-bd7d-4162-89ef-c2d1f140eb40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a47e6262-bd7d-4162-89ef-c2d1f140eb40",
    "outputId": "b1d5079a-9241-4d01-faac-50f7992fe177"
   },
   "outputs": [],
   "source": [
    "DATASET_ID = 'intersectionally_unfair'\n",
    "\n",
    "client.upload_dataset(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    dataset={\n",
    "        'baseline': baseline_df\n",
    "    },\n",
    "    info=dataset_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58c04c-9735-4b16-a67e-85397debdd9d",
   "metadata": {
    "id": "7e58c04c-9735-4b16-a67e-85397debdd9d"
   },
   "source": [
    "Within your Fiddler environment's UI, you should now be able to see the newly created dataset within your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6af46-dd9b-46bf-a665-6224362bfa24",
   "metadata": {
    "id": "15c6af46-dd9b-46bf-a665-6224362bfa24"
   },
   "source": [
    "## 3. Upload your model package\n",
    "\n",
    "Now it's time to upload your model package to Fiddler.  To complete this step, we need to ensure we have 2 assets in a directory.  It doesn't matter what this directory is called, but for this example we will call it **/model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90f373-7f0a-4475-971a-d847eff7208f",
   "metadata": {
    "id": "df90f373-7f0a-4475-971a-d847eff7208f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a7474-d52c-4257-8494-cc610e027804",
   "metadata": {
    "id": "e51a7474-d52c-4257-8494-cc610e027804"
   },
   "source": [
    "***Your model package directory will need to contain:***\n",
    "1. A **package.py** file which explains to Fiddler how to invoke your model's prediction endpoint\n",
    "2. And the **model artifact** itself\n",
    "3. (Optional) A **requirements.txt** specifying which python libraries need by package.py.  This example doesn't require any additional libraries to be installed so a requirements.txt file is not needed here.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1.a  Create the **model_info** object \n",
    "\n",
    "This is done by creating our [model_info](https://docs.fiddler.ai/reference/fdlmodelinfo) object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d35d83-8548-400b-b648-88836cc9bc49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "id": "42d35d83-8548-400b-b648-88836cc9bc49",
    "outputId": "93b9c25e-3fdd-4ad0-d5df-f3a182c9ad2c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_cols = ['gender','race']\n",
    "feature_columns = ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
    "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
    "       'CNT_FAM_MEMBERS', 'income', 'paid_off', '#_of_pastdues', 'no_loan']\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=client.get_dataset_info(PROJECT_ID, DATASET_ID),\n",
    "    target='target', \n",
    "    features=feature_columns,\n",
    "    metadata_cols = metadata_cols,\n",
    "    outputs=['Approve_probability_of_credit_request'],\n",
    "    display_name='Credit model with systemic racial and gender bias',\n",
    "    description='logistic reg model'\n",
    ")\n",
    "\n",
    "model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7c3e5",
   "metadata": {},
   "source": [
    "### 3.1.b Add Model Information to Fiddler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9VM-PLniLDg3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9VM-PLniLDg3",
    "outputId": "7388f960-f740-4f74-e915-97628153f173"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = 'intersectionally_unfair'\n",
    "\n",
    "client.add_model(\n",
    "    project_id=PROJECT_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    model_id=MODEL_ID,\n",
    "    model_info=model_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb1f43-dd33-473d-b788-086cbbb3d10d",
   "metadata": {
    "id": "83bb1f43-dd33-473d-b788-086cbbb3d10d"
   },
   "source": [
    "### 3.2 Create the **package.py** file\n",
    "\n",
    "The contents of the cell below will be written into our ***package.py*** file.  This is the step that will be most unique based on model type, framework and use case.  The model's ***package.py*** file also allows for preprocessing transformations and other processing before the model's prediction endpoint is called.  For more information about how to create the ***package.py*** file for a variety of model tasks and frameworks, please reference the [Uploading a Model Artifact](https://docs.fiddler.ai/docs/uploading-a-model-artifact#packagepy-script) section of the Fiddler product documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0e075-34cf-425b-9fb5-d773c507cc48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fa0e075-34cf-425b-9fb5-d773c507cc48",
    "outputId": "5c3ea18d-a68c-46f0-897d-0ff183e14044"
   },
   "outputs": [],
   "source": [
    "%%writefile model/package.py\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PACKAGE_PATH = Path(__file__).parent\n",
    "\n",
    "class SklearnModelPackage:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.is_classifier = True\n",
    "        self.is_multiclass = False\n",
    "        self.output_columns = ['Approve_probability_of_credit_request']\n",
    "        with open(PACKAGE_PATH / 'model_unfair.pkl', 'rb') as infile:\n",
    "            self.model = pickle.load(infile)\n",
    "\n",
    "    def predict(self, input_df):\n",
    "        if self.is_classifier:\n",
    "            if self.is_multiclass:\n",
    "                predict_fn = self.model.predict_proba\n",
    "            else:\n",
    "                def predict_fn(x):\n",
    "                    return self.model.predict_proba(x)[:, 1]\n",
    "        else:\n",
    "            predict_fn = self.model.predict\n",
    "        return pd.DataFrame(predict_fn(input_df), columns=self.output_columns)\n",
    "\n",
    "def get_model():\n",
    "    return SklearnModelPackage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4097b-3a18-405d-8f01-fde414fea49f",
   "metadata": {
    "id": "cda4097b-3a18-405d-8f01-fde414fea49f"
   },
   "source": [
    "### 3.3  Ensure your model's artifact is in the **/model** directory\n",
    "\n",
    "Make sure your model artifact (*e.g. the model_unfair.pkl file*) is also present in the model package directory.  The following cell will move this model's pkl file into our */model* directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f8b88f-d5cf-4156-929d-751b175abf54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26f8b88f-d5cf-4156-929d-751b175abf54",
    "outputId": "b676bd1b-a62e-4da1-83ac-c46d69d8e69a"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/models/model_unfair.pkl\", \"model/model_unfair.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2efce",
   "metadata": {},
   "source": [
    "### 3.4 Define Model Parameters \n",
    "\n",
    "This is done by creating our [DEPLOYMENT_PARAMETERS](https://docs.fiddler.ai/reference/fdldeploymentparams) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_PARAMETERS = fdl.DeploymentParams(image_uri=\"md-base/python/machine-learning:1.0.0\",  \n",
    "                                    cpu=100,\n",
    "                                    memory=256,\n",
    "                                    replicas=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ddcab9-54fa-4367-92f0-b87306d14b7e",
   "metadata": {
    "id": "f8ddcab9-54fa-4367-92f0-b87306d14b7e"
   },
   "source": [
    "### Finally, upload the model package directory\n",
    "\n",
    "Once the model's artifact is in the */model* directory along with the **pacakge.py** file and requirments.txt the model package directory can be uploaded to Fiddler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff090a7-b4df-4dc0-8c1d-ac05f2f0eb3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ff090a7-b4df-4dc0-8c1d-ac05f2f0eb3f",
    "outputId": "43d22682-a361-4f65-8ad7-dcc86726f731"
   },
   "outputs": [],
   "source": [
    "client.add_model_artifact(model_dir='model/', project_id=PROJECT_ID, model_id=MODEL_ID, deployment_params=DEPLOYMENT_PARAMETERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd366b0-f40b-4e28-8325-12d429987349",
   "metadata": {
    "id": "acd366b0-f40b-4e28-8325-12d429987349"
   },
   "source": [
    "Within your Fiddler environment's UI, you should now be able to see the newly created model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e237cc-d7b6-4181-991f-ae27bf61cce3",
   "metadata": {
    "id": "25e237cc-d7b6-4181-991f-ae27bf61cce3"
   },
   "source": [
    "# 4. Get Fairness insights\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "Now just head to your Fiddler environment's UI and explore the model's fairness metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ce453-2246-42eb-b441-7a766fb39c7a",
   "metadata": {},
   "source": [
    "Alternatively, you can also run fairness from the Fiddler Python client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89f5e6-a8c9-4a08-b172-2ec95585f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_features = ['gender', 'race']\n",
    "positive_outcome = 1\n",
    "\n",
    "fairness_metrics = client.run_fairness(\n",
    "    project_id=PROJECT_ID,\n",
    "    model_id=MODEL_ID,\n",
    "    dataset_id=DATASET_ID,\n",
    "    protected_features=protected_features,\n",
    "    positive_outcome=positive_outcome\n",
    ")\n",
    "\n",
    "fairness_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f07628-f153-453d-b53a-e829e16f94ef",
   "metadata": {
    "id": "a9f07628-f153-453d-b53a-e829e16f94ef"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
    "\n",
    "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
