{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiddler Ranking Model Quick Start Guide\n",
    "\n",
    "Fiddler offer the ability for your teams to observe you ranking models to understand thier performance and catch issues like data drift before they affect your applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporting Ranking models\n",
    "\n",
    "\n",
    "### Monitoring\n",
    "\n",
    "#### Data Drift\n",
    "We calcualte drift in your model's production events by comaprning it agaisnt the baseline datasets you provide. We offer the following data drift metrics in our platform:\n",
    "\n",
    "- **JSD** - Jensen-Shanon Divercgence \n",
    "- **PSI** - Population Stability Index\n",
    " \n",
    "You can read more about this on our [Data Drift] [https://docs.fiddler.ai/docs/data-drift-platform] docs. \n",
    "\n",
    "#### Performance\n",
    "\n",
    "Fiddler provides 2 ranking specific performance metrics:\n",
    "- **MAP** (Mean Average Precision) at k: available only for binary relevance ranking models.\n",
    "- **NDCG** (Normalized Discounted Cumulative Gain) at k: available for both binary and graded relevance ranking models.  \n",
    "\n",
    "#### Data Integrity \n",
    "Finally you can track Data Integrity and Service Metrics like:\n",
    "- **Missing value violations** — The percentage of missing value violations over all features for a given period of time.\n",
    "- **Type violations** — The percentage of data type mismatch violations over all features for a given period of time.\n",
    "- **Range violations** — The percentage of range mismatch violations over all features for a given period of time.\n",
    "\n",
    "\n",
    "\n",
    "### Explainability\n",
    "\n",
    "#### Global Explanations \n",
    "You can get global or model level impact and importance for each feature that your model uses. This helps you undersatnd what the model focuses on for making the predictions/rankings.\n",
    "\n",
    "#### Point Explanations\n",
    "The SHAP algorithms (Fiddler-SHAP and traditional Kernel SHAP), have been modified to get explanation with respect to the rest of the query result. For example, query ID 'xyz' has 150 results and we want to understand why a particular items has been ranked 3rd. SHAP algorithms will be run with the background dataset formed by the 150 results of the query ID 'xyz'. \n",
    "\n",
    "#### Dependence plots\n",
    "Dependence plots (ICE plots and PDP plots) can both be generated from the Fiddler platfrom to understand the model's inner workings. \n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart: Expedia Search Ranking\n",
    "The following dataset is coming from Expedia. It includes shopping and purchase data as well as information on price competitiveness. The data are organized around a set of “search result impressions”, or the ordered list of hotels that the user sees after they search for a hotel on the Expedia website. In addition to impressions from the existing algorithm, the data contain impressions where the hotels were randomly sorted, to avoid the position bias of the existing algorithm. The user response is provided as a click on a hotel. From: https://www.kaggle.com/c/expedia-personalized-sort/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import time as time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Fiddler and Create a Project\n",
    "First we install and import the Fiddler Python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q fiddler-client\n",
    "import fiddler as fdl\n",
    "print(f\"Running client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can add information about your model with Fiddler, you'll need to connect using our API client.\n",
    "\n",
    "---\n",
    "\n",
    "**We need a few pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your organization ID\n",
    "3. Your authorization token\n",
    "\n",
    "The latter two of these can be found by pointing your browser to your Fiddler URL and navigating to the **Settings** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = '' # Make sure to include the full URL (including https://). For example, https://abc.xyz.ai\n",
    "ORG_ID = ''\n",
    "AUTH_TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the following code block to connect to the Fiddler API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = fdl.FiddlerApi(url=URL, org_id=ORG_ID, auth_token=AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you connect, you can create a new project by specifying a unique project ID in the client's `create_project` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'search_ranking'\n",
    "\n",
    "if not PROJECT_ID in client.list_projects():\n",
    "    print(f'Creating project: {PROJECT_ID}')\n",
    "    client.create_project(PROJECT_ID)\n",
    "else:\n",
    "    print(f'Project: {PROJECT_ID} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Upload the Baseline Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we retrieve the Expedia Dataset as a baseline for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/expedia_baseline_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiddler uses this baseline dataset to keep track of important information about your data.\n",
    "  \n",
    "This includes **data types**, **data ranges**, and **unique values** for categorical variables.\n",
    "\n",
    "---\n",
    "\n",
    "You can construct a `DatasetInfo` object to be used as **a schema for keeping track of this information** by running the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_info = fdl.DatasetInfo.from_dataframe(df=df, max_inferred_cardinality=100)\n",
    "dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use the client's [upload_dataset](https://docs.fiddler.ai/reference/clientupload_dataset) function to send this information to Fiddler!\n",
    "  \n",
    "*Just include:*\n",
    "1. A unique dataset ID\n",
    "2. The baseline dataset as a pandas DataFrame\n",
    "3. The [DatasetInfo](https://docs.fiddler.ai/reference/fdldatasetinfo) object you just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ID = 'expedia_data'\n",
    "client.upload_dataset(project_id=PROJECT_ID,\n",
    "                      dataset={'baseline': df},\n",
    "                      dataset_id=DATASET_ID,\n",
    "                      info=dataset_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain a model's inner workigs we need to upload the model artifacts. Let's train this ranking model with the sample data from expedia that we just downloaded. \n",
    "The following model is trained with **lightgbm 2.3.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a Data Prepration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and validation splits: 90/10 split\n",
    "cutoff_id = df[\"srch_id\"].quantile(0.94) \n",
    "\n",
    "X_train = df.loc[df.srch_id < cutoff_id].drop([\"click_bool\", 'score'], axis=1)\n",
    "X_eval = df.loc[df.srch_id >= cutoff_id].drop([\"click_bool\", 'score'], axis=1)\n",
    "y_train = df.loc[df.srch_id < cutoff_id][\"click_bool\"]\n",
    "y_eval = df.loc[df.srch_id >= cutoff_id][\"click_bool\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMRanker()\n",
    "groups = np.unique(X_train.srch_id, return_counts=True)\n",
    "groups_number = list(groups[1])\n",
    "gbm.fit(X_train, y_train, group=groups_number)\n",
    "gbm.predict(X_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c Saving the Model\n",
    "\n",
    "We need to create a new folder and add the pieces needed for Fiddler to use/run your model. This folder will have:\n",
    "\n",
    "- your model file saved into the format of your choice (json, pickle, h5, ..)\n",
    "- a wrapper: package.py (created in the next step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "os.mkdir(\"model\")\n",
    "\n",
    "model_dir = pathlib.Path('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(model_dir / 'model.pkl', 'wb') as infile:\n",
    "    pickle.dump(gbm, infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Share Model Metadata and Upload the Model\n",
    "\n",
    "Now let's add this model we just created to Fiddler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a Adding model to Fiddler\n",
    "To add a Ranking model you must specify the ModelTask as `RANKING` in the model info object.  \n",
    "\n",
    "Additionally, you must provide the `group_by` argument that corresponds to the query search id. This `group_by` column should be present either in:\n",
    "- `features` : if it is used to build and run the model\n",
    "- `metadata_cols` : if not used by the model \n",
    "\n",
    "Optionally, you can give a `ranking_top_k` number (default is 50). This will be the number of results within each query to take into account while computing the performance metrics in monitoring.  \n",
    "\n",
    "Unless the prediction column was part of your baseline dataset, you must provide the minimum and maximum values predictions can take in a dictionary format (see below).  \n",
    "\n",
    "If your target is categorical (string), you need to provide the `categorical_target_class_details` argument. If your target is numerical and you don't specify this argument, Fiddler will infer it.   \n",
    "\n",
    "This will be the list of possible values for the target **ordered**. The first element should be the least relevant target level, the last element should be the most relevant target level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'click_bool'\n",
    "features = list(df.drop(columns=['click_bool', 'score']).columns)\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=client.get_dataset_info(project_id=PROJECT_ID, dataset_id=DATASET_ID),\n",
    "    target=target,\n",
    "    features=features,\n",
    "    input_type=fdl.ModelInputType.TABULAR,\n",
    "    model_task=fdl.ModelTask.RANKING,\n",
    "    outputs={'score':[-5.0, 3.0]},\n",
    "    group_by='srch_id',\n",
    "    ranking_top_k=20,\n",
    "    categorical_target_class_details=[0, 1]\n",
    ")\n",
    "\n",
    "# inspect model info and modify as needed\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 'expedia_model'\n",
    "\n",
    "if not MODEL_ID in client.list_models(project_id=PROJECT_ID):\n",
    "    client.add_model(\n",
    "        project_id=PROJECT_ID,\n",
    "        dataset_id=DATASET_ID,\n",
    "        model_id=MODEL_ID,\n",
    "        model_info=model_info\n",
    "    )\n",
    "else:\n",
    "    print(f'Model: {MODEL_ID} already exists in Project: {PROJECT_ID}. Please use a different name.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b Create a Model Wrapper Script\n",
    "\n",
    "Package.py is the interface between Fiddler’s backend and your model. This code helps Fiddler to understand the model, its inputs and outputs.\n",
    "\n",
    "You need to implement three parts:\n",
    "- init: Load the model, and any associated files such as feature transformers.\n",
    "- transform: If you use some pre-processing steps not part of the model file, transform the data into a format that the model recognizes.\n",
    "- predict: Make predictions using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model/package.py\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PACKAGE_PATH = Path(__file__).parent\n",
    "\n",
    "class ModelPackage:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "         Load the model file and any pre-processing files if needed.\n",
    "        \"\"\"\n",
    "        self.output_columns = ['score']\n",
    "        \n",
    "        with open(PACKAGE_PATH / 'model.pkl', 'rb') as infile:\n",
    "            self.model = pickle.load(infile)\n",
    "    \n",
    "    def transform(self, input_df):\n",
    "        \"\"\"\n",
    "        Accepts a pandas DataFrame object containing rows of raw feature vectors. \n",
    "        Use pre-processing file to transform the data if needed. \n",
    "        In this example we don't need to transform the data.\n",
    "        Outputs a pandas DataFrame object containing transformed data.\n",
    "        \"\"\"\n",
    "        return input_df\n",
    "    \n",
    "    def predict(self, input_df):\n",
    "        \"\"\"\n",
    "        Accepts a pandas DataFrame object containing rows of raw feature vectors. \n",
    "        Outputs a pandas DataFrame object containing the model predictions whose column labels \n",
    "        must match the output column names in model info.\n",
    "        \"\"\"\n",
    "        transformed_df = self.transform(input_df)\n",
    "        pred = self.model.predict(transformed_df)\n",
    "        return pd.DataFrame(pred, columns=self.output_columns)\n",
    "    \n",
    "def get_model():\n",
    "    return ModelPackage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.c Upload the model files to Fiddler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now you can upload the model artifact files using `add_model_artifact`. \n",
    "   - The `model_dir` is the path for the folder containing the model file(s) and the `package.py` from ther last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading Model files\n",
    "client.add_model_artifact(model_dir=model_dir, project_id=PROJECT_ID, model_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Send Traffic For Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.a Gather and prepare Production Events\n",
    "This is the production log file we are going to upload in Fiddler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs = pd.read_csv('https://media.githubusercontent.com/media/fiddler-labs/fiddler-examples/main/quickstart/data/expedia_logs.csv')\n",
    "df_logs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs['event_id'] = df_logs['event_id'].apply(str)\n",
    "#timeshift to move the data to last 29 days\n",
    "df_logs['time_epoch'] = df_logs['time_epoch'] + (float(time.time()) - df_logs['time_epoch'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ranking, we need to ingest all events from a given Query ID together. To do that, we need to transform the data to a grouped format.  \n",
    "You can use the `convert_flat_csv_data_to_grouped` utility function to do the transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs_grouped = fdl.utils.pandas.convert_flat_csv_data_to_grouped(input_data=df_logs, group_by_col='srch_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logs_grouped.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.b Publish events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.publish_events_batch(project_id=PROJECT_ID,\n",
    "                            model_id=model_id,\n",
    "                            batch_source=df_logs_grouped,\n",
    "                            id_field='event_id',\n",
    "                            timestamp_field='time_epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Get insights\n",
    "\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "You can now head to Fiddler URL and start getting enhanced observability into your model's performance. Run the following code block to get your URL:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('/'.join([URL, 'projects', PROJECT_ID, 'models', MODEL_ID, 'monitor']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please allow 3-5 minutes for monitoring data to populate the charts.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
    "\n",
    "Join our [community Slack](http://fiddler-community.slack.com/) to ask any questions!\n",
    "\n",
    "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
