{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33263a5b",
   "metadata": {},
   "source": [
    "# Fiddler Evals SDK - Using Fiddler Evaluators\n",
    "\n",
    "This quickstart shows how to set up and use Fiddler's built-in evaluators to assess your AI application outputs.\n",
    "\n",
    "**Prerequisites:**\n",
    "- A Fiddler account with API access\n",
    "- An LLM credential configured in **Settings > LLM Gateway**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a70cf41",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Connect to Fiddler and initialize evaluators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8926cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fiddler_evals import init\n",
    "from fiddler_evals.evaluators import RAGFaithfulness, AnswerRelevance\n",
    "\n",
    "URL = ''  # e.g., 'https://your-org.fiddler.ai'\n",
    "TOKEN = ''  # From Settings > Credentials\n",
    "LLM_CREDENTIAL_NAME = ''  # From Settings > LLM Gateway\n",
    "LLM_MODEL_NAME = ''  # e.g., 'fiddler/llama3.1-8b'\n",
    "\n",
    "init(url=URL, token=TOKEN)\n",
    "\n",
    "# Initialize evaluators\n",
    "faithfulness = RAGFaithfulness(model=LLM_MODEL_NAME, credential=LLM_CREDENTIAL_NAME)\n",
    "relevance = AnswerRelevance(model=LLM_MODEL_NAME, credential=LLM_CREDENTIAL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ca06af",
   "metadata": {},
   "source": [
    "## 2. Test Cases\n",
    "\n",
    "Create sample data to evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9174071-9171-41d2-a703-4cf643808f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            'scenario': '✅ Perfect Match',\n",
    "            'query': 'What is the capital of France?',\n",
    "            'context': ['Paris is the capital of France.'],\n",
    "            'response': 'The capital of France is Paris.',\n",
    "        },\n",
    "        {\n",
    "            'scenario': '❌ Hallucination',\n",
    "            'query': 'What are the office hours?',\n",
    "            'context': ['We are closed on weekends.'],\n",
    "            'response': 'We are open 9 AM to 5 PM every day.',\n",
    "        },\n",
    "        {\n",
    "            'scenario': '❌ Irrelevant Answer',\n",
    "            'query': 'How do I reset my password?',\n",
    "            'context': ['To reset, click \"Forgot Password\".'],\n",
    "            'response': 'Our system is very secure and uses 256-bit encryption.',\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a032ff7",
   "metadata": {},
   "source": [
    "## 3. Evaluate\n",
    "\n",
    "Use evaluators to score each test case. Each evaluator returns a score with a `value` (0-1) and `label`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_row(row):\n",
    "    f_score = faithfulness.score(\n",
    "        user_query=row['query'],\n",
    "        rag_response=row['response'],\n",
    "        retrieved_documents=row['context'],\n",
    "    )\n",
    "\n",
    "    r_score = relevance.score(user_query=row['query'], rag_response=row['response'])\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            'Faithfulness': f_score.label,\n",
    "            'Relevance': r_score.label,\n",
    "            'Status': 'HEALTHY'\n",
    "            if f_score.value > 0.6 and r_score.value > 0.6\n",
    "            else 'ISSUE DETECTED',\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfed077",
   "metadata": {},
   "source": [
    "## 4. View Results\n",
    "\n",
    "Display the evaluation results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7909b2-a855-4f36-aec6-8254b2674198",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_cases.join(test_cases.apply(evaluate_row, axis=1))\n",
    "\n",
    "\n",
    "def color_status(val):\n",
    "    color = '#d9534f' if val == 'ISSUE DETECTED' else '#5cb85c'\n",
    "    return f'background-color: {color}; color: white; font-weight: bold'\n",
    "\n",
    "\n",
    "results[['scenario', 'Faithfulness', 'Relevance', 'Status']].style.map(\n",
    "    color_status, subset=['Status']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c97b7d",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Try more of Fiddler's out-of-the-box evaluators\n",
    "- Try custom evaluators in [Part 2: Custom Judge](./Fiddler_Quickstart_Evals_Pt2_CustomJudge.ipynb)\n",
    "- Try Datasets and Experiments in [Part 3: Datasets and Experiments](./Fiddler_Quickstart_Evals_Pt3_Datasets_Experiments.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
