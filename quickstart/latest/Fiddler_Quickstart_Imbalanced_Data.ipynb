{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxxiKou3wZTw",
    "tags": []
   },
   "source": [
    "# Fiddler Quick Start Class Imbalance Guide\n",
    "\n",
    "Many ML use cases, like fraud detection and facial recognition, suffer from what is known as the class imbalance problem.  This problem exists where a vast majority of the inferences seen by the model belong to only one class, known as the majority class.  This makes detecting drift in the minority class very difficult as the \"signal\" is completely outweighed by the large number of inferences seen in the majority class.  The following notebook showcases how Fiddler uses a class weighting paramater to deal with this problem. This notebook will onboard two identical models -- one without class imbalance weighting and one with class imbalance weighting -- to illustrate how drift signals in the minority class are easier to detect once properly amplified by Fiddler's unique class weighting approach.\n",
    "\n",
    "1. Connect to Fiddler\n",
    "2. Load a Data Sample\n",
    "3. Create Both Model Versions\n",
    "4. Publish Static Baselines\n",
    "5. Publish Production Events\n",
    "6. Compare the Two Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUZi_5s7wsGA"
   },
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pg-BdRJ4w3LM"
   },
   "outputs": [],
   "source": [
    "%pip install scikit-learn==1.6.1\n",
    "%pip install -q fiddler-client\n",
    "\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fiddler as fdl\n",
    "\n",
    "print(f\"Running Fiddler Python client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcP0yWfV1GoZ"
   },
   "source": [
    "# 1. Connect to Fiddler\n",
    "\n",
    "Before you can add information about your model with Fiddler, you'll need to connect using the Fiddler Python client.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**We need a couple pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your authorization token\n",
    "\n",
    "Your authorization token can be found by navigating to the **Credentials** tab on the **Settings** page of your Fiddler environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = ''  # Make sure to include the full URL (including https:// e.g. 'https://your_company_name.fiddler.ai').\n",
    "TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants for this example notebook, change as needed to create your own versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'quickstart_examples'\n",
    "MODEL_NAME = 'imbalance_cc_fraud'\n",
    "MODEL_NAME_WEIGHTED = 'imbalance_cc_fraud_weighted'\n",
    "STATIC_BASELINE_NAME = 'baseline_dataset'\n",
    "\n",
    "PATH_TO_SAMPLE_CSV = 'https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/data/v3/imbalance_data_sample.csv'\n",
    "PATH_TO_EVENTS_CSV = 'https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/data/v3/imbalance_production_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just run the following to connect to your Fiddler environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdl.init(url=URL, token=TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a Create New or Load Existing Project\n",
    "\n",
    "Once you connect, you can create a new project by specifying a unique project name in the fld.Project constructor and call the `create()` method. If the project already exists, it will load it for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = fdl.Project.get_or_create(name=PROJECT_NAME)\n",
    "\n",
    "print(f'Using project with id = {project.id} and name = {project.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load a Data Sample\n",
    "\n",
    "In this example, we'll be looking at a fraud detection use case.\n",
    "  \n",
    "In order to get insights into the model's performance, **Fiddler needs a small sample of data** to learn the schema of incoming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFVJcU8uCY7z"
   },
   "outputs": [],
   "source": [
    "\n",
    "sample_data_df = pd.read_csv(PATH_TO_SAMPLE_CSV)\n",
    "sample_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKXCbsxwvBHY"
   },
   "outputs": [],
   "source": [
    "sample_data_df['Class'].value_counts()\n",
    "\n",
    "print(\n",
    "    'Percentage of minority class: {}%'.format(\n",
    "        round(\n",
    "            sample_data_df['Class'].value_counts()[1] * 100 / sample_data_df.shape[0], 4\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IK3sL73_4FxO"
   },
   "source": [
    "# 3. Create Both Model Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMIVScsbvBHZ"
   },
   "source": [
    "Now, we will create two models:\n",
    "1. One model with class weight parameters\n",
    "2. One model without class weight parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRd0MBknvBHZ"
   },
   "source": [
    "Below, we first create a `ModelSpec` object which is common between the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec = fdl.ModelSpec(\n",
    "    inputs=set(sample_data_df.columns) - set(['Class', 'prediction_score', 'timestamp']),\n",
    "    outputs=['prediction_score'],\n",
    "    targets=['Class'],\n",
    "    metadata=['timestamp']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have columns in your ModelSpec which denote **prediction IDs or timestamps**, then Fiddler can use these to power its analytics accordingly.\n",
    "\n",
    "Let's call them out here and use them when configuring the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_column = '' # Optional: Specify the name of the ID column if you have one\n",
    "timestamp_column = 'timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the weighted and unweighted versions of the model task parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task = fdl.ModelTask.BINARY_CLASSIFICATION\n",
    "\n",
    "# Weighted Model Task Params\n",
    "task_params_weighted = fdl.ModelTaskParams(\n",
    "    target_class_order=[0, 1],\n",
    "    binary_classification_threshold=0.4,\n",
    "    class_weights=sklearn.utils.class_weight.compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(sample_data_df[\"Class\"]),\n",
    "        y=sample_data_df[\"Class\"],\n",
    "    ).tolist(),\n",
    ")\n",
    "\n",
    "# Unweighted Model Task Params aka default Model Task Params\n",
    "task_params_unweighted = fdl.ModelTaskParams(\n",
    "    target_class_order=[0, 1],\n",
    "    binary_classification_threshold=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we onboard (create) the two models to Fiddler -- the first without any class weights and the second with defined class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fdl.Model.from_data(\n",
    "    name=MODEL_NAME,\n",
    "    project_id=project.id,\n",
    "    source=sample_data_df,\n",
    "    spec=model_spec,\n",
    "    task=model_task,\n",
    "    task_params=task_params_unweighted,\n",
    "    event_ts_col=timestamp_column\n",
    ")\n",
    "\n",
    "model.create()\n",
    "print(f'New unweighted model created with id = {model.id} and name = {model.name}')\n",
    "\n",
    "weighted_model = fdl.Model.from_data(\n",
    "    name=MODEL_NAME_WEIGHTED,\n",
    "    project_id=project.id,\n",
    "    source=sample_data_df,\n",
    "    spec=model_spec,\n",
    "    task=model_task,\n",
    "    task_params=task_params_weighted,\n",
    "    event_ts_col=timestamp_column\n",
    ")\n",
    "\n",
    "weighted_model.create()\n",
    "print(f'New weighted model created with id = {weighted_model.id} and name = {weighted_model.name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Publish Static Baselines\n",
    "\n",
    "Since Fiddler already knows how to process data for your models, we can now add a **baseline dataset**.\n",
    "\n",
    "You can think of this as a static dataset which represents **\"golden data,\"** or the kind of data your model expects to receive.\n",
    "\n",
    "Then, once we start sending production data to Fiddler, you'll be able to see **drift scores** telling you whenever it starts to diverge from this static baseline.\n",
    "\n",
    "***\n",
    "\n",
    "Let's publish our **original data sample** as a pre-production dataset. After uploading, we will explicitly create a baseline for each model.\n",
    "\n",
    "\n",
    "*For more information on how to design your baseline dataset, [click here](https://docs.fiddler.ai/technical-reference/python-client-guides/publishing-production-data/creating-a-baseline-dataset).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Upload the pre-production data\n",
    "baseline_publish_job = model.publish(\n",
    "    source=sample_data_df,\n",
    "    environment=fdl.EnvType.PRE_PRODUCTION,\n",
    "    dataset_name=STATIC_BASELINE_NAME,\n",
    ")\n",
    "print(\n",
    "    f'Initiated pre-production environment data upload with Job ID = {baseline_publish_job.id}'\n",
    ")\n",
    "\n",
    "baseline_publish_job_weighted = weighted_model.publish(\n",
    "    source=sample_data_df,\n",
    "    environment=fdl.EnvType.PRE_PRODUCTION,\n",
    "    dataset_name=STATIC_BASELINE_NAME,\n",
    ")\n",
    "print(\n",
    "    f'Initiated pre-production environment data upload with Job ID = {baseline_publish_job_weighted.id}'\n",
    ")\n",
    "\n",
    "# Uncomment the lines below to wait for the jobs to finish, otherwise they will run in the background.\n",
    "# You can check the statuses on the Jobs page in the Fiddler UI or use the job IDs to query the job statuses via the API.\n",
    "# baseline_publish_job.wait()\n",
    "# baseline_publish_job_weighted.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Explicitly create a static baseline from the uploaded pre-production data\n",
    "dataset = fdl.Dataset.from_name(name=STATIC_BASELINE_NAME, model_id=model.id)\n",
    "\n",
    "dataset_id = dataset.id\n",
    "\n",
    "print(dataset_id)\n",
    "\n",
    "static_baseline = fdl.Baseline(\n",
    "    name=STATIC_BASELINE_NAME,\n",
    "    model_id=model.id,\n",
    "    environment=fdl.EnvType.PRE_PRODUCTION,\n",
    "    dataset_id=dataset_id,\n",
    "    type_=fdl.BaselineType.STATIC,\n",
    ")\n",
    "static_baseline.create()\n",
    "print(\n",
    "    f'Static baseline created with id = {static_baseline.id} and name = {static_baseline.name}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZNJ5NNm5vnA"
   },
   "source": [
    "# 5. Publish Production Events \n",
    "\n",
    "Publish the same events to both models with synthetic drift in the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dmA8PP7GTdJ"
   },
   "outputs": [],
   "source": [
    "production_data_df = pd.read_csv(PATH_TO_EVENTS_CSV)\n",
    "\n",
    "# Shift the timestamps of the production events to be as recent as today\n",
    "production_data_df['timestamp'] = production_data_df['timestamp'] + (\n",
    "    int(time.time() * 1000) - production_data_df['timestamp'].max()\n",
    ")\n",
    "production_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnFA3KGzvBHa"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Percentage of minority class: {}%\".format(\n",
    "        round(\n",
    "            production_data_df[\"Class\"].value_counts()[1] * 100 / production_data_df.shape[0], 4\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IuKuheyvBHa"
   },
   "source": [
    "We see that the percentage of minority class in production data is > 3 times than that of baseline data. This should create a big drift in the predictions.\n",
    "\n",
    "We will now publish the same production/event data for both of the models -- the one with class weights and the one without class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WM4ZUocQvBHa"
   },
   "outputs": [],
   "source": [
    "production_publish_job = model.publish(production_data_df)\n",
    "\n",
    "print(f'For Model: {model.name} - initiated production environment data upload with Job ID = {production_publish_job.id}')\n",
    "\n",
    "production_publish_job_weighted = weighted_model.publish(production_data_df)\n",
    "\n",
    "print(f'For Model: {weighted_model.name} - initiated production environment data upload with Job ID = {production_publish_job_weighted.id}')\n",
    "\n",
    "# Uncomment the lines below to wait for the jobs to finish, otherwise they will run in the background.\n",
    "# You can check the statuses on the Jobs page in the Fiddler UI or use the job IDs to query the job statuses via the API.\n",
    "# production_publish_job.wait()\n",
    "# production_publish_job_weighted.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vR6IR8YNHgG1"
   },
   "source": [
    "# 5. Compare the Two Models\n",
    "\n",
    "**You're all done!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oFePPOSvBHa"
   },
   "source": [
    "In the Fiddler UI, we can see the model without the class weights defined the output/prediction drift in the minority class is very hard to detect (`<=0.05`) because it is obsured by the overwhelming volume of events in the majority class.  If we declare class weights, then we see a higher drift which is a more accurate respresentation of the production data where the ratio of minority is class is 3x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7WCOUHvvBHa"
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/images/imabalance_data_1.png\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jdkj1eHgOTAO"
   },
   "source": [
    "**What's Next?**\n",
    "\n",
    "Try the [LLM Monitoring - Quick Start Notebook](https://docs.fiddler.ai/tutorials-and-quick-starts/llm-and-genai/simple-llm-monitoring)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Fiddler_Quick_Start_DIY.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
