{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8accbd85",
   "metadata": {},
   "source": [
    "# Fiddler LLM-as-a-Judge Quick Start Guide - Prompt Specs\n",
    "\n",
    "## Goal\n",
    "\n",
    "This guide demonstrates how to create a custom LLM-as-a-Judge eval; test it on a small amount of data; and then utilize it in the Fiddler platform.\n",
    "\n",
    "## About Fiddler\n",
    "\n",
    "Fiddler is the all-in-one AI Observability and Security platform for responsible AI. Monitoring and analytics capabilities provide a common language, centralized controls, and actionable insights to operationalize production ML models, GenAI, AI agents, and LLM applications with trust. An integral part of the platform, the Fiddler Trust Service provides quality and moderation controls for LLM applications. Powered by cost-effective, task-specific, and scalable Fiddler-developed trust models — including cloud and VPC deployments for secure environments — it delivers the fastest guardrails in the industry. Fortune 500 organizations utilize Fiddler to scale LLM and ML deployments, delivering high-performance AI, reducing costs, and ensuring responsible governance.\n",
    "\n",
    "---\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "You can start using Fiddler's LLM-as-a-Judge ***in minutes*** by following these quick steps.\n",
    "1. Load a Data Sample. \n",
    "1. Create and validate a Prompt Spec.\n",
    "1. Measure performance in the Evaluations Playground.\n",
    "1. Add field descriptions to improve accuracy.\n",
    "1. Create a corresponding enrichment in our Fiddler Project.\n",
    "1. Publish Production Events.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f610e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q fiddler-client # only needed if creating an enrichment in the Fiddler platform\n",
    "\n",
    "import json\n",
    "\n",
    "import fiddler as fdl\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d277c",
   "metadata": {},
   "source": [
    "## Setup Your Environment\n",
    "\n",
    "Please set `FIDDLER_TOKEN` and `FIDDLER_BASE_URL` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6cbbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIDDLER_TOKEN = \"\"\n",
    "FIDDLER_BASE_URL = \"https://my_company.fiddler.ai\"  # Make sure to include the full URL (including https:// e.g. 'https://your_company_name.fiddler.ai').\n",
    "\n",
    "PROMPT_SPEC_URL = f\"{FIDDLER_BASE_URL}/v3/llm-as-a-judge/prompt-spec\"\n",
    "\n",
    "FIDDLER_HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {FIDDLER_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "assert FIDDLER_TOKEN != \"\", \"Please set your Fiddler API token\"\n",
    "assert FIDDLER_BASE_URL != \"https://my_company.fiddler.ai\", (\n",
    "    \"Please set your Fiddler API URL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1abea62",
   "metadata": {},
   "source": [
    "## 1. Download and Sample Data\n",
    "\n",
    "We'll use [AG News set](https://huggingface.co/datasets/fancyzhx/ag_news). It has the text of a news summary and a categorical `label` column for corresponding topic. We'll use Fiddler's LLM-as-a-Judge solution to predict this label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38a3505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>original_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>Late rally sees Wall Street end week on a posi...</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>Rejuvenated Real out to start scoring goals It...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>Service-Sector Revenues Rise in Q2 Revenues in...</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>One assist, goal for hometown star STOCKHOLM, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Some People Not Eligible to Get in on Google I...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label original_topic\n",
       "1514  Late rally sees Wall Street end week on a posi...      2       Business\n",
       "2917  Rejuvenated Real out to start scoring goals It...      1         Sports\n",
       "1670  Service-Sector Revenues Rise in Q2 Revenues in...      2       Business\n",
       "2375  One assist, goal for hometown star STOCKHOLM, ...      1         Sports\n",
       "23    Some People Not Eligible to Get in on Google I...      3       Sci/Tech"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ag_news = pd.read_parquet(\n",
    "    \"hf://datasets/fancyzhx/ag_news/data/test-00000-of-00001.parquet\"\n",
    ").sample(100, random_state=42)\n",
    "df_ag_news[\"original_topic\"] = df_ag_news[\"label\"].map(\n",
    "    {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n",
    ")\n",
    "\n",
    "df_ag_news_eval_sample = df_ag_news.sample(20, random_state=42)\n",
    "df_ag_news_eval_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5759df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_topic\n",
       "Sports      8\n",
       "Business    6\n",
       "Sci/Tech    3\n",
       "World       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ag_news_eval_sample[\"original_topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c134a",
   "metadata": {},
   "source": [
    "## 2. Make a Simple Prompt Spec\n",
    "\n",
    "The Prompt Spec is a a simple definition of the input and output fields for the LLM-as-a-Judge task. Under the hood we will turn this simple specification into an appropriate prompt.\n",
    "\n",
    "For our Prompt Spec we define a single input field and two output fields:\n",
    "1. Input `news_title`: note that this is a more descriptive name than original column name `text`. Descriptive name can improve model performance.\n",
    "1. Output `topic`: we expect this will match the given `label`\n",
    "1. Output `reasoning`: this is a free-text field in which the model will include why it chose the `topic`. Including this field will cause longer execution times, but will help us during prompt-tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e5f9a",
   "metadata": {},
   "source": [
    "### 2.1 Define and Validate the Prompt Spec \n",
    "\n",
    "Here we use the `validate` endpoint to check that our spec is valid. You could skip directly to `predict` in Section 2.2, as that action performs a validation check as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "677c6ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"input_fields\": {\n",
      "    \"news_summary\": {\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"output_fields\": {\n",
      "    \"topic\": {\n",
      "      \"type\": \"string\",\n",
      "      \"choices\": [\n",
      "        \"Business\",\n",
      "        \"Sports\",\n",
      "        \"Sci/Tech\",\n",
      "        \"World\"\n",
      "      ]\n",
      "    },\n",
      "    \"reasoning\": {\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt_spec_basic = {\n",
    "    \"input_fields\": {\"news_summary\": {\"type\": \"string\"}},\n",
    "    \"output_fields\": {\n",
    "        \"topic\": {\n",
    "            \"type\": \"string\",\n",
    "            \"choices\": df_ag_news_eval_sample[\"original_topic\"].unique().tolist(),\n",
    "        },\n",
    "        \"reasoning\": {\"type\": \"string\"},\n",
    "    },\n",
    "}\n",
    "print(json.dumps(prompt_spec_basic, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d306b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"valid\": true,\n",
      "  \"message\": \"Valid prompt_spec\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "validate_response = requests.post(\n",
    "    f\"{PROMPT_SPEC_URL}/validate\",\n",
    "    headers=FIDDLER_HEADERS,\n",
    "    json={\"prompt_spec\": prompt_spec_basic},\n",
    ")\n",
    "validate_response.raise_for_status()\n",
    "print(\"Status Code:\", validate_response.status_code)\n",
    "print(json.dumps(validate_response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42ca0c",
   "metadata": {},
   "source": [
    "### 2.2 Test with Ad-Hoc Data\n",
    "\n",
    "We send in one request to the `predict` endpoint. In the next section we'll send in our entire dataframe. \n",
    "\n",
    "Note: This could take 10-15 minutes to run the first time, while the backend spins up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279eb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(prompt_spec, input_data):\n",
    "    predict_response = requests.post(\n",
    "        f\"{PROMPT_SPEC_URL}/predict\",\n",
    "        headers=FIDDLER_HEADERS,\n",
    "        json={\"prompt_spec\": prompt_spec, \"input_data\": input_data},\n",
    "    )\n",
    "    if predict_response.status_code != 200:\n",
    "        print(f\"Error ({predict_response.status_code}): {predict_response.text}\")\n",
    "        return {\"topic\": None, \"reasoning\": None}\n",
    "    return predict_response.json()[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dc80698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"topic\": \"Sports\",\n",
      "  \"reasoning\": \"The topic is Sports because the news summary mentions Wimbledon, which is a well-known tennis tournament.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    json.dumps(\n",
    "        get_prediction(\n",
    "            prompt_spec_basic, {\"news_summary\": \"Wimbledon 2025 is under way!\"}\n",
    "        ),\n",
    "        indent=2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b05b7",
   "metadata": {},
   "source": [
    "### 2.3 Test with a DataFrame\n",
    "\n",
    "Now that you're familiar with the `predict` action, let's use it to evaluate our dataframe. This will take about 30 seconds to run.\n",
    "\n",
    "Note: This endpoint is meant for evaluation purposes only and should not be used on production-loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57031624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ag_news_eval_sample[[\"topic\", \"reasoning\"]] = df_ag_news_eval_sample.apply(\n",
    "    lambda row: get_prediction(prompt_spec_basic, {\"news_summary\": row[\"text\"]}),\n",
    "    axis=1,\n",
    "    result_type=\"expand\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69aa2d4",
   "metadata": {},
   "source": [
    "### 2.4 Inspect Results\n",
    "\n",
    "We see that all `Sci/Tech` articles were mis-classified as `Business`. The `reasoning` field helps identify trends. We'll use this to update our prompt spec in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff78f6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "original_topic  topic   \n",
       "Business        Business    6\n",
       "Sports          Sports      6\n",
       "Sci/Tech        Business    3\n",
       "World           World       3\n",
       "Sports          World       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (\n",
    "    df_ag_news_eval_sample[\"original_topic\"] == df_ag_news_eval_sample[\"topic\"]\n",
    ").mean()\n",
    "print(f\"Accuracy: {accuracy:.0%}\")\n",
    "\n",
    "df_ag_news_eval_sample.value_counts(subset=[\"original_topic\", \"topic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe3245c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topic is Business because the news summary is about a company's Initial Public Offering (IPO), which is a financial event.\n",
      "The topic is Business because the news summary is about companies and their decisions regarding a product (Internet Explorer) and a new browser (Firefox).\n",
      "The topic is Business because the news summary is about a business process outsourcing (BPO) global strategic-alliance program and customer relationship management (CRM) marketplaces.\n"
     ]
    }
   ],
   "source": [
    "for r in df_ag_news_eval_sample[df_ag_news_eval_sample[\"original_topic\"] == \"Sci/Tech\"][\n",
    "    \"reasoning\"\n",
    "]:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4664b50d",
   "metadata": {},
   "source": [
    "## 3. Make a Richer Prompt Spec\n",
    "\n",
    "In Section 2 we noted that descriptive field names can help improve model performance. You can also add a task instruction and field descriptions. We will add a label description to help with classifying `Sci/Tech` articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355d5d8c",
   "metadata": {},
   "source": [
    "### 3.1 Update the spec with a label \"hint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c78c6b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_spec_rich = {\n",
    "    \"instruction\": \"Determine the topic of the given news summary.\",\n",
    "    \"input_fields\": {\n",
    "        \"news_summary\": {\n",
    "            \"type\": \"string\",\n",
    "        }\n",
    "    },\n",
    "    \"output_fields\": {\n",
    "        \"topic\": {\n",
    "            \"type\": \"string\",\n",
    "            \"choices\": df_ag_news_eval_sample[\"original_topic\"].unique().tolist(),\n",
    "            \"description\": \"\"\"Use topic 'Sci/Tech' if the news summary is about a company or business in the tech industry, or if the news summary is about a scientific discovery or research.\n",
    "            Use topic 'Sports' if the news summary is about a sports event or athlete.\n",
    "            Use topic 'Business' if the news summary is about a company or industry outside of science, technology, or sports.\n",
    "            Use topic 'World' if the news summary is about a global event or issue.\n",
    "            \"\"\",\n",
    "        },\n",
    "        \"reasoning\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The reasoning behind the predicted topic.\",\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0a45277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"topic\": \"Sci/Tech\",\n",
      "  \"reasoning\": \"The news summary is about a company (Google) and its IPO, which is a business event in the tech industry, so the topic is 'Sci/Tech'.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    json.dumps(\n",
    "        get_prediction(\n",
    "            prompt_spec_rich, {\"news_summary\": df_ag_news_eval_sample.loc[23, \"text\"]}\n",
    "        ),\n",
    "        indent=2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ab2b7",
   "metadata": {},
   "source": [
    "### 3.2 Re-evaluate with the new Prompt\n",
    "\n",
    "We see that accuracy has improved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28ebe94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ag_news_eval_sample[[\"topic\", \"reasoning\"]] = df_ag_news_eval_sample.apply(\n",
    "    lambda row: get_prediction(prompt_spec_rich, {\"news_summary\": row[\"text\"]}),\n",
    "    axis=1,\n",
    "    result_type=\"expand\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "228e5cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "original_topic  topic   \n",
       "Sports          Sports      7\n",
       "Business        Business    6\n",
       "World           World       3\n",
       "Sci/Tech        Sci/Tech    2\n",
       "                Business    1\n",
       "Sports          World       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (\n",
    "    df_ag_news_eval_sample[\"original_topic\"] == df_ag_news_eval_sample[\"topic\"]\n",
    ").mean()\n",
    "print(f\"Accuracy: {accuracy:.0%}\")\n",
    "\n",
    "df_ag_news_eval_sample.value_counts(subset=[\"original_topic\", \"topic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dbb994",
   "metadata": {},
   "source": [
    "## 4. Create an Enrichment\n",
    "\n",
    "Create an Enrichment using our rich prompt spec. \n",
    "\n",
    "Note: you can go back and remove the `reasoning` field if you do not want to include it in production monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec78ef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250729T21:03:41.142Z     INFO| attached stderr handler to logger: auto_attach_log_handler=True, and root logger not configured \n",
      "250729T21:03:41.144Z     INFO| http: https://jen2.dev.fiddler.ai/v3/server-info GET -- emit req (0 B, timeout: (5, 15)) \n",
      "250729T21:03:41.855Z     INFO| http: https://jen2.dev.fiddler.ai/v3/server-info GET -- resp code: 200, took 0.711 s, resp/req body size: (923 B, 0 B) \n",
      "250729T21:03:41.857Z     INFO| http: https://jen2.dev.fiddler.ai/v3/version-compatibility GET -- emit req (0 B, timeout: (5, 15)) \n",
      "250729T21:03:41.917Z     INFO| http: https://jen2.dev.fiddler.ai/v3/version-compatibility GET -- resp code: 200, took 0.059 s, resp/req body size: (2 B, 0 B) \n"
     ]
    }
   ],
   "source": [
    "fdl.init(url=FIDDLER_BASE_URL, token=FIDDLER_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f67c4e3",
   "metadata": {},
   "source": [
    "### 4.1 Create a Fiddler Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd31a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"quickstart_examples_2\"  # If the project already exists, the notebook will create the model under the existing project.\n",
    "MODEL_NAME = \"fiddler_news_classifier_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e96b9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250729T21:03:43.605Z     INFO| http: https://jen2.dev.fiddler.ai/v3/projects GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250729T21:03:43.691Z     INFO| http: https://jen2.dev.fiddler.ai/v3/projects GET -- resp code: 200, took 0.085 s, resp/req body size: (160 B, 0 B) \n",
      "250729T21:03:43.691Z     INFO| Project not found, creating a new one - `quickstart_examples_2` \n",
      "250729T21:03:43.692Z     INFO| http: https://jen2.dev.fiddler.ai/v3/projects POST -- emit req (33 B, timeout: (5, 100)) \n",
      "250729T21:03:43.945Z     INFO| http: https://jen2.dev.fiddler.ai/v3/projects POST -- resp code: 200, took 0.253 s, resp/req body size: (335 B, 33 B) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project with id = 16fc21bf-705b-438b-9cf3-7d0e8ecb8086 and name = quickstart_examples_2\n"
     ]
    }
   ],
   "source": [
    "project = fdl.Project.get_or_create(name=PROJECT_NAME)\n",
    "\n",
    "print(f\"Using project with id = {project.id} and name = {project.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29afb4ed",
   "metadata": {},
   "source": [
    "### 4.2 Manipulate DataFrame\n",
    "\n",
    "Recall we used `news_summary` in our prompt. Let's make our dataframe match this and add some metadata.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a27e9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_summary</th>\n",
       "      <th>label</th>\n",
       "      <th>original_topic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7094</th>\n",
       "      <td>Fan v Fan: Manchester City-Tottenham Hotspur T...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sports</td>\n",
       "      <td>7094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>Paris Tourists Search for Key to 'Da Vinci Cod...</td>\n",
       "      <td>0</td>\n",
       "      <td>World</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>Net firms: Don't tax VoIP The Spanish-American...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>Dependent species risk extinction The global e...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>EDS Is Charter Member of Siebel BPO Alliance (...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           news_summary  label original_topic  \\\n",
       "7094  Fan v Fan: Manchester City-Tottenham Hotspur T...      1         Sports   \n",
       "1017  Paris Tourists Search for Key to 'Da Vinci Cod...      0          World   \n",
       "2850  Net firms: Don't tax VoIP The Spanish-American...      3       Sci/Tech   \n",
       "1452  Dependent species risk extinction The global e...      3       Sci/Tech   \n",
       "457   EDS Is Charter Member of Siebel BPO Alliance (...      3       Sci/Tech   \n",
       "\n",
       "        id  \n",
       "7094  7094  \n",
       "1017  1017  \n",
       "2850  2850  \n",
       "1452  1452  \n",
       "457    457  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform_df = df_ag_news.rename(columns={\"text\": \"news_summary\"})\n",
    "platform_df[\"id\"] = platform_df.index\n",
    "platform_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3c245",
   "metadata": {},
   "source": [
    "### 4.3 Enable Fiddler LLM Enrichments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "894d9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiddler_llm_enrichments = [\n",
    "    fdl.Enrichment(\n",
    "        name=\"news_topic\",\n",
    "        enrichment=\"llm_as_a_judge\",\n",
    "        columns=[\"news_summary\"],\n",
    "        config={\"prompt_spec\": prompt_spec_rich},\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f016ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250729T21:04:16.114Z     INFO| http: https://jen2.dev.fiddler.ai/v3/files/upload POST -- emit req (0.022 MB, timeout: (5, 100)) \n",
      "250729T21:04:16.406Z     INFO| http: https://jen2.dev.fiddler.ai/v3/files/upload POST -- resp code: 200, took 0.291 s, resp/req body size: (525 B, 0.022 MB) \n",
      "250729T21:04:16.407Z     INFO| http: https://jen2.dev.fiddler.ai/v3/model-factory POST -- emit req (1185 B, timeout: (5, 100)) \n",
      "250729T21:04:17.263Z     INFO| http: https://jen2.dev.fiddler.ai/v3/model-factory POST -- resp code: 200, took 0.855 s, resp/req body size: (2113 B, 1185 B) \n"
     ]
    }
   ],
   "source": [
    "model_spec = fdl.ModelSpec(\n",
    "    inputs=[\"news_summary\"],\n",
    "    metadata=[\"id\", \"original_topic\"],\n",
    "    custom_features=fiddler_llm_enrichments,\n",
    ")\n",
    "llm_application = fdl.Model.from_data(\n",
    "    source=platform_df,\n",
    "    name=MODEL_NAME,\n",
    "    project_id=project.id,\n",
    "    spec=model_spec,\n",
    "    task=fdl.ModelTask.LLM,\n",
    "    max_cardinality=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fbf96bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250729T21:04:18.979Z     INFO| http: https://jen2.dev.fiddler.ai/v3/models POST -- emit req (2447 B, timeout: (5, 100)) \n",
      "250729T21:04:21.224Z     INFO| http: https://jen2.dev.fiddler.ai/v3/models POST -- resp code: 200, took 2.244 s, resp/req body size: (3467 B, 2447 B) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model created with id = 8d553634-1ac8-491c-96b8-99791c4bb785 and name = fiddler_news_classifier_2\n"
     ]
    }
   ],
   "source": [
    "llm_application.create()\n",
    "print(\n",
    "    f\"New model created with id = {llm_application.id} and name = {llm_application.name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912d16a4",
   "metadata": {},
   "source": [
    "### 4.4 Publish Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e14f9371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250729T21:04:23.680Z     INFO| Model[fiddler_news_classifier_2/v1] - Publishing events \n",
      "250729T21:04:23.684Z     INFO| http: https://jen2.dev.fiddler.ai/v3/files/upload POST -- emit req (0.022 MB, timeout: (5, 100)) \n",
      "250729T21:04:23.873Z     INFO| http: https://jen2.dev.fiddler.ai/v3/files/upload POST -- resp code: 200, took 0.189 s, resp/req body size: (532 B, 0.022 MB) \n",
      "250729T21:04:23.874Z     INFO| http: https://jen2.dev.fiddler.ai/v3/events POST -- emit req (175 B, timeout: (5, 100)) \n",
      "250729T21:04:24.232Z     INFO| http: https://jen2.dev.fiddler.ai/v3/events POST -- resp code: 202, took 0.357 s, resp/req body size: (163 B, 175 B) \n",
      "250729T21:04:24.234Z     INFO| http: https://jen2.dev.fiddler.ai/v3/jobs/0ba0e43e-736e-4d2e-a9f9-079b24f0caa5 GET -- emit req (0 B, timeout: (5, 100)) \n",
      "250729T21:04:24.339Z     INFO| http: https://jen2.dev.fiddler.ai/v3/jobs/0ba0e43e-736e-4d2e-a9f9-079b24f0caa5 GET -- resp code: 200, took 0.105 s, resp/req body size: (897 B, 0 B) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiated production data upload with Job ID = 0ba0e43e-736e-4d2e-a9f9-079b24f0caa5\n"
     ]
    }
   ],
   "source": [
    "production_publish_job = llm_application.publish(platform_df)\n",
    "\n",
    "print(f\"Initiated production data upload with Job ID = {production_publish_job.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3877e19",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Explore the Fiddler UI to see your model and enrichments\n",
    "- Try different prompt specs with your own data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-base-py3-11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
