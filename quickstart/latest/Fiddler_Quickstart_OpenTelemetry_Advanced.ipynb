{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiddler OpenTelemetry Integration - Advanced Guide\n",
    "\n",
    "## Goal\n",
    "\n",
    "This comprehensive guide demonstrates how to integrate **custom AI agents** with **Fiddler** using **OpenTelemetry** for full observability and monitoring. You will learn advanced patterns for instrumentation, attribute mapping, and production-ready configurations. ü§ñ\n",
    "\n",
    "## About OpenTelemetry Integration\n",
    "\n",
    "OpenTelemetry provides a vendor-neutral way to collect telemetry data from your applications. This notebook shows you how to:\n",
    "\n",
    "- Set up OpenTelemetry tracing with Fiddler's OTLP endpoint\n",
    "- Map agent attributes to Fiddler's semantic conventions\n",
    "- Instrument LLM calls, tool execution, and agent chains\n",
    "- Track conversations and sessions with custom attributes\n",
    "- Implement production-ready configurations\n",
    "- Debug and troubleshoot trace collection\n",
    "\n",
    "## About Fiddler\n",
    "\n",
    "Fiddler is the all-in-one AI Observability and Security platform for responsible AI. Monitoring and analytics capabilities provide a common language, centralized controls, and actionable insights to operationalize production ML models, GenAI, AI agents, and LLM applications with trust.\n",
    "\n",
    "## When to Use OpenTelemetry Integration\n",
    "\n",
    "Use this approach when:\n",
    "\n",
    "- **Multi-framework environments**: You use multiple agentic frameworks and need unified observability\n",
    "- **Custom frameworks**: Your agent framework doesn't have a dedicated Fiddler SDK\n",
    "- **Advanced control**: You need fine-grained control over instrumentation\n",
    "\n",
    "**When to Use SDKs Instead:**\n",
    "\n",
    "- **LangGraph/LangChain**: Use [Fiddler LangGraph SDK](https://docs.fiddler.ai/tutorials/llm-monitoring/langgraph-sdk-quick-start) for auto-instrumentation\n",
    "- **Strands Agents**: Use [Fiddler Strands SDK](https://docs.fiddler.ai/tutorials/llm-monitoring/strands-agent-quick-start) for native integration\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Summary\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "1. Install OpenTelemetry packages\n",
    "2. Set up environment variables for Fiddler OTLP endpoint\n",
    "3. Configure OpenTelemetry with TracerProvider and OTLP exporter\n",
    "4. Build a comprehensive travel agent with hotel and flight booking tools\n",
    "5. Implement custom user-defined attributes\n",
    "6. Track conversations across multi-turn interactions\n",
    "7. Configure production settings (sampling, batching, compression)\n",
    "8. Verify traces in Fiddler dashboard\n",
    "\n",
    "**Time to complete:** ~25-30 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Fiddler account with Application UUID and Access Token\n",
    "- OpenAI API key (or other LLM provider)\n",
    "- Python 3.10+\n",
    "- OpenTelemetry packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages\n",
    "\n",
    "First, install OpenTelemetry and LLM provider packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenTelemetry packages\n",
    "%pip install -q opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp-proto-http openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Environment Variables\n",
    "\n",
    "Set up your Fiddler credentials and LLM API key.\n",
    "\n",
    "**Where to find these values:**\n",
    "\n",
    "- **FIDDLER_URL**: Your Fiddler instance URL (e.g., `https://acme.fiddler.ai`)\n",
    "- **APPLICATION_UUID**: From your Fiddler GenAI Apps ‚Üí Application Details\n",
    "- **ACCESS_TOKEN**: From Fiddler Settings ‚Üí Credentials\n",
    "- **OPENAI_API_KEY**: Your OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ‚ö†Ô∏è Replace these with your actual credentials\n",
    "FIDDLER_URL = 'https://your-instance.fiddler.ai'\n",
    "APPLICATION_UUID = 'your-application-uuid-here'  # Must be valid UUID4\n",
    "ACCESS_TOKEN = 'your-access-token-here'\n",
    "OPENAI_API_KEY = 'your-openai-api-key-here'\n",
    "\n",
    "# Set environment variables for OpenTelemetry\n",
    "os.environ['OTEL_EXPORTER_OTLP_ENDPOINT'] = FIDDLER_URL\n",
    "os.environ['OTEL_EXPORTER_OTLP_HEADERS'] = (\n",
    "    f'authorization=Bearer {ACCESS_TOKEN},'\n",
    "    f'fiddler-application-id={APPLICATION_UUID}'\n",
    ")\n",
    "os.environ['OTEL_RESOURCE_ATTRIBUTES'] = f'application.id={APPLICATION_UUID}'\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "print('‚úÖ Environment variables configured')\n",
    "print(f'   Fiddler URL: {FIDDLER_URL}')\n",
    "print(f'   Application ID: {APPLICATION_UUID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Part 1: Basic OpenTelemetry Configuration\n",
    "\n",
    "Set up OpenTelemetry with:\n",
    "\n",
    "- **TracerProvider**: Manages trace generation\n",
    "- **OTLPSpanExporter**: Exports spans to Fiddler\n",
    "- **BatchSpanProcessor**: Batches spans for efficient transmission\n",
    "- **Console Exporter**: For local debugging (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "\n",
    "# Initialize tracer provider\n",
    "trace.set_tracer_provider(TracerProvider())\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "# Configure OTLP exporter for Fiddler\n",
    "otlp_endpoint = os.getenv('OTEL_EXPORTER_OTLP_ENDPOINT') + '/v1/traces'\n",
    "otlp_exporter = OTLPSpanExporter(endpoint=otlp_endpoint)\n",
    "otlp_processor = BatchSpanProcessor(otlp_exporter)\n",
    "trace.get_tracer_provider().add_span_processor(otlp_processor)\n",
    "\n",
    "# Optional: Add console exporter for local debugging\n",
    "console_exporter = ConsoleSpanExporter()\n",
    "console_processor = BatchSpanProcessor(console_exporter)\n",
    "trace.get_tracer_provider().add_span_processor(console_processor)\n",
    "\n",
    "print('‚úÖ OpenTelemetry configured successfully')\n",
    "print(f'   OTLP Endpoint: {otlp_endpoint}')\n",
    "print('   Console Exporter: Enabled (for debugging)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Part 2: Comprehensive Travel Agent Example\n",
    "\n",
    "This section implements a production-ready travel agent with:\n",
    "\n",
    "- Hotel booking tool\n",
    "- Flight booking tool\n",
    "- LLM orchestration\n",
    "- Proper span hierarchy (chain ‚Üí LLM ‚Üí tools)\n",
    "- Complete Fiddler attribute mapping\n",
    "\n",
    "### Define Agent Constants and System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_NAME = \"travel_agent\"\n",
    "AGENT_ID = \"travel_agent_v1\"\n",
    "\n",
    "TRAVEL_AGENT_SYSTEM_PROMPT = \"\"\"\n",
    "You are a professional travel agent capable of booking hotels and flights.\n",
    "You have access to the following tools: book_hotel_tool, book_flight_tool.\n",
    "\n",
    "When a user asks to book travel, you should:\n",
    "1. Search for available hotels if they need accommodation\n",
    "2. Book the hotel if they approve\n",
    "3. Book flights if they need transportation\n",
    "4. Provide confirmation details for all bookings\n",
    "\n",
    "Be helpful, professional, and ensure you gather all necessary information\n",
    "before making any bookings.\n",
    "\"\"\"\n",
    "\n",
    "print('‚úÖ Agent configuration defined')\n",
    "print(f'   Agent Name: {AGENT_NAME}')\n",
    "print(f'   Agent ID: {AGENT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Travel Agent Tools\n",
    "\n",
    "Each tool creates a properly instrumented span with Fiddler-required attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def _book_hotel(city: str, date: str) -> dict:\n",
    "    \"\"\"Simulate hotel booking API.\"\"\"\n",
    "    return {\n",
    "        \"status\": \"confirmed\",\n",
    "        \"hotel_name\": f\"Grand Hotel {city}\",\n",
    "        \"city\": city,\n",
    "        \"date\": date,\n",
    "        \"confirmation\": f\"HTL-{city[:3].upper()}-{date.replace('-', '')}\",\n",
    "        \"price\": 250\n",
    "    }\n",
    "\n",
    "def book_hotel_tool(city: str, date: str):\n",
    "    \"\"\"\n",
    "    Book a hotel in the specified city.\n",
    "    Creates an instrumented tool span with Fiddler attributes.\n",
    "    \"\"\"\n",
    "    with tracer.start_as_current_span(\"book_hotel_tool\") as span:\n",
    "        # Required Fiddler attributes\n",
    "        span.set_attribute(\"fiddler.span.type\", \"tool\")\n",
    "        span.set_attribute(\"gen_ai.agent.name\", AGENT_NAME)\n",
    "        span.set_attribute(\"gen_ai.agent.id\", AGENT_ID)\n",
    "\n",
    "        # Tool-specific attributes\n",
    "        span.set_attribute(\"gen_ai.tool.name\", \"book_hotel_tool\")\n",
    "        tool_input = {\"city\": city, \"date\": date}\n",
    "        span.set_attribute(\"gen_ai.tool.input\", json.dumps(tool_input))\n",
    "\n",
    "        # Execute tool\n",
    "        result = _book_hotel(city, date)\n",
    "        span.set_attribute(\"gen_ai.tool.output\", json.dumps(result))\n",
    "\n",
    "        return result\n",
    "\n",
    "def _book_flight(source: str, destination: str, date: str) -> dict:\n",
    "    \"\"\"Simulate flight booking API.\"\"\"\n",
    "    return {\n",
    "        \"status\": \"confirmed\",\n",
    "        \"flight_number\": f\"FL{source[:2].upper()}{destination[:2].upper()}456\",\n",
    "        \"source\": source,\n",
    "        \"destination\": destination,\n",
    "        \"date\": date,\n",
    "        \"departure\": \"10:00 AM\",\n",
    "        \"arrival\": \"2:30 PM\",\n",
    "        \"price\": 450\n",
    "    }\n",
    "\n",
    "def book_flight_tool(source: str, destination: str, date: str):\n",
    "    \"\"\"\n",
    "    Book a flight between two cities.\n",
    "    Creates an instrumented tool span with Fiddler attributes.\n",
    "    \"\"\"\n",
    "    with tracer.start_as_current_span(\"book_flight_tool\") as span:\n",
    "        # Required Fiddler attributes\n",
    "        span.set_attribute(\"fiddler.span.type\", \"tool\")\n",
    "        span.set_attribute(\"gen_ai.agent.name\", AGENT_NAME)\n",
    "        span.set_attribute(\"gen_ai.agent.id\", AGENT_ID)\n",
    "\n",
    "        # Tool-specific attributes\n",
    "        span.set_attribute(\"gen_ai.tool.name\", \"book_flight_tool\")\n",
    "        tool_input = {\n",
    "            \"source\": source,\n",
    "            \"destination\": destination,\n",
    "            \"date\": date\n",
    "        }\n",
    "        span.set_attribute(\"gen_ai.tool.input\", json.dumps(tool_input))\n",
    "\n",
    "        # Execute tool\n",
    "        result = _book_flight(source, destination, date)\n",
    "        span.set_attribute(\"gen_ai.tool.output\", json.dumps(result))\n",
    "\n",
    "        return result\n",
    "\n",
    "print('‚úÖ Travel agent tools defined')\n",
    "print('   - book_hotel_tool')\n",
    "print('   - book_flight_tool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Main Travel Agent Function\n",
    "\n",
    "This function orchestrates LLM calls and tool execution with proper instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def travel_agent(user_request: str):\n",
    "    \"\"\"\n",
    "    Main travel agent function that processes user requests.\n",
    "    Creates a chain span with nested LLM and tool spans.\n",
    "    \"\"\"\n",
    "    with tracer.start_as_current_span(\"travel_agent_chain\") as root_span:\n",
    "        # Root chain span\n",
    "        root_span.set_attribute(\"fiddler.span.type\", \"chain\")\n",
    "        root_span.set_attribute(\"gen_ai.agent.name\", AGENT_NAME)\n",
    "        root_span.set_attribute(\"gen_ai.agent.id\", AGENT_ID)\n",
    "\n",
    "        # First LLM call: Understand request and plan actions\n",
    "        with tracer.start_as_current_span(\"llm_planning\") as llm_span:\n",
    "            # Required Fiddler attributes\n",
    "            llm_span.set_attribute(\"fiddler.span.type\", \"llm\")\n",
    "            llm_span.set_attribute(\"gen_ai.agent.name\", AGENT_NAME)\n",
    "            llm_span.set_attribute(\"gen_ai.agent.id\", AGENT_ID)\n",
    "\n",
    "            # LLM-specific attributes\n",
    "            model = \"gpt-4o-mini\"\n",
    "            llm_span.set_attribute(\"gen_ai.request.model\", model)\n",
    "            llm_span.set_attribute(\"gen_ai.system\", \"openai\")\n",
    "            llm_span.set_attribute(\"gen_ai.llm.input.system\", TRAVEL_AGENT_SYSTEM_PROMPT)\n",
    "            llm_span.set_attribute(\"gen_ai.llm.input.user\", user_request)\n",
    "            \n",
    "            # Message history\n",
    "            llm_span.set_attribute(\"gen_ai.input.messages\", json.dumps([\n",
    "                {\"role\": \"system\", \"content\": TRAVEL_AGENT_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": user_request}\n",
    "            ]))\n",
    "\n",
    "            # Set LLM context\n",
    "            llm_span.set_attribute(\"gen_ai.llm.context\", \"Quick start opentelemetry example context\")\n",
    "\n",
    "            # Define tool definitions (reusable)\n",
    "            tool_definitions = [\n",
    "                {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": \"book_hotel_tool\",\n",
    "                        \"description\": \"Book a hotel in a city for a specific date\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"city\": {\"type\": \"string\"},\n",
    "                                \"date\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"required\": [\"city\", \"date\"]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": \"book_flight_tool\",\n",
    "                        \"description\": \"Book a flight between two cities\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"source\": {\"type\": \"string\"},\n",
    "                                \"destination\": {\"type\": \"string\"},\n",
    "                                \"date\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"required\": [\"source\", \"destination\", \"date\"]\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            # NEW (v1.1.0+): Capture tool definitions on span\n",
    "            llm_span.set_attribute(\"gen_ai.tool.definitions\", json.dumps(tool_definitions))\n",
    "\n",
    "            # Call OpenAI with tool definitions\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": TRAVEL_AGENT_SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": user_request}\n",
    "                ],\n",
    "                tools=tool_definitions\n",
    "            )\n",
    "\n",
    "            # Set token usage\n",
    "            llm_span.set_attribute(\"gen_ai.usage.input_tokens\", response.usage.prompt_tokens)\n",
    "            llm_span.set_attribute(\"gen_ai.usage.output_tokens\", response.usage.completion_tokens)\n",
    "            llm_span.set_attribute(\"gen_ai.usage.total_tokens\", response.usage.total_tokens)\n",
    "\n",
    "            # Process tool calls\n",
    "            tool_results = []\n",
    "            message = response.choices[0].message\n",
    "\n",
    "            if message.tool_calls:\n",
    "                # Build tool_call parts for complex OpenTelemetry format\n",
    "                tool_call_parts = []\n",
    "                for tool_call in message.tool_calls:\n",
    "                    tool_name = tool_call.function.name\n",
    "                    tool_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                    # Execute the tool\n",
    "                    if tool_name == \"book_hotel_tool\":\n",
    "                        result = book_hotel_tool(**tool_args)\n",
    "                        tool_results.append({\"tool\": \"hotel\", \"result\": result})\n",
    "                    elif tool_name == \"book_flight_tool\":\n",
    "                        result = book_flight_tool(**tool_args)\n",
    "                        tool_results.append({\"tool\": \"flight\", \"result\": result})\n",
    "                    \n",
    "                    # Add tool call part (complex format with type, name, id, arguments)\n",
    "                    tool_call_parts.append({\n",
    "                        \"type\": \"tool_call\",\n",
    "                        \"name\": tool_name,\n",
    "                        \"id\": tool_call.id,\n",
    "                        \"arguments\": tool_args\n",
    "                    })\n",
    "\n",
    "                llm_span.set_attribute(\n",
    "                    \"gen_ai.llm.output\",\n",
    "                    f\"Executed {len(tool_results)} tool(s): {[t['tool'] for t in tool_results]}\"\n",
    "                )\n",
    "                \n",
    "                # Output message history (complex format with tool calls)\n",
    "                llm_span.set_attribute(\"gen_ai.output.messages\", json.dumps([{\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"parts\": tool_call_parts,\n",
    "                    \"finish_reason\": response.choices[0].finish_reason\n",
    "                }]))\n",
    "            else:\n",
    "                llm_span.set_attribute(\"gen_ai.llm.output\", message.content or \"No response\")\n",
    "                \n",
    "                # Output message history (simple format)\n",
    "                llm_span.set_attribute(\"gen_ai.output.messages\", json.dumps([\n",
    "                    {\"role\": \"assistant\", \"content\": message.content or \"\"}\n",
    "                ]))\n",
    "\n",
    "        # Second LLM call: Generate user-friendly response\n",
    "        if tool_results:\n",
    "            with tracer.start_as_current_span(\"llm_response_generation\") as response_span:\n",
    "                response_span.set_attribute(\"fiddler.span.type\", \"llm\")\n",
    "                response_span.set_attribute(\"gen_ai.agent.name\", AGENT_NAME)\n",
    "                response_span.set_attribute(\"gen_ai.agent.id\", AGENT_ID)\n",
    "                response_span.set_attribute(\"gen_ai.request.model\", model)\n",
    "                response_span.set_attribute(\"gen_ai.system\", \"openai\")\n",
    "\n",
    "                summary_prompt = f\"Summarize these booking results for the user: {json.dumps(tool_results)}\"\n",
    "                response_span.set_attribute(\"gen_ai.llm.input.user\", summary_prompt)\n",
    "                \n",
    "                # Message history\n",
    "                response_span.set_attribute(\"gen_ai.input.messages\", json.dumps([\n",
    "                    {\"role\": \"system\", \"content\": \"Provide a friendly booking confirmation summary.\"},\n",
    "                    {\"role\": \"user\", \"content\": summary_prompt}\n",
    "                ]))\n",
    "\n",
    "                final_response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"Provide a friendly booking confirmation summary.\"},\n",
    "                        {\"role\": \"user\", \"content\": summary_prompt}\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                response_span.set_attribute(\"gen_ai.usage.input_tokens\", final_response.usage.prompt_tokens)\n",
    "                response_span.set_attribute(\"gen_ai.usage.output_tokens\", final_response.usage.completion_tokens)\n",
    "                response_span.set_attribute(\"gen_ai.usage.total_tokens\", final_response.usage.total_tokens)\n",
    "\n",
    "                final_text = final_response.choices[0].message.content\n",
    "                response_span.set_attribute(\"gen_ai.llm.output\", final_text)\n",
    "                \n",
    "                # Output message history (simple format)\n",
    "                response_span.set_attribute(\"gen_ai.output.messages\", json.dumps([\n",
    "                    {\"role\": \"assistant\", \"content\": final_text}\n",
    "                ]))\n",
    "\n",
    "                return {\n",
    "                    \"status\": \"success\",\n",
    "                    \"bookings\": tool_results,\n",
    "                    \"summary\": final_text\n",
    "                }\n",
    "\n",
    "        return {\n",
    "            \"status\": \"no_action\",\n",
    "            \"message\": message.content if message.content else \"No tools executed\"\n",
    "        }\n",
    "\n",
    "print('‚úÖ Travel agent implementation complete')\n",
    "print('   Supports: hotel booking, flight booking, LLM orchestration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Travel Agent\n",
    "\n",
    "Run a sample query to verify instrumentation works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "result = travel_agent(\"I need to book a hotel in Paris for 2024-12-15 and a flight from London to Paris for the same day\")\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('TRAVEL AGENT RESPONSE')\n",
    "print('=' * 60)\n",
    "print(f'Status: {result[\"status\"]}')\n",
    "if result[\"status\"] == \"success\":\n",
    "    print(f'\\nBookings Made: {len(result[\"bookings\"])}')\n",
    "    for booking in result[\"bookings\"]:\n",
    "        print(f\"  - {booking['tool']}: {json.dumps(booking['result'], indent=4)}\")\n",
    "    print(f'\\nSummary: {result[\"summary\"]}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Tool Definitions Capture (v1.1.0+)\n",
    "\n",
    "Starting with **Fiddler LangGraph SDK v1.1.0**, you can capture tool definitions that are available to the LLM for tool calling. This enables powerful analysis and evaluation capabilities:\n",
    "\n",
    "#### Why Capture Tool Definitions?\n",
    "\n",
    "- **Validate Tool Usage:** Verify that the LLM selected the correct tool for the task\n",
    "- **Parameter Validation:** Check that all required parameters were provided correctly\n",
    "- **Tool Coverage Analysis:** Understand which tools are being used and which are ignored\n",
    "- **Debugging:** Quickly identify tool-related issues in production\n",
    "- **Evaluation:** Enable automated evaluators to validate tool calls against their schemas\n",
    "\n",
    "#### How It Works\n",
    "\n",
    "1. **Define tools** in OpenAI format (type, function name, description, parameters)\n",
    "2. **Capture on span** by setting `gen_ai.tool.definitions` attribute with JSON-serialized tools\n",
    "3. **View in Fiddler** - Tool definitions appear in the trace viewer and are available for evaluation\n",
    "\n",
    "#### Format\n",
    "\n",
    "Tool definitions are stored in OpenAI's native nested format:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"tool_name\",\n",
    "      \"description\": \"What the tool does\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"param1\": {\"type\": \"string\", \"description\": \"...\"},\n",
    "          \"param2\": {\"type\": \"number\", \"description\": \"...\"}\n",
    "        },\n",
    "        \"required\": [\"param1\"]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "#### Best Practices\n",
    "\n",
    "- Always capture tool definitions when using tool calling\n",
    "- Include detailed descriptions for better LLM tool selection\n",
    "- Specify parameter types and required fields accurately\n",
    "- Keep tool definitions in sync with actual tool implementations\n",
    "- Remember to JSON-serialize before setting as span attribute\n",
    "\n",
    "Let's see a standalone example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standalone example: Tool definitions capture for any LLM call\n",
    "\n",
    "def make_llm_call_with_tools(prompt: str, tools: list):\n",
    "    \"\"\"\n",
    "    Example function showing how to capture tool definitions\n",
    "    for any LLM call with tool calling capability.\n",
    "    \"\"\"\n",
    "    with tracer.start_as_current_span(\"llm_with_tools\") as span:\n",
    "        # Set basic attributes\n",
    "        span.set_attribute(\"fiddler.span.type\", \"llm\")\n",
    "        span.set_attribute(\"gen_ai.agent.name\", AGENT_NAME)\n",
    "        span.set_attribute(\"gen_ai.agent.id\", AGENT_ID)\n",
    "        span.set_attribute(\"gen_ai.request.model\", \"gpt-4o-mini\")\n",
    "        span.set_attribute(\"gen_ai.system\", \"openai\")\n",
    "        span.set_attribute(\"gen_ai.llm.input.user\", prompt)\n",
    "        \n",
    "        # Message history\n",
    "        span.set_attribute(\"gen_ai.input.messages\", json.dumps([\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]))\n",
    "        \n",
    "        # Capture tool definitions (v1.1.0+)\n",
    "        span.set_attribute(\"gen_ai.tool.definitions\", json.dumps(tools))\n",
    "        \n",
    "        # Make LLM call\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            tools=tools\n",
    "        )\n",
    "        \n",
    "        # Set output\n",
    "        if response.choices[0].message.tool_calls:\n",
    "            # Build tool_call parts\n",
    "            tool_call_parts = []\n",
    "            for tc in response.choices[0].message.tool_calls:\n",
    "                tool_call_parts.append({\n",
    "                    \"type\": \"tool_call\",\n",
    "                    \"name\": tc.function.name,\n",
    "                    \"id\": tc.id,\n",
    "                    \"arguments\": json.loads(tc.function.arguments)\n",
    "                })\n",
    "            \n",
    "            span.set_attribute(\"gen_ai.llm.output\", f\"Called tools: {[tc['name'] for tc in tool_call_parts]}\")\n",
    "            \n",
    "            # Output message history (complex format with tool calls)\n",
    "            span.set_attribute(\"gen_ai.output.messages\", json.dumps([{\n",
    "                \"role\": \"assistant\",\n",
    "                \"parts\": tool_call_parts,\n",
    "                \"finish_reason\": response.choices[0].finish_reason\n",
    "            }]))\n",
    "        else:\n",
    "            span.set_attribute(\"gen_ai.llm.output\", response.choices[0].message.content or \"\")\n",
    "            \n",
    "            # Output message history (simple format)\n",
    "            span.set_attribute(\"gen_ai.output.messages\", json.dumps([\n",
    "                {\"role\": \"assistant\", \"content\": response.choices[0].message.content or \"\"}\n",
    "            ]))\n",
    "        \n",
    "        span.set_attribute(\"gen_ai.usage.input_tokens\", response.usage.prompt_tokens)\n",
    "        span.set_attribute(\"gen_ai.usage.output_tokens\", response.usage.completion_tokens)\n",
    "        span.set_attribute(\"gen_ai.usage.total_tokens\", response.usage.total_tokens)\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Test with a weather tool example\n",
    "test_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"City name\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"Temperature unit\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result = make_llm_call_with_tools(\"What's the weather in Paris?\", test_tools)\n",
    "print(\"Tool definitions captured!\")\n",
    "print(f\"   Captured {len(test_tools)} tool definition(s)\")\n",
    "if result.choices[0].message.tool_calls:\n",
    "    print(f\"   LLM called tool: {result.choices[0].message.tool_calls[0].function.name}\")\n",
    "else:\n",
    "    print(f\"   LLM Response: {result.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Part 3: Custom User-Defined Attributes\n",
    "\n",
    "Add business context and custom metadata to traces using Fiddler's user-defined attribute patterns.\n",
    "\n",
    "### Session-Level Attributes\n",
    "\n",
    "These attributes should be added to **all spans** in a trace and use the pattern:\n",
    "- `fiddler.session.user.{key}`\n",
    "\n",
    "### Span-Level Attributes\n",
    "\n",
    "These attributes are specific to individual spans:\n",
    "- `fiddler.span.user.{key}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travel_agent_with_custom_attributes(user_request: str, user_id: str, tier: str, region: str):\n",
    "    \"\"\"\n",
    "    Enhanced travel agent with custom business attributes.\n",
    "    \"\"\"\n",
    "    with tracer.start_as_current_span(\"travel_agent_chain\") as root_span:\n",
    "        # Required Fiddler attributes\n",
    "        root_span.set_attribute(\"fiddler.span.type\", \"chain\")\n",
    "        root_span.set_attribute(\"gen_ai.agent.name\", AGENT_NAME)\n",
    "        root_span.set_attribute(\"gen_ai.agent.id\", AGENT_ID)\n",
    "\n",
    "        # ========== SESSION-LEVEL CUSTOM ATTRIBUTES ==========\n",
    "        # These should be on ALL spans in the trace\n",
    "        root_span.set_attribute(\"fiddler.session.user.user_id\", user_id)\n",
    "        root_span.set_attribute(\"fiddler.session.user.tier\", tier)\n",
    "        root_span.set_attribute(\"fiddler.session.user.region\", region)\n",
    "        # ===================================================\n",
    "\n",
    "        # ========== SPAN-LEVEL CUSTOM ATTRIBUTES ==========\n",
    "        # Business-specific metadata for this interaction\n",
    "        root_span.set_attribute(\"fiddler.span.user.request_type\", \"travel_booking\")\n",
    "        root_span.set_attribute(\"fiddler.span.user.priority\", \"high\" if tier == \"premium\" else \"normal\")\n",
    "        # =================================================\n",
    "\n",
    "        # Continue with normal agent logic...\n",
    "        result = travel_agent(user_request)\n",
    "        return result\n",
    "\n",
    "# Test with custom attributes\n",
    "print('\\n' + '=' * 60)\n",
    "print('Testing Custom Attributes')\n",
    "print('=' * 60)\n",
    "result = travel_agent_with_custom_attributes(\n",
    "    user_request=\"Book a hotel in Tokyo for 2024-12-20\",\n",
    "    user_id=\"user_12345\",\n",
    "    tier=\"premium\",\n",
    "    region=\"APAC\"\n",
    ")\n",
    "print('‚úÖ Custom attributes added to trace')\n",
    "print('   Session attributes: user_id, tier, region')\n",
    "print('   Span attributes: request_type, priority')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Part 4: Conversation Management\n",
    "\n",
    "Track multi-turn conversations using the `gen_ai.conversation.id` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def set_conversation_context(conversation_id: str):\n",
    "    \"\"\"\n",
    "    Helper to add conversation ID to all spans in a conversation.\n",
    "    In production, you would manage this through a context manager or middleware.\n",
    "    \"\"\"\n",
    "    return conversation_id\n",
    "\n",
    "def conversational_travel_agent(user_request: str, conversation_id: str = None):\n",
    "    \"\"\"\n",
    "    Travel agent that tracks conversations.\n",
    "    \"\"\"\n",
    "    # Generate or use provided conversation ID\n",
    "    conv_id = conversation_id or str(uuid.uuid4())\n",
    "\n",
    "    with tracer.start_as_current_span(\"travel_agent_chain\") as root_span:\n",
    "        # Required attributes\n",
    "        root_span.set_attribute(\"fiddler.span.type\", \"chain\")\n",
    "        root_span.set_attribute(\"gen_ai.agent.name\", AGENT_NAME)\n",
    "        root_span.set_attribute(\"gen_ai.agent.id\", AGENT_ID)\n",
    "\n",
    "        # ========== CONVERSATION TRACKING ==========\n",
    "        # Add conversation ID to track multi-turn interactions\n",
    "        root_span.set_attribute(\"gen_ai.conversation.id\", conv_id)\n",
    "        # ==========================================\n",
    "\n",
    "        result = travel_agent(user_request)\n",
    "        result[\"conversation_id\"] = conv_id\n",
    "        return result\n",
    "\n",
    "# Simulate multi-turn conversation\n",
    "print('\\n' + '=' * 60)\n",
    "print('Multi-Turn Conversation Example')\n",
    "print('=' * 60)\n",
    "\n",
    "# First turn - generate new conversation ID\n",
    "result1 = conversational_travel_agent(\"I need a hotel in San Francisco\")\n",
    "conv_id = result1[\"conversation_id\"]\n",
    "print(f'Turn 1: Conversation ID = {conv_id}')\n",
    "\n",
    "# Second turn - use same conversation ID\n",
    "result2 = conversational_travel_agent(\n",
    "    \"Also book me a flight from LA to San Francisco\",\n",
    "    conversation_id=conv_id\n",
    ")\n",
    "print(f'Turn 2: Conversation ID = {result2[\"conversation_id\"]}')\n",
    "\n",
    "print('\\n‚úÖ Multi-turn conversation tracked with consistent ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Part 5: Production Configuration\n",
    "\n",
    "Configure OpenTelemetry for production deployments with:\n",
    "\n",
    "- **Sampling**: Reduce volume by sampling traces\n",
    "- **Batch Processing**: Optimize network usage\n",
    "- **Compression**: Reduce data transmission size\n",
    "- **Resource Attributes**: Add service metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.sdk.trace import sampling\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import Compression\n",
    "\n",
    "def create_production_tracer_provider():\n",
    "    \"\"\"\n",
    "    Create a production-ready tracer provider with optimized settings.\n",
    "    \"\"\"\n",
    "    # 1. Sampling: Sample 10% of traces\n",
    "    sampler = sampling.TraceIdRatioBased(0.1)\n",
    "\n",
    "    # 2. Resource attributes: Add service metadata\n",
    "    resource = Resource.create({\n",
    "        \"service.name\": \"travel-agent-service\",\n",
    "        \"service.version\": \"1.0.0\",\n",
    "        \"deployment.environment\": \"production\",\n",
    "        \"application.id\": APPLICATION_UUID\n",
    "    })\n",
    "\n",
    "    # 3. Create provider with sampler and resource\n",
    "    provider = TracerProvider(sampler=sampler, resource=resource)\n",
    "\n",
    "    # 4. Configure OTLP exporter with compression\n",
    "    otlp_exporter = OTLPSpanExporter(\n",
    "        endpoint=otlp_endpoint,\n",
    "        compression=Compression.Gzip  # Enable gzip compression\n",
    "    )\n",
    "\n",
    "    # 5. Batch processor with production settings\n",
    "    batch_processor = BatchSpanProcessor(\n",
    "        otlp_exporter,\n",
    "        max_queue_size=500,           # Max spans in queue\n",
    "        max_export_batch_size=50,     # Spans per export batch\n",
    "        schedule_delay_millis=500,    # Export every 500ms\n",
    "        export_timeout_millis=10000   # 10 second timeout\n",
    "    )\n",
    "\n",
    "    provider.add_span_processor(batch_processor)\n",
    "    return provider\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('Production Configuration')\n",
    "print('=' * 60)\n",
    "print('‚úÖ Production tracer provider configured')\n",
    "print('   - Sampling: 10% of traces')\n",
    "print('   - Compression: gzip enabled')\n",
    "print('   - Batch size: 50 spans')\n",
    "print('   - Export interval: 500ms')\n",
    "print('   - Resource metadata: service.name, version, environment')\n",
    "print('\\nüí° Use this configuration in production deployments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Part 6: Using FiddlerClient Alternative\n",
    "\n",
    "If you have `fiddler-langgraph` installed, you can use `FiddlerClient.get_tracer()` for simplified setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Simplified setup with FiddlerClient\n",
    "# Requires: pip install fiddler-langgraph\n",
    "\n",
    "try:\n",
    "    from fiddler_langgraph import FiddlerClient\n",
    "\n",
    "    # Initialize FiddlerClient\n",
    "    fdl_client = FiddlerClient(\n",
    "        api_key=ACCESS_TOKEN,\n",
    "        application_id=APPLICATION_UUID,\n",
    "        url=FIDDLER_URL\n",
    "    )\n",
    "\n",
    "    # Get pre-configured tracer\n",
    "    tracer_simplified = fdl_client.get_tracer()\n",
    "\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('FiddlerClient Alternative')\n",
    "    print('=' * 60)\n",
    "    print('‚úÖ FiddlerClient setup complete')\n",
    "    print('   This approach handles OTLP configuration automatically')\n",
    "    print('   Use tracer_simplified for manual span creation')\n",
    "\n",
    "except ImportError:\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('FiddlerClient Alternative (Optional)')\n",
    "    print('=' * 60)\n",
    "    print('‚ö†Ô∏è  fiddler-langgraph not installed')\n",
    "    print('   Install with: pip install fiddler-langgraph')\n",
    "    print('   This provides simplified tracer setup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Verify Traces in Fiddler\n",
    "\n",
    "After running the examples above, traces should appear in your Fiddler application.\n",
    "\n",
    "**Steps to verify:**\n",
    "\n",
    "1. Navigate to your Fiddler instance\n",
    "2. Go to **GenAI Apps** and select your application\n",
    "3. Check that application status shows as **Active**\n",
    "4. View traces in the **Traces** tab\n",
    "\n",
    "**What to check:**\n",
    "\n",
    "- ‚úÖ Application shows as Active\n",
    "- ‚úÖ Traces appear within 1-2 minutes\n",
    "- ‚úÖ Span hierarchy: chain ‚Üí LLM ‚Üí tools\n",
    "- ‚úÖ Required attributes present:\n",
    "  - `fiddler.span.type`\n",
    "  - `gen_ai.agent.name`\n",
    "  - `gen_ai.agent.id`\n",
    "- ‚úÖ LLM attributes:\n",
    "  - `gen_ai.request.model`\n",
    "  - `gen_ai.usage.*` (token counts)\n",
    "- ‚úÖ Tool attributes:\n",
    "  - `gen_ai.tool.name`\n",
    "  - `gen_ai.tool.input`\n",
    "  - `gen_ai.tool.output`\n",
    "- ‚úÖ Custom attributes:\n",
    "  - `fiddler.session.user.*`\n",
    "  - `fiddler.span.user.*`\n",
    "- ‚úÖ Conversation tracking:\n",
    "  - `gen_ai.conversation.id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Troubleshooting Diagnostics\n",
    "\n",
    "Run diagnostics to verify your configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('DIAGNOSTIC CHECKS')\n",
    "print('=' * 60)\n",
    "\n",
    "# 1. Environment variables\n",
    "print('\\n1. Environment Variables:')\n",
    "print(f'   OTEL_EXPORTER_OTLP_ENDPOINT: {os.getenv(\"OTEL_EXPORTER_OTLP_ENDPOINT\")}')\n",
    "print(f'   OTEL_RESOURCE_ATTRIBUTES: {os.getenv(\"OTEL_RESOURCE_ATTRIBUTES\")}')\n",
    "print(f'   OTEL_EXPORTER_OTLP_HEADERS: {\"Set\" if os.getenv(\"OTEL_EXPORTER_OTLP_HEADERS\") else \"Not Set\"}')\n",
    "\n",
    "# 2. Network connectivity\n",
    "print('\\n2. Network Connectivity:')\n",
    "try:\n",
    "    response = requests.head(FIDDLER_URL, timeout=5)\n",
    "    print(f'   ‚úÖ Connection to {FIDDLER_URL}: Success (Status: {response.status_code})')\n",
    "except Exception as e:\n",
    "    print(f'   ‚ùå Connection to {FIDDLER_URL}: Failed ({str(e)})')\n",
    "\n",
    "# 3. Configuration summary\n",
    "print('\\n3. Configuration Summary:')\n",
    "print(f'   Fiddler URL: {FIDDLER_URL}')\n",
    "print(f'   Application UUID: {APPLICATION_UUID}')\n",
    "print(f'   Access Token: {\"Set\" if ACCESS_TOKEN else \"Not Set\"}')\n",
    "print(f'   OpenAI API Key: {\"Set\" if OPENAI_API_KEY else \"Not Set\"}')\n",
    "\n",
    "# 4. OpenTelemetry configuration\n",
    "print('\\n4. OpenTelemetry Status:')\n",
    "print(f'   Tracer Provider: {\"Initialized\" if trace.get_tracer_provider() else \"Not Initialized\"}')\n",
    "print(f'   OTLP Endpoint: {otlp_endpoint}')\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('\\nüí° If traces are not appearing:')\n",
    "print('   1. Verify credentials are correct')\n",
    "print('   2. Check network connectivity')\n",
    "print('   3. Ensure Application UUID is valid UUID4 format')\n",
    "print('   4. Look for errors in console exporter output above')\n",
    "print('   5. Wait 1-2 minutes for traces to appear in Fiddler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Next Steps\n",
    "\n",
    "Now that you have advanced OpenTelemetry integration working:\n",
    "\n",
    "### Explore Fiddler Capabilities\n",
    "\n",
    "- **Monitor Performance**: Track latency, token usage, and success rates\n",
    "- **Custom Dashboards**: Create dashboards using your custom attributes\n",
    "- **Alerts**: Set up alerts for errors, high latency, or anomalies\n",
    "- **Cost Analysis**: Monitor LLM API costs through token tracking\n",
    "\n",
    "### Consider SDKs for Specific Frameworks\n",
    "\n",
    "- [Fiddler LangGraph SDK](https://docs.fiddler.ai/tutorials/llm-monitoring/langgraph-sdk-quick-start) - Auto-instrumentation for LangGraph/LangChain\n",
    "- [Fiddler Strands SDK](https://docs.fiddler.ai/tutorials/llm-monitoring/strands-agent-quick-start) - Native Strands integration\n",
    "\n",
    "### Production Deployment\n",
    "\n",
    "- Implement the production configuration from Part 5\n",
    "- Set up error handling and retry logic\n",
    "- Configure sampling based on your volume\n",
    "- Add environment-specific resource attributes\n",
    "- Implement PII filtering if needed\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [OpenTelemetry Quick Start Guide](https://docs.fiddler.ai/tutorials/llm-monitoring/opentelemetry-quick-start)\n",
    "- [Getting Started: Agentic Monitoring](https://docs.fiddler.ai/getting-started/agentic-monitoring)\n",
    "- [Fiddler Documentation](https://docs.fiddler.ai)\n",
    "- [OpenTelemetry Python](https://opentelemetry.io/docs/instrumentation/python/)\n",
    "\n",
    "---\n",
    "\n",
    "**Need Help?**\n",
    "\n",
    "- Email: support@fiddler.ai\n",
    "- Documentation: https://docs.fiddler.ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
