{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4HCMkMtvGu9"
   },
   "source": [
    "# Fiddler Ranking Model Quick Start Guide\n",
    "\n",
    "## Goal\n",
    "\n",
    "This guide demonstrates how to onboard a search ranking model to Fiddler by defining a `RANKING` model task, specifying group-by parameters, and publishing grouped event data for monitoring.\n",
    "\n",
    "## Monitoring Ranking Models\n",
    "\n",
    "This notebook provides a step-by-step walkthrough for monitoring a ranking model, using an Expedia search results dataset as an example. You'll learn how to configure a model specifically for the `RANKING` task in Fiddler, including how to define the critical `group_by` parameter that associates individual items with a unique query or request. The guide demonstrates the necessary data transformation step of grouping events by this ID before publishing both a baseline and production data. This enables Fiddler to calculate specialized ranking metrics and monitor your model's performance effectively\n",
    "\n",
    "## About Fiddler\n",
    "\n",
    "Fiddler is the all-in-one AI Observability and Security platform for responsible AI. Monitoring and analytics capabilities provide a common language, centralized controls, and actionable insights to operationalize production ML models, GenAI, AI agents, and LLM applications with trust. An integral part of the platform, the Fiddler Trust Service provides quality and moderation controls for LLM applications. Powered by cost-effective, task-specific, and scalable Fiddler-developed trust models — including cloud and VPC deployments for secure environments — it delivers the fastest guardrails in the industry. Fortune 500 organizations utilize Fiddler to scale LLM and ML deployments, delivering high-performance AI, reducing costs, and ensuring responsible governance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1yVGAH2vGvA"
   },
   "source": [
    "### Getting Started\n",
    "\n",
    "1. Connect to Fiddler\n",
    "2. Load a Data Sample\n",
    "3. Define the Model Specifications and Model Task\n",
    "4. Create a Model\n",
    "5. Publish a Pre-production Baseline\n",
    "6. Publish Production Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "583iLl9lvGvA"
   },
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OoDdHCPMvGvC"
   },
   "outputs": [],
   "source": [
    "%pip install -q fiddler-client\n",
    "\n",
    "import time as time\n",
    "\n",
    "import pandas as pd\n",
    "import fiddler as fdl\n",
    "\n",
    "print(f\"Running Fiddler Python client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trtTWu6dvGvD"
   },
   "source": [
    "## 1. Connect to Fiddler\n",
    "\n",
    "Before you can add information about your model with Fiddler, you'll need to connect using the Fiddler Python client.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**We need a couple pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your authorization token\n",
    "\n",
    "Your authorization token can be found by navigating to the **Credentials** tab on the **Settings** page of your Fiddler environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUBetAWYvGvD"
   },
   "outputs": [],
   "source": [
    "URL = ''  # Make sure to include the full URL (including https:// e.g. 'https://your_company_name.fiddler.ai').\n",
    "TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants for this example notebook, change as needed to create your own versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for the default example, change as needed to create your own versions\n",
    "PROJECT_NAME = 'quickstart_examples'\n",
    "MODEL_NAME = 'search_ranking_example'\n",
    "DATASET_NAME = 'expedia_dataset'\n",
    "\n",
    "PATH_TO_SAMPLE_CSV = 'https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/data/v3/expedia_data_sample.csv'\n",
    "PATH_TO_EVENTS_CSV = 'https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/data/v3/expedia_logs.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q6RX3UwvGvE"
   },
   "source": [
    "Next we use these credentials to connect to the Fiddler API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rho39PQcvGvE"
   },
   "outputs": [],
   "source": [
    "fdl.init(url=URL, token=TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtJV4iIJvGvE"
   },
   "source": [
    "Once you connect, you can create a new project by specifying a unique project name in the fld.Project constructor and calling the `create()` method. If the project already exists, it will load it for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7V2wpm9vGvE"
   },
   "outputs": [],
   "source": [
    "project = fdl.Project.get_or_create(name=PROJECT_NAME)\n",
    "\n",
    "print(f'Using project with id = {project.id} and name = {project.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiXy5tCwvGvF"
   },
   "source": [
    "## 2. Load a Data Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zb2QlLEevGvF"
   },
   "source": [
    "Now we retrieve the Expedia Dataset as a data sample for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsjVExV9vGvF"
   },
   "outputs": [],
   "source": [
    "sample_data_df = pd.read_csv(PATH_TO_SAMPLE_CSV)\n",
    "sample_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiMAH9QUvGvF"
   },
   "source": [
    "Fiddler uses this data sample to keep track of important information about your data.\n",
    "  \n",
    "This includes **data types**, **data ranges**, and **unique values** for categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I46fM8ybvGvG"
   },
   "source": [
    "## 3. Define the Model Specifications and Model Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5h4cDewzvGvG"
   },
   "source": [
    "To add a Ranking model you must specify the ModelTask as `RANKING` in the model info object.  \n",
    "\n",
    "Additionally, you must provide the `group_by` argument that corresponds to the query search id. This `group_by` column should be present either in:\n",
    "- `features` : if it is used to build and run the model\n",
    "- `metadata_cols` : if not used by the model\n",
    "\n",
    "Optionally, you can give a `ranking_top_k` number (default is 50). This will be the number of results within each query to take into account while computing the performance metrics in monitoring.  \n",
    "\n",
    "Unless the prediction column was part of your baseline dataset, you must provide the minimum and maximum values predictions can take in a dictionary format (see below).  \n",
    "\n",
    "If your target is categorical (string), you need to provide the `target_class_order` argument. If your target is numerical and you don't specify this argument, Fiddler will infer it.   \n",
    "\n",
    "This will be the list of possible values for the target **ordered**. The first element should be the least relevant target level, the last element should be the most relevant target level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec = fdl.ModelSpec(\n",
    "    inputs=list(\n",
    "        sample_data_df.drop(\n",
    "            columns=[\n",
    "                'binary_relevance',\n",
    "                'score',\n",
    "                'graded_relevance',\n",
    "                'position',\n",
    "                'timestamp',\n",
    "            ]\n",
    "        ).columns\n",
    "    ),\n",
    "    outputs=['score'],\n",
    "    targets=['binary_relevance'],\n",
    "    metadata=['timestamp', 'graded_relevance', 'position'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have columns in your ModelSpec which denote **prediction IDs or timestamps**, then Fiddler can use these to power its analytics accordingly.\n",
    "\n",
    "Let's call them out here and use them when configuring the Model in step 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_column = '' # Optional: Specify the name of the ID column if you have one\n",
    "timestamp_column = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task = fdl.ModelTask.RANKING\n",
    "\n",
    "task_params = fdl.ModelTaskParams(\n",
    "    group_by='srch_id', top_k=20, target_class_order=[0, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fdl.Model.from_data(\n",
    "    name=MODEL_NAME,\n",
    "    project_id=project.id,\n",
    "    source=sample_data_df,\n",
    "    spec=model_spec,\n",
    "    task=model_task,\n",
    "    task_params=task_params,\n",
    "    event_ts_col=timestamp_column,\n",
    ")\n",
    "\n",
    "model.create()\n",
    "print(f'New model created with id = {model.id} and name = {model.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Publish a Pre-production Baseline **(Optional)**\n",
    "\n",
    "We can publish the data sample from earlier to add it as a baseline.\n",
    "\n",
    "For ranking, we need to ingest all events from a given query or search ID together. To do that, we need to transform the data to a grouped format.  \n",
    "You can use the `group_by` utility function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the pre-production data to make it available as a baseline\n",
    "sample_df_grouped = fdl.utils.helpers.group_by(\n",
    "    df=sample_data_df, group_by_col='srch_id'\n",
    ")\n",
    "\n",
    "baseline_publish_job = model.publish(\n",
    "    source=sample_df_grouped,\n",
    "    environment=fdl.EnvType.PRE_PRODUCTION,\n",
    "    dataset_name=DATASET_NAME,\n",
    ")\n",
    "print(\n",
    "    f'Initiated pre-production environment data upload with Job ID = {baseline_publish_job.id}'\n",
    ")\n",
    "\n",
    "# Uncomment the line below to wait for the job to finish, otherwise it will run in the background.\n",
    "# You can check the status on the Jobs page in the Fiddler UI or use the job ID to query the job status via the API.\n",
    "# baseline_publish_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B8Vly1JvGvI"
   },
   "source": [
    "# 6. Publish Events For Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2Cznqy5vGvI"
   },
   "source": [
    "Fiddler will **monitor this data and compare it to your baseline to generate powerful insights into how your model is behaving**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Each record sent to Fiddler is called **an event**.\n",
    "  \n",
    "Let's load some sample events from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doqcM3ZevGvI"
   },
   "outputs": [],
   "source": [
    "production_data_df = pd.read_csv(PATH_TO_EVENTS_CSV)\n",
    "\n",
    "# Shift the timestamps of the production events to be as recent as today\n",
    "production_data_df['timestamp'] = production_data_df['timestamp'] + (\n",
    "    int(time.time() * 1000) - production_data_df['timestamp'].max()\n",
    ")\n",
    "production_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DLRNuT5vGvJ"
   },
   "source": [
    "Again, let's group the data before sending it to Fiddler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cF_V6FZ-vGvJ"
   },
   "outputs": [],
   "source": [
    "df_logs_grouped = fdl.utils.helpers.group_by(\n",
    "    df=production_data_df, group_by_col='srch_id'\n",
    ")\n",
    "df_logs_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYzNsNDNvGvJ"
   },
   "source": [
    "Now publish the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_publish_job = model.publish(df_logs_grouped)\n",
    "\n",
    "print(\n",
    "    f'Initiated production environment data upload with Job ID = {production_publish_job.id}'\n",
    ")\n",
    "\n",
    "# Uncomment the line below to wait for the job to finish, otherwise it will run in the background.\n",
    "# You can check the status on the Jobs page in the Fiddler UI or use the job ID to query the job status via the API.\n",
    "# production_publish_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNtMwctovGvO"
   },
   "source": [
    "# Get insights\n",
    "\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "You can now head to your Fiddler environment and start getting enhanced observability into your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXyjlZNgvGvO"
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/images/ranking_model_1.png\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHvq62t4vGvO"
   },
   "source": [
    "--------\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
