{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4HCMkMtvGu9"
   },
   "source": [
    "# Fiddler Ranking Model Quick Start Guide\n",
    "\n",
    "Fiddler enables your teams to monitor and evaluate model rankings, providing insights into model performance and detecting issues like data drift before they impact your applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1yVGAH2vGvA"
   },
   "source": [
    "### Example: Expedia Search Ranking\n",
    "The following dataset contains Expedia shopping and purchase data as well as information on price competitiveness. The data are organized around a set of “search result impressions”, or the ordered list of hotels that the user sees after they search for a hotel on the Expedia website. In addition to impressions from the existing algorithm, the data contain impressions where the hotels were randomly sorted, to avoid the position bias of the existing algorithm. The user response is provided as a click on a hotel. From: https://www.kaggle.com/c/expedia-personalized-sort/overview\n",
    "\n",
    "1. Connect to Fiddler\n",
    "2. Load a Data Sample\n",
    "3. Define the Model Specifications and Model Task\n",
    "4. Create a Model\n",
    "5. Publish a Pre-production Baseline\n",
    "6. Publish Production Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "583iLl9lvGvA"
   },
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OoDdHCPMvGvC"
   },
   "outputs": [],
   "source": [
    "%pip install -q fiddler-client\n",
    "\n",
    "import os\n",
    "import time as time\n",
    "\n",
    "import pandas as pd\n",
    "import fiddler as fdl\n",
    "\n",
    "print(f\"Running Fiddler Python client version {fdl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trtTWu6dvGvD"
   },
   "source": [
    "## 1. Connect to Fiddler\n",
    "\n",
    "Before you can add information about your model with Fiddler, you'll need to connect using the Fiddler Python client.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**We need a couple pieces of information to get started.**\n",
    "1. The URL you're using to connect to Fiddler\n",
    "2. Your authorization token\n",
    "\n",
    "Your authorization token can be found by navigating to the **Credentials** tab on the **Settings** page of your Fiddler environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUBetAWYvGvD"
   },
   "outputs": [],
   "source": [
    "URL = ''  # Make sure to include the full URL (including https:// e.g. 'https://your_company_name.fiddler.ai').\n",
    "TOKEN = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants for this example notebook, change as needed to create your own versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for the default example, change as needed to create your own versions\n",
    "PROJECT_NAME = 'quickstart_examples'\n",
    "MODEL_NAME = 'search_ranking_example'\n",
    "DATASET_NAME = 'expedia_dataset'\n",
    "\n",
    "PATH_TO_SAMPLE_CSV = 'https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/data/v3/expedia_data_sample.csv'\n",
    "PATH_TO_EVENTS_CSV = 'https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/data/v3/expedia_logs.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q6RX3UwvGvE"
   },
   "source": [
    "Next we use these credentials to connect to the Fiddler API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rho39PQcvGvE"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    fdl.init(url=URL, token=TOKEN) \n",
    "except Exception as e:\n",
    "    print(f'Error initializing Fiddler Python client: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtJV4iIJvGvE"
   },
   "source": [
    "Once you connect, you can create a new project by specifying a unique project name in the fld.Project constructor and calling the `create()` method. If the project already exists, it will load it for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7V2wpm9vGvE"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create project\n",
    "    project = fdl.Project(name=PROJECT_NAME).create()\n",
    "    print(f'New project created with id = {project.id} and name = {project.name}')\n",
    "except fdl.Conflict:\n",
    "    # Get project by name\n",
    "    project = fdl.Project.from_name(name=PROJECT_NAME)\n",
    "    print(f'Loaded existing project with id = {project.id} and name = {project.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiXy5tCwvGvF"
   },
   "source": [
    "## 2. Load a Data Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zb2QlLEevGvF"
   },
   "source": [
    "Now we retrieve the Expedia Dataset as a data sample for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsjVExV9vGvF"
   },
   "outputs": [],
   "source": [
    "sample_data_df = pd.read_csv(PATH_TO_SAMPLE_CSV)\n",
    "sample_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiMAH9QUvGvF"
   },
   "source": [
    "Fiddler uses this data sample to keep track of important information about your data.\n",
    "  \n",
    "This includes **data types**, **data ranges**, and **unique values** for categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I46fM8ybvGvG"
   },
   "source": [
    "## 3. Define the Model Specifications and Model Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5h4cDewzvGvG"
   },
   "source": [
    "To add a Ranking model you must specify the ModelTask as `RANKING` in the model info object.  \n",
    "\n",
    "Additionally, you must provide the `group_by` argument that corresponds to the query search id. This `group_by` column should be present either in:\n",
    "- `features` : if it is used to build and run the model\n",
    "- `metadata_cols` : if not used by the model\n",
    "\n",
    "Optionally, you can give a `ranking_top_k` number (default is 50). This will be the number of results within each query to take into account while computing the performance metrics in monitoring.  \n",
    "\n",
    "Unless the prediction column was part of your baseline dataset, you must provide the minimum and maximum values predictions can take in a dictionary format (see below).  \n",
    "\n",
    "If your target is categorical (string), you need to provide the `target_class_order` argument. If your target is numerical and you don't specify this argument, Fiddler will infer it.   \n",
    "\n",
    "This will be the list of possible values for the target **ordered**. The first element should be the least relevant target level, the last element should be the most relevant target level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec = fdl.ModelSpec(\n",
    "    inputs=list(\n",
    "        sample_data_df.drop(\n",
    "            columns=[\n",
    "                'binary_relevance',\n",
    "                'score',\n",
    "                'graded_relevance',\n",
    "                'position',\n",
    "                'timestamp',\n",
    "            ]\n",
    "        ).columns\n",
    "    ),\n",
    "    outputs=['score'],\n",
    "    targets=['binary_relevance'],\n",
    "    metadata=['timestamp', 'graded_relevance', 'position'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have columns in your ModelSpec which denote **prediction IDs or timestamps**, then Fiddler can use these to power its analytics accordingly.\n",
    "\n",
    "Let's call them out here and use them when configuring the Model in step 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_column = '' # Optional: Specify the name of the ID column if you have one\n",
    "timestamp_column = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task = fdl.ModelTask.RANKING\n",
    "\n",
    "task_params = fdl.ModelTaskParams(\n",
    "    group_by='srch_id', top_k=20, target_class_order=[0, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fdl.Model.from_data(\n",
    "    name=MODEL_NAME,\n",
    "    project_id=project.id,\n",
    "    source=sample_data_df,\n",
    "    spec=model_spec,\n",
    "    task=model_task,\n",
    "    task_params=task_params,\n",
    "    event_ts_col=timestamp_column,\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.create()\n",
    "    print(f'New model created with id = {model.id} and name = {model.name}')\n",
    "except Exception as e:\n",
    "    print(f'Error calling fdl.Model.create(): {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Publish a Pre-production Baseline **(Optional)**\n",
    "\n",
    "We can publish the data sample from earlier to add it as a baseline.\n",
    "\n",
    "For ranking, we need to ingest all events from a given query or search ID together. To do that, we need to transform the data to a grouped format.  \n",
    "You can use the `group_by` utility function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_grouped = fdl.utils.helpers.group_by(\n",
    "    df=sample_data_df, group_by_col='srch_id'\n",
    ")\n",
    "\n",
    "baseline_publish_job = model.publish(\n",
    "    source=sample_df_grouped,\n",
    "    environment=fdl.EnvType.PRE_PRODUCTION,\n",
    "    dataset_name=DATASET_NAME,\n",
    ")\n",
    "print(\n",
    "    f'Initiated pre-production environment data upload with Job ID = {baseline_publish_job.id}'\n",
    ")\n",
    "\n",
    "# Uncomment the line below to wait for the job to finish, otherwise it will run in the background.\n",
    "# You can check the status on the Jobs page in the Fiddler UI or use the job ID to query the job status via the API.\n",
    "# baseline_publish_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B8Vly1JvGvI"
   },
   "source": [
    "# 6. Publish Events For Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2Cznqy5vGvI"
   },
   "source": [
    "Fiddler will **monitor this data and compare it to your baseline to generate powerful insights into how your model is behaving**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Each record sent to Fiddler is called **an event**.\n",
    "  \n",
    "Let's load some sample events from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doqcM3ZevGvI"
   },
   "outputs": [],
   "source": [
    "production_data_df = pd.read_csv(PATH_TO_EVENTS_CSV)\n",
    "\n",
    "# Shift the timestamps of the production events to be as recent as today\n",
    "production_data_df['timestamp'] = production_data_df['timestamp'] + (\n",
    "    int(time.time() * 1000) - production_data_df['timestamp'].max()\n",
    ")\n",
    "production_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DLRNuT5vGvJ"
   },
   "source": [
    "Again, let's group the data before sending it to Fiddler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cF_V6FZ-vGvJ"
   },
   "outputs": [],
   "source": [
    "df_logs_grouped = fdl.utils.helpers.group_by(\n",
    "    df=production_data_df, group_by_col='srch_id'\n",
    ")\n",
    "df_logs_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYzNsNDNvGvJ"
   },
   "source": [
    "Now publish the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_publish_job = model.publish(df_logs_grouped)\n",
    "\n",
    "print(\n",
    "    f'Initiated production environment data upload with Job ID = {production_publish_job.id}'\n",
    ")\n",
    "\n",
    "# Uncomment the line below to wait for the job to finish, otherwise it will run in the background.\n",
    "# You can check the status on the Jobs page in the Fiddler UI or use the job ID to query the job status via the API.\n",
    "# production_publish_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNtMwctovGvO"
   },
   "source": [
    "# Get insights\n",
    "\n",
    "\n",
    "**You're all done!**\n",
    "  \n",
    "You can now head to your Fiddler environment and start getting enhanced observability into your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXyjlZNgvGvO"
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"https://raw.githubusercontent.com/fiddler-labs/fiddler-examples/main/quickstart/images/ranking_model_1.png\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHvq62t4vGvO"
   },
   "source": [
    "--------\n",
    "**Questions?**  \n",
    "  \n",
    "Check out [our docs](https://docs.fiddler.ai/) for a more detailed explanation of what Fiddler has to offer.\n",
    "\n",
    "Join our [community Slack](http://fiddler-community.slack.com/) to ask any questions!\n",
    "\n",
    "If you're still looking for answers, fill out a ticket on [our support page](https://fiddlerlabs.zendesk.com/) and we'll get back to you shortly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
