{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f4a3c1-9b2d-4f5e-a7c9-1e5f8b3d6a9c",
   "metadata": {},
   "source": [
    "# Fiddler Strands Agent Integration Quick Start\n",
    "\n",
    "## Goal\n",
    "\n",
    "This guide demonstrates how to integrate **Strands agents** with **Fiddler** for comprehensive observability and monitoring using OpenTelemetry (OTEL). You will learn to instrument agents, configure trace export, and verify monitoring in Fiddler. 🤖\n",
    "\n",
    "## About Strands Agents\n",
    "\n",
    "Strands is a modern AI agent framework that provides built-in telemetry support through OpenTelemetry. This notebook shows you how to connect Strands agents to Fiddler's monitoring platform, enabling you to:\n",
    "\n",
    "- Track agent execution traces and spans\n",
    "- Monitor tool usage and performance\n",
    "- Analyze multi-agent workflows\n",
    "- Debug agent behavior with detailed telemetry\n",
    "- Set up alerts for agent failures and anomalies\n",
    "\n",
    "## About Fiddler\n",
    "\n",
    "Fiddler is the all-in-one AI Observability and Security platform for responsible AI. Monitoring and analytics capabilities provide a common language, centralized controls, and actionable insights to operationalize production ML models, GenAI, AI agents, and LLM applications with trust. Fortune 500 organizations utilize Fiddler to scale LLM and ML deployments, delivering high-performance AI, reducing costs, and ensuring responsible governance.\n",
    "\n",
    "## Integration Overview\n",
    "\n",
    "The Fiddler-Strands integration uses three main components:\n",
    "\n",
    "1. **FiddlerSpanProcessor**: Custom span processor for attribute denormalization\n",
    "2. **StrandsTelemetry**: Telemetry setup that configures OpenTelemetry\n",
    "3. **Agent Configuration**: Proper instrumentation of Strands agents\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Summary\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "1. Set up environment variables for Fiddler OTLP endpoint\n",
    "2. Implement a custom FiddlerSpanProcessor for attribute propagation\n",
    "3. Configure Strands telemetry with OTLP export\n",
    "4. Create and instrument a Strands agent with tools\n",
    "5. Execute the agent and send traces to Fiddler\n",
    "6. Verify traces appear in the Fiddler UI\n",
    "\n",
    "This notebook should complete within 2-3 minutes.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Fiddler account with Application UUID and Bearer Token\n",
    "- OpenAI API key\n",
    "- Python packages: `strands-agents`, `opentelemetry-api`, `opentelemetry-sdk`, `opentelemetry-exporter-otlp`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2c3d4-e5f6-4a7b-8c9d-0e1f2a3b4c5d",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages\n",
    "\n",
    "First, let's install all necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -q strands-agents opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-f6a7-4b8c-9d0e-1f2a3b4c5d6e",
   "metadata": {},
   "source": [
    "## 2. Configure Environment Variables\n",
    "\n",
    "Set up your Fiddler credentials and OpenAI API key. Replace the placeholder values with your actual credentials.\n",
    "\n",
    "**Where to find these values:**\n",
    "- **FIDDLER_ENDPOINT**: Your Fiddler instance URL (e.g., `http://demo.fiddler.ai`)\n",
    "- **APPLICATION_UUID**: From your Fiddler application settings\n",
    "- **BEARER_TOKEN**: Generate from Fiddler Settings → API Tokens\n",
    "- **OPENAI_API_KEY**: Your OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6-a7b8-4c9d-0e1f-2a3b4c5d6e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Fiddler Configuration\n",
    "FIDDLER_ENDPOINT = ''  # e.g., \"http://demo.fiddler.ai\"\n",
    "APPLICATION_UUID = ''  # Your Fiddler application UUID\n",
    "TOKEN = ''  # Your Fiddler access token\n",
    "\n",
    "# OpenAI Configuration\n",
    "OPENAI_API_KEY = ''  # Your OpenAI API key\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['OTEL_EXPORTER_OTLP_ENDPOINT'] = FIDDLER_ENDPOINT\n",
    "os.environ['OTEL_RESOURCE_ATTRIBUTES'] = f'application.id={APPLICATION_UUID}'\n",
    "os.environ['OTEL_EXPORTER_OTLP_HEADERS'] = (\n",
    "    f'authorization=Bearer {TOKEN},fiddler-application-id={APPLICATION_UUID}'\n",
    ")\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "print('✅ Environment variables configured successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-b8c9-4d0e-1f2a-3b4c5d6e7f8a",
   "metadata": {},
   "source": [
    "## 3. Implement FiddlerSpanProcessor\n",
    "\n",
    "The FiddlerSpanProcessor ensures that critical agent attributes (name, ID, system prompt) are propagated from parent spans to child spans. This is essential for maintaining context in multi-step agent workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8-c9d0-4e1f-2a3b-4c5d6e7f8a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.sdk.trace import SpanProcessor\n",
    "from opentelemetry.trace import Span, get_current_span\n",
    "from opentelemetry import context\n",
    "\n",
    "\n",
    "class FiddlerSpanProcessor(SpanProcessor):\n",
    "    \"\"\"Custom span processor for Fiddler integration.\n",
    "\n",
    "    Copies critical attributes from parent spans to child spans to ensure\n",
    "    proper context propagation in agent workflows.\n",
    "    \"\"\"\n",
    "\n",
    "    # Attributes to denormalize (copy from parent to child)\n",
    "    DENORMALIZED_ATTRIBUTES = ['gen_ai.agent.name', 'gen_ai.agent.id', 'system_prompt']\n",
    "\n",
    "    def on_start(self, span: Span, parent_context: context.Context = None):\n",
    "        \"\"\"Called when a span starts.\n",
    "\n",
    "        Args:\n",
    "            span: The span that is starting\n",
    "            parent_context: Context of the parent span\n",
    "        \"\"\"\n",
    "        # Get the parent span from the context\n",
    "        parent_span = get_current_span(parent_context)\n",
    "\n",
    "        # Check if parent span is valid and has attributes\n",
    "        if (\n",
    "            parent_span\n",
    "            and parent_span.is_recording()\n",
    "            and hasattr(parent_span, 'attributes')\n",
    "        ):\n",
    "            # Get all attributes from the parent span\n",
    "            parent_attributes = parent_span.attributes\n",
    "\n",
    "            # Copy denormalized attributes to the child span\n",
    "            for attr in self.DENORMALIZED_ATTRIBUTES:\n",
    "                if parent_attributes.get(attr):\n",
    "                    span.set_attribute(attr, parent_attributes.get(attr))\n",
    "\n",
    "\n",
    "print('✅ FiddlerSpanProcessor implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9-d0e1-4f2a-3b4c-5d6e7f8a9b0c",
   "metadata": {},
   "source": [
    "## 4. Configure Strands Telemetry\n",
    "\n",
    "Set up the Strands telemetry system with:\n",
    "- Console exporter for local debugging\n",
    "- OTLP exporter for sending traces to Fiddler\n",
    "- FiddlerSpanProcessor for attribute propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-e1f2-4a3b-5c6d-7e8f9a0b1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands.telemetry import StrandsTelemetry\n",
    "\n",
    "# Initialize Strands telemetry\n",
    "strands_telemetry = StrandsTelemetry()\n",
    "\n",
    "# Add the Fiddler span processor for attribute denormalization\n",
    "strands_telemetry.tracer_provider.add_span_processor(FiddlerSpanProcessor())\n",
    "\n",
    "# Setup exporters\n",
    "strands_telemetry.setup_console_exporter()  # For debugging - prints to console\n",
    "strands_telemetry.setup_otlp_exporter()  # For Fiddler - sends traces via OTLP\n",
    "\n",
    "print('✅ Strands telemetry configured with Fiddler integration')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1-f2a3-4b5c-6d7e-8f9a0b1c2d3e",
   "metadata": {},
   "source": [
    "## 5. Define Agent Tools\n",
    "\n",
    "Create tools that the agent can use. These will be automatically traced and monitored by Fiddler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2-a3b4-5c6d-7e8f-9a0b1c2d3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\n",
    "\n",
    "    Args:\n",
    "        city: The name of the city\n",
    "\n",
    "    Returns:\n",
    "        Weather information as a string\n",
    "    \"\"\"\n",
    "    # Simulate weather API response\n",
    "    import random\n",
    "\n",
    "    conditions = ['sunny', 'cloudy', 'rainy', 'partly cloudy']\n",
    "    temp = random.randint(60, 85)\n",
    "    return f'The weather in {city} is {random.choice(conditions)} with a temperature of {temp}°F'\n",
    "\n",
    "@tool\n",
    "def search_knowledge_base(query: str) -> str:\n",
    "    \"\"\"Search the knowledge base for information.\n",
    "\n",
    "    Args:\n",
    "        query: The search query\n",
    "\n",
    "    Returns:\n",
    "        Relevant information from the knowledge base\n",
    "    \"\"\"\n",
    "    # Simulate knowledge base search\n",
    "    knowledge = {\n",
    "        'monitoring': 'Fiddler provides comprehensive AI observability for models, LLMs, and agents.',\n",
    "        'agents': 'AI agents can be monitored using OpenTelemetry integration with Fiddler.',\n",
    "        'strands': 'Strands is a modern agent framework with built-in telemetry support.',\n",
    "    }\n",
    "\n",
    "    for key, value in knowledge.items():\n",
    "        if key in query.lower():\n",
    "            return value\n",
    "\n",
    "    return f\"No specific information found for '{query}', but Fiddler can help monitor AI systems.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Safely evaluate a mathematical expression.\n",
    "\n",
    "    Args:\n",
    "        expression: Mathematical expression to evaluate (e.g., \"2 + 2\")\n",
    "\n",
    "    Returns:\n",
    "        The result of the calculation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safe evaluation of simple math expressions\n",
    "        result = eval(expression, {'__builtins__': {}}, {})\n",
    "        return f'The result is: {result}'\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating '{expression}': {str(e)}\"\n",
    "\n",
    "\n",
    "print('✅ Agent tools defined: get_weather, search_knowledge_base, calculate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3-b4c5-6d7e-8f9a-0b1c2d3e4f5a",
   "metadata": {},
   "source": [
    "## 6. Create and Configure the Agent\n",
    "\n",
    "Initialize the Strands agent with OpenAI model and the defined tools. The agent is automatically instrumented with telemetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4-c5d6-7e8f-9a0b-1c2d3e4f5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.models.openai import OpenAIModel\n",
    "\n",
    "# Initialize OpenAI model\n",
    "model = OpenAIModel(\n",
    "    client_args={'api_key': os.getenv('OPENAI_API_KEY')}, model_id='gpt-4o-mini'\n",
    ")\n",
    "\n",
    "# Create the agent with system prompt and tools\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"\"\"You are a helpful AI assistant with access to weather information, \n",
    "    a knowledge base, and calculation tools. Always be concise and accurate in your responses.\n",
    "    When appropriate, use the available tools to provide helpful information.\"\"\",\n",
    "    tools=[get_weather, search_knowledge_base, calculate],\n",
    ")\n",
    "\n",
    "print('✅ Agent created and instrumented with telemetry')\n",
    "print(f'   Model: {model.config}')\n",
    "print(f'   Tools: {agent.tool_names} available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5-d6e7-8f9a-0b1c-2d3e4f5a6b7c",
   "metadata": {},
   "source": [
    "## 7. Execute Agent Tasks\n",
    "\n",
    "Run several example queries to generate traces. Each execution will create spans that are sent to Fiddler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6-e7f8-9a0b-1c2d-3e4f5a6b7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Example 1: Weather query (uses get_weather tool)\n",
    "print('\\n' + '=' * 60)\n",
    "print('Query 1: Weather Information')\n",
    "print('=' * 60)\n",
    "response1 = agent(\"What's the weather like in San Francisco?\")\n",
    "print(f'Response: {response1}')\n",
    "\n",
    "time.sleep(1)  # Brief pause between queries\n",
    "\n",
    "# Example 2: Knowledge base query (uses search_knowledge_base tool)\n",
    "print('\\n' + '=' * 60)\n",
    "print('Query 2: Knowledge Base Search')\n",
    "print('=' * 60)\n",
    "response2 = agent('Tell me about monitoring AI agents with Fiddler')\n",
    "print(f'Response: {response2}')\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Example 3: Calculation (uses calculate tool)\n",
    "print('\\n' + '=' * 60)\n",
    "print('Query 3: Mathematical Calculation')\n",
    "print('=' * 60)\n",
    "response3 = agent('What is 15 * 7 + 23?')\n",
    "print(f'Response: {response3}')\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# Example 4: Multi-tool query (may use multiple tools)\n",
    "print('\\n' + '=' * 60)\n",
    "print('Query 4: Complex Multi-Tool Request')\n",
    "print('=' * 60)\n",
    "response4 = agent(\n",
    "    \"What's the weather in New York and how does Strands agent monitoring work?\"\n",
    ")\n",
    "print(f'Response: {response4}')\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('✅ All queries completed successfully')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7-f8a9-0b1c-2d3e-4f5a6b7c8d9e",
   "metadata": {},
   "source": [
    "## 8. Verify Traces in Fiddler\n",
    "\n",
    "After running the agent queries, traces should appear in your Fiddler application within 30 seconds.\n",
    "\n",
    "**Steps to verify:**\n",
    "\n",
    "1. Navigate to your Fiddler instance\n",
    "2. Go to your application (the one with APPLICATION_UUID)\n",
    "3. Click on the **Traces** tab\n",
    "4. Look for recent traces from the agent executions\n",
    "\n",
    "**What to check:**\n",
    "- ✅ Traces appear for each agent query\n",
    "- ✅ Parent and child spans are properly linked\n",
    "- ✅ Tool calls appear as separate spans\n",
    "- ✅ Agent attributes are present:\n",
    "  - `gen_ai.agent.name`\n",
    "  - `gen_ai.agent.id`\n",
    "  - `system_prompt`\n",
    "- ✅ Latency metrics are captured\n",
    "\n",
    "**Console Output:**\n",
    "\n",
    "You should also see trace information in the console output above (from the console exporter). This helps with local debugging before checking Fiddler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9-b0c1-2d3e-4f5a-6b7c8d9e0f1a",
   "metadata": {},
   "source": [
    "## 9. Troubleshooting\n",
    "\n",
    "If traces are not appearing in Fiddler, check the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0-c1d2-3e4f-5a6b-7c8d9e0f1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic checks\n",
    "print('Diagnostic Information:')\n",
    "print('=' * 60)\n",
    "\n",
    "# Check environment variables\n",
    "print('\\n1. Environment Variables:')\n",
    "print(f'   OTEL_EXPORTER_OTLP_ENDPOINT: {os.getenv(\"OTEL_EXPORTER_OTLP_ENDPOINT\")}')\n",
    "print(f'   OTEL_RESOURCE_ATTRIBUTES: {os.getenv(\"OTEL_RESOURCE_ATTRIBUTES\")}')\n",
    "print(\n",
    "    f'   OTEL_EXPORTER_OTLP_HEADERS: {\"Set\" if os.getenv(\"OTEL_EXPORTER_OTLP_HEADERS\") else \"Not Set\"}'\n",
    ")\n",
    "\n",
    "# Check network connectivity\n",
    "print('\\n2. Network Connectivity:')\n",
    "try:\n",
    "    import requests\n",
    "\n",
    "    response = requests.head(FIDDLER_ENDPOINT, timeout=5)\n",
    "    print(\n",
    "        f'   Connection to {FIDDLER_ENDPOINT}: ✅ Success (Status: {response.status_code})'\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f'   Connection to {FIDDLER_ENDPOINT}: ❌ Failed ({str(e)})')\n",
    "\n",
    "# Verify configuration\n",
    "print('\\n3. Configuration:')\n",
    "print(f'   Fiddler Endpoint: {FIDDLER_ENDPOINT}')\n",
    "print(f'   Application UUID: {APPLICATION_UUID}')\n",
    "print(f'   Bearer Token: {\"Set\" if TOKEN else \"Not Set\"}')\n",
    "print(f'   OpenAI API Key: {\"Set\" if OPENAI_API_KEY else \"Not Set\"}')\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('\\nIf issues persist:')\n",
    "print('1. Verify your personal access token is valid and not expired')\n",
    "print('2. Ensure Application UUID matches your Fiddler application')\n",
    "print('3. Check Fiddler application has OTEL ingestion enabled')\n",
    "print('4. Review console exporter output for trace details')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1-d2e3-4f5a-6b7c-8d9e0f1a2b3c",
   "metadata": {},
   "source": [
    "## 10. Advanced Configuration (Optional)\n",
    "\n",
    "For production deployments, you may want to customize the telemetry configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2-e3f4-5a6b-7c8d-9e0f1a2b3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Advanced telemetry configuration\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "\n",
    "# Create custom resource with additional metadata\n",
    "resource = Resource.create(\n",
    "    {\n",
    "        'service.name': 'strands-agent-service',\n",
    "        'service.version': '1.0.0',\n",
    "        'deployment.environment': 'notebook-demo',\n",
    "        'application.id': APPLICATION_UUID,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize tracer provider with custom resource\n",
    "provider = TracerProvider(resource=resource)\n",
    "\n",
    "# Add Fiddler span processor\n",
    "provider.add_span_processor(FiddlerSpanProcessor())\n",
    "\n",
    "# Configure OTLP exporter with custom settings\n",
    "otlp_exporter = OTLPSpanExporter(\n",
    "    endpoint=FIDDLER_ENDPOINT,\n",
    "    headers={\n",
    "        'authorization': f'Bearer {TOKEN}',\n",
    "        'fiddler-application-id': APPLICATION_UUID,\n",
    "    },\n",
    "    timeout=10,  # Custom timeout in seconds\n",
    ")\n",
    "\n",
    "# Add batch processor with custom settings\n",
    "batch_processor = BatchSpanProcessor(\n",
    "    otlp_exporter,\n",
    "    max_queue_size=2048,  # Max spans in queue\n",
    "    max_export_batch_size=512,  # Spans per export batch\n",
    "    schedule_delay_millis=5000,  # Export every 5 seconds\n",
    ")\n",
    "provider.add_span_processor(batch_processor)\n",
    "\n",
    "print('✅ Advanced telemetry configuration ready')\n",
    "print('   This configuration can be used for production deployments')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1d2e3-f4a5-6b7c-8d9e-0f1a2b3c4d5e",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you have Strands agents integrated with Fiddler:\n",
    "\n",
    "### Monitoring & Analytics\n",
    "- Explore agent performance metrics in Fiddler\n",
    "- Set up alerts for agent failures and anomalies\n",
    "- Analyze tool usage patterns\n",
    "- Track latency and token usage\n",
    "\n",
    "### Advanced Features\n",
    "- Implement multi-agent workflows with monitoring\n",
    "- Add custom metrics and attributes\n",
    "- Configure sampling strategies for scale\n",
    "- Set up data privacy and PII filtering\n",
    "\n",
    "### Resources\n",
    "- [Fiddler Documentation](https://docs.fiddler.ai)\n",
    "- [Strands Agents Documentation](https://strands-ai.github.io/strands-agents/)\n",
    "- [OpenTelemetry Python](https://opentelemetry.io/docs/instrumentation/python/)\n",
    "\n",
    "---\n",
    "\n",
    "**Need Help?**\n",
    "- Email: support@fiddler.ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
